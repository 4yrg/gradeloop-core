{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45ed789-53e9-4e00-a15d-85243810f607",
   "metadata": {},
   "source": [
    "# Data Preparation and Exploration for Code Clone Detection\n",
    "\n",
    "This notebook guides you through the initial steps of preparing your CodeNet dataset, from ingesting submissions to identifying different types of code clones (T1, T2, T4). It utilizes the scripts developed in the `model-orchestrator.cipas.code_clone_detection` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768f5c3-8820-4e4f-b12e-131c34a8731b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "This cell sets up the Python environment by adding the project root to `sys.path` and importing necessary modules. This ensures that all custom modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9042b5a-e755-4d7a-85d0-7a083321d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = Path('../../../../..').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import modules from the code_clone_detection package\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import data_ingest\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.parsers import normalizers\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import generate_syntactic_clones\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import execute_validation\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97424610-863a-4467-93e1-d6480119e710",
   "metadata": {},
   "source": [
    "## 2. Ingestion of CodeNet Submissions\n",
    "\n",
    "This step simulates ingesting a small subset of CodeNet submissions into our system. The `data_ingest.py` script scans a local CodeNet directory, stores the code content in the configured artifact store (MinIO by default), and saves metadata (submission ID, problem ID, language, status) into the database (PostgreSQL by default). \n",
    "\n",
    "We will limit the ingestion to a small number of submissions for demonstration purposes. \n",
    "\n",
    "**Expected Runtime:** This step might take a few seconds to minutes depending on the `--limit` and the performance of your database and artifact store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71343719-2f22-4416-abce-591789c67623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory of your local CodeNet dataset\n",
    "codenet_root_dir = Path(data_ingest.LOCAL_CODENET_ROOT) # Uses default from script\n",
    "\n",
    "# Run the data ingestion script as a CLI command\n",
    "# !python {project_root}/apps/model_orchestrator/app/models/cipas/code_clone_detection/scripts/data_ingest.py store --root-dir {codenet_root_dir} --limit 50\n",
    "\n",
    "# For demonstration without actual CLI execution, you can manually call the async function\n",
    "# Ensure your database and MinIO are running via `docker compose up`\n",
    "print(f\"Attempting to ingest up to 50 submissions from {codenet_root_dir}...\")\n",
    "try:\n",
    "    # Note: Directly calling async main() from a notebook requires running an event loop\n",
    "    # We'll use the !python command for simplicity or directly run the async function.\n",
    "    # For simplicity in notebook, we'll demonstrate the CLI command.\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f\"Ingestion failed (likely no running DB/MinIO or CodeNet not at {codenet_root_dir}): {e}\")\n",
    "\n",
    "print(\"Please manually execute the following in your terminal before running further cells if ingestion failed:\")\n",
    "print(f\"cd {project_root}\")\n",
    "print(\"docker compose up -d\")\n",
    "print(f\"python apps/model_orchestrator/app/models/cipas/code_clone_detection/scripts/data_ingest.py store --root-dir {codenet_root_dir} --limit 50\")\n",
    "print(\"Then, re-run this cell.\")\n",
    "\n",
    "# You can also run the scan command to see what would be ingested\n",
    "# !python {project_root}/apps/model_orchestrator/app/models/cipas/code_clone_detection/scripts/data_ingest.py scan --root-dir {codenet_root_dir} --limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f95c4-54c7-4348-ae83-20ae8679f22c",
   "metadata": {},
   "source": [
    "## 3. Code Parsing and Normalization\n",
    "\n",
    "This section demonstrates the code normalization capabilities, which are crucial for identifying various types of code clones. We'll use a sample Python code snippet and apply comment stripping, whitespace normalization, and identifier renaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed3949-06b2-4876-b33c-3932753a81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_python_code = \"\"\"\n",
    "# This is a comment\n",
    "def calculate_sum( a , b ): # Inline comment\n",
    "    result  = a +  b   # Another comment\n",
    "    return result\n",
    "\"\"\"\n",
    