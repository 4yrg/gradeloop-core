{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45ed789-53e9-4e00-a15d-85243810f607",
   "metadata": {},
   "source": [
    "# Cross-Dataset Validation of Code Clone Detection Encoder\n",
    "\n",
    "This notebook demonstrates how to evaluate the performance of the trained code clone detection encoder and retrieval system across different benchmark datasets: a held-out subset of CodeNet, BigCloneBench (BCB), and CodeXGLUE. It will compute relevant metrics such as Mean Average Precision (MAP), Recall@k, and F1-score for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768f5c3-8820-4e4f-b12e-131c34a8731b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "This cell sets up the Python environment, defines paths to necessary artifacts, and imports modules for data loading, inference, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9042b5a-e755-4d7a-85d0-7a083321d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Set, Tuple, Dict, Any\n",
    