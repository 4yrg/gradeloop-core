{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76ae403",
   "metadata": {},
   "source": [
    "# Hybrid Model Code Clone Dataset Generator\n",
    "\n",
    "## Problem Statement\n",
    "The original script used a small model (`codegemma:2b`) for all clone types. While fast, this model lacks the capability to handle complex Type-3 and Type-4 semantic transformations, resulting in mislabeled clones.\n",
    "\n",
    "## Solution: Hybrid Approach\n",
    "- **Easy Clones (Type-1, Type-2)**: Use `codegemma:2b` for fast, reliable generation\n",
    "- **Hard Clones (Type-3, Type-4)**: Use `deepseek-coder:6.7b` for accurate semantic transformations\n",
    "\n",
    "This notebook implements the complete hybrid workflow in a step-by-step manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178dae36",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "Import all required libraries and set up the configuration for the hybrid generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eef59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.099134Z",
     "start_time": "2025-12-13T05:36:17.085375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import all required libraries\n",
    "\"\"\"\n",
    "import uuid\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from colorama import Fore, Style, init\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Initialize colorama for Windows compatibility\n",
    "init(autoreset=True)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dd5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.151208Z",
     "start_time": "2025-12-13T05:36:17.129135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "Easy Model (Type-1/2): deepseek-coder:6.7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Model (Type-3/4): deepseek-coder:6.7b\n",
      "Target per type: 1\n",
      "CodeNet Root: D:\\Projects\\SLIIT\\Research\\Datasets\\Project_CodeNet\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration - Edit these paths and parameters\n",
    "\"\"\"\n",
    "\n",
    "# Path to CodeNet root directory\n",
    "CODENET_ROOT = Path(r\"D:/Projects/SLIIT/Research/Datasets/Project_CodeNet\")\n",
    "\n",
    "# CodeNet subdirectories\n",
    "RAW_CODENET_DIR = CODENET_ROOT / \"data\"\n",
    "METADATA_DIR = CODENET_ROOT / \"metadata\"\n",
    "\n",
    "# Output paths\n",
    "EASY_OUTPUT_PATH = Path(\"dataset/java_clones_easy_types.jsonl\")\n",
    "HARD_OUTPUT_PATH = Path(\"dataset/java_clones_hard_types.jsonl\")\n",
    "COMBINED_OUTPUT_PATH = Path(\"dataset/java_clones_10k.jsonl\")\n",
    "# Non-clone output paths\n",
    "EASY_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_easy_types.jsonl\")\n",
    "HARD_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_hard_types.jsonl\")\n",
    "FINAL_DATASET_PATH = Path(\"dataset/java_complete_dataset.jsonl\")\n",
    "GENERATED_DIR = Path(\"generated\")\n",
    "SEEDS_DIR = Path(\"seeds\")\n",
    "\n",
    "# Execution settings\n",
    "TIMEOUT_SECONDS = 30\n",
    "MAX_PROBLEMS = None  # None for all problems, or int to limit\n",
    "\n",
    "# Clone generation settings\n",
    "TARGET_CLONES_PER_TYPE = 1  # Target per type\n",
    "# Non-clone generation settings\n",
    "TARGET_NONCLONES_EASY = 1 # Target easy non-clones (simple algorithmic differences)\n",
    "TARGET_NONCLONES_HARD = 1  # Target hard non-clones (different problem domains)\n",
    "MAX_CLONES_PER_PROBLEM = 1\n",
    "MAX_CYCLES = 50\n",
    "\n",
    "# Model settings - HYBRID APPROACH\n",
    "EASY_MODEL = \"deepseek-coder:6.7b\"       # Fast model for Type-1, Type-2\n",
    "HARD_MODEL = \"deepseek-coder:6.7b\"  # Capable model for Type-3, Type-4\n",
    "\n",
    "# Logging\n",
    "VERBOSE = True\n",
    "\n",
    "# Create directories\n",
    "for directory in [GENERATED_DIR, SEEDS_DIR, EASY_OUTPUT_PATH.parent]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Configuration loaded\")\n",
    "print(f\"{Fore.CYAN}Easy Model (Type-1/2): {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Hard Model (Type-3/4): {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Target per type: {TARGET_CLONES_PER_TYPE}\")\n",
    "print(f\"{Fore.CYAN}CodeNet Root: {CODENET_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5526e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.196364Z",
     "start_time": "2025-12-13T05:36:17.179108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined (Updated with improved sanitization)\n"
     ]
    }
   ],
   "source": [
    "def normalize_unicode_to_ascii(text):\n",
    "    \"\"\"Convert Unicode characters to ASCII equivalents.\"\"\"\n",
    "    replacements = {\n",
    "        '\\u201c': '\"', '\\u201d': '\"', '\\u2018': \"'\", '\\u2019': \"'\",\n",
    "        '\\u201b': \"'\", '\\u2013': '-', '\\u2014': '-', '\\u2015': '-',\n",
    "        '\\u00a0': ' ', '\\u2009': ' ', '\\u200a': ' ', '\\u2026': '...',\n",
    "        '\\u00b4': \"'\", '\\u02bb': \"'\", '\\u02bc': \"'\"\n",
    "    }\n",
    "    \n",
    "    for unicode_char, ascii_char in replacements.items():\n",
    "        text = text.replace(unicode_char, ascii_char)\n",
    "    \n",
    "    cleaned = []\n",
    "    for char in text:\n",
    "        if ord(char) < 128 or char in ['\\n', '\\r', '\\t']:\n",
    "            cleaned.append(char)\n",
    "        else:\n",
    "            cleaned.append(' ')\n",
    "    \n",
    "    return ''.join(cleaned)\n",
    "\n",
    "def sanitize_code_from_model(raw_text):\n",
    "    \"\"\"Sanitize and extract Java code from model output.\"\"\"\n",
    "    if raw_text is None:\n",
    "        return None\n",
    "    \n",
    "    text = raw_text.strip()\n",
    "    text = normalize_unicode_to_ascii(text)\n",
    "    \n",
    "    # Handle fenced code blocks\n",
    "    if \"```\" in text:\n",
    "        parts = text.split(\"```\")\n",
    "        for part in parts:\n",
    "            if part.lower().startswith(\"java\"):\n",
    "                text = part[4:].lstrip()\n",
    "                break\n",
    "        else:\n",
    "            # Fallback: find the largest block inside backticks\n",
    "            candidates = [p for p in parts if len(p.strip()) > 20]\n",
    "            if candidates:\n",
    "                text = max(candidates, key=len)\n",
    "    \n",
    "    # Remove common LLM artifacts\n",
    "    llm_artifacts = [\n",
    "        r'< begin of sentence >', r'<begin of sentence>', r'< end of sentence >',\n",
    "        r'<end of sentence>', r'<\\|begin_of_text\\|>', r'<\\|end_of_text\\|>',\n",
    "        r'<s>', r'</s>', r'<\\|startoftext\\|>', r'<\\|endoftext\\|>',\n",
    "        r'<\\|file_separator\\|>', r'<\\|code_start\\|>', r'<\\|code_end\\|>'\n",
    "    ]\n",
    "    \n",
    "    for artifact in llm_artifacts:\n",
    "        text = re.sub(artifact, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up specific System.out artifacts if they leaked into code\n",
    "    # e.g., System.out< begin of sentence >println\n",
    "    text = re.sub(r'System\\.out\\s*<[^>]+>\\s*', 'System.out.', text)\n",
    "    \n",
    "    # Basic validation\n",
    "    if \"class Main\" not in text:\n",
    "        # Try to wrap it if it looks like code but missing class\n",
    "        if \"public static void main\" in text:\n",
    "             text = \"public class Main {\\n\" + text + \"\\n}\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Helper functions defined (Updated with improved sanitization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824f439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.231580Z",
     "start_time": "2025-12-13T05:36:17.214860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prompt templates defined (including non-clone templates)\n",
      "  Clone templates: Type-1, Type-2, Type-3, Type-4\n",
      "  Non-clone templates: Easy, Hard\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prompt templates for clone generation\n",
    "\"\"\"\n",
    "TYPE1_PROMPT_TEMPLATE = \"\"\"You are a Java code formatter. Transform this Java code by ONLY changing formatting while preserving all semantics.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. ONLY change formatting: whitespace, indentation, line breaks, comments\n",
    "4. MUST preserve all identifiers, literals, and code structure\n",
    "5. DO NOT rename variables, methods, or classes\n",
    "6. DO NOT change any literals or expressions\n",
    "7. DO NOT add, remove, or modify any statements\n",
    "8. DO NOT change control flow structure\n",
    "9. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Formatted Code:\"\"\"\n",
    "\n",
    "TYPE2_PROMPT_TEMPLATE = \"\"\"You are a Java refactoring assistant. Transform this code by renaming identifiers and changing literals while preserving exact behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. CAN rename variables, parameters, and method names (EXCEPT main method)\n",
    "4. CAN change literals (e.g., 10→0xA, true→(1==1), \"test\"→\"TEST\".toLowerCase())\n",
    "5. MUST preserve exact control flow and structure\n",
    "6. DO NOT add, remove, or reorder any statements\n",
    "7. DO NOT change the algorithmic logic or approach\n",
    "8. DO NOT modify control flow patterns (if/else, loops, etc.)\n",
    "9. Structure and statement order MUST remain identical\n",
    "10. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Refactored Code:\"\"\"\n",
    "\n",
    "TYPE3_PROMPT_TEMPLATE = \"\"\"You are a Java code mutator. Transform this code with statement-level modifications while preserving exact program behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. CAN replace statements with equivalent ones (e.g., for↔while loops)\n",
    "4. CAN introduce or remove temporary variables\n",
    "5. CAN refactor expressions (e.g., a+b+c → temp=a+b; result=temp+c)\n",
    "6. CAN add minimal dead code (unused variables, unreachable code after return)\n",
    "7. CAN reorder independent statements\n",
    "8. DO NOT change the underlying algorithm or approach\n",
    "9. DO NOT switch to library-based solutions (streams, collections APIs)\n",
    "10. MUST preserve exact input/output behavior\n",
    "11. Observable behavior MUST be identical\n",
    "12. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Modified Code:\"\"\"\n",
    "\n",
    "TYPE4_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Rewrite this code using a completely different algorithm while maintaining identical observable behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST preserve exact input format and parsing\n",
    "4. MUST preserve exact output format and content\n",
    "5. MUST have identical behavior for ALL possible inputs\n",
    "6. CAN use completely different algorithms, data structures, approaches\n",
    "7. CAN restructure the entire program logic\n",
    "8. CAN use different computational strategies\n",
    "9. Structure and implementation MAY be completely different\n",
    "10. Observable input/output behavior MUST be identical\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Rewritten Code:\"\"\"\n",
    "\n",
    "EASY_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are a Java programmer. Create a simple, different Java program that solves a basic algorithmic problem.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. Create a program for a COMPLETELY DIFFERENT problem domain\n",
    "4. DO NOT reuse any variable names from the reference code\n",
    "5. DO NOT use similar control-flow patterns\n",
    "6. DO NOT use similar data structures\n",
    "7. Must solve a clearly different algorithmic problem\n",
    "8. Use basic concepts: simple loops, arrays, basic arithmetic\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem goal and output meaning required\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SOMETHING COMPLETELY DIFFERENT):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Different Program:\"\"\"\n",
    "\n",
    "HARD_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Create a sophisticated Java program that has similar structure but different semantics from the reference code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST have similar control flow patterns (similar if/else, loop structures)\n",
    "4. MUST have similar program skeleton and structure\n",
    "5. MUST solve a DIFFERENT semantic problem with DIFFERENT output meaning\n",
    "6. MUST NOT have behavioral equivalence with the reference code\n",
    "7. Use advanced concepts: collections, recursion, object-oriented design\n",
    "8. High structural similarity but different algorithmic goal required\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem domain but similar complexity\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SIMILAR STRUCTURE, DIFFERENT SEMANTICS):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Structurally Similar Program:\"\"\"\n",
    "\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Prompt templates defined (including non-clone templates)\")\n",
    "print(f\"{Fore.CYAN}  Clone templates: Type-1, Type-2, Type-3, Type-4\")\n",
    "print(f\"{Fore.CYAN}  Non-clone templates: Easy, Hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d773ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.268803Z",
     "start_time": "2025-12-13T05:36:17.252459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CodeNet loading functions defined\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CodeNet data loading functions\n",
    "\"\"\"\n",
    "\n",
    "def list_problems():\n",
    "    \"\"\"List all available problem directories in CodeNet.\"\"\"\n",
    "    if not RAW_CODENET_DIR.exists():\n",
    "        log(f\"CodeNet directory not found: {RAW_CODENET_DIR}\", Fore.RED)\n",
    "        return []\n",
    "    \n",
    "    problems = []\n",
    "    for item in RAW_CODENET_DIR.iterdir():\n",
    "        if item.is_dir() and item.name.startswith('p') and len(item.name) == 6 and item.name[1:].isdigit():\n",
    "            problems.append(item.name)\n",
    "    \n",
    "    return sorted(problems)\n",
    "\n",
    "def load_submissions_csv(problem_id):\n",
    "    \"\"\"Load metadata CSV for a problem.\"\"\"\n",
    "    csv_path = METADATA_DIR / f\"{problem_id}.csv\"\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log(f\"Error reading CSV {csv_path}: {e}\", Fore.RED)\n",
    "        return None\n",
    "\n",
    "def choose_seed(problem_id):\n",
    "    \"\"\"Select a seed Java submission from the problem.\"\"\"\n",
    "    df = load_submissions_csv(problem_id)\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        return None, None\n",
    "    \n",
    "    java_accepted = df[\n",
    "        (df['language'] == 'Java') &\n",
    "        (df['status'] == 'Accepted')\n",
    "    ]\n",
    "    \n",
    "    if java_accepted.empty:\n",
    "        return None, None\n",
    "    \n",
    "    for _, row in java_accepted.iterrows():\n",
    "        submission_id = row['submission_id']\n",
    "        java_path = RAW_CODENET_DIR / problem_id / \"Java\" / f\"{submission_id}.java\"\n",
    "        \n",
    "        if not java_path.exists():\n",
    "            continue\n",
    "        \n",
    "        if java_path.stat().st_size > 10240:  # 10KB limit\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            code = java_path.read_text(encoding='utf-8')\n",
    "            return code, submission_id\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def load_testcases(problem_id):\n",
    "    \"\"\"Load input/output testcases for a problem.\"\"\"\n",
    "    testcases_dir = CODENET_ROOT / \"derived\" / \"input_output\" / \"data\" / problem_id\n",
    "    \n",
    "    input_file = testcases_dir / \"input.txt\"\n",
    "    output_file = testcases_dir / \"output.txt\"\n",
    "    \n",
    "    if not input_file.exists() or not output_file.exists():\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        input_text = input_file.read_text(encoding='utf-8')\n",
    "        output_text = output_file.read_text(encoding='utf-8')\n",
    "        return [(input_text, output_text)]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ CodeNet loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171eb097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.313909Z",
     "start_time": "2025-12-13T05:36:17.294759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Java validation functions defined (Updated checks and error reporting)\n"
     ]
    }
   ],
   "source": [
    "def log(message, color=Fore.WHITE):\n",
    "    \"\"\"Simple logger function.\"\"\"\n",
    "    try:\n",
    "        print(f\"{color}{message}{Style.RESET_ALL}\")\n",
    "    except Exception:\n",
    "        print(message)\n",
    "\n",
    "def ask_model_ollama(prompt, model_name, max_tokens=1500, temperature=0.1):\n",
    "    \"\"\"Call Ollama API to generate code.\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": max_tokens\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generated_text = result.get(\"response\", \"\")\n",
    "            return generated_text, None\n",
    "        else:\n",
    "            error_msg = f\"Ollama API error: HTTP {response.status_code}\"\n",
    "            return None, error_msg\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return None, \"Cannot connect to Ollama. Is it running? (ollama serve)\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        return None, \"Ollama API timeout\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Ollama API error: {str(e)}\"\n",
    "\n",
    "def quick_check_code_quality(code_str):\n",
    "    \"\"\"Check code quality without compilation.\"\"\"\n",
    "    if not code_str or len(code_str) < 50:\n",
    "        return False, \"Code too short\"\n",
    "    \n",
    "    if \"class Main\" not in code_str:\n",
    "        return False, \"Missing 'class Main'\"\n",
    "    \n",
    "    if \"main(\" not in code_str:\n",
    "        return False, \"Missing main method\"\n",
    "    \n",
    "    # Check for suspicious patterns\n",
    "    suspicious = [\n",
    "        \"TODO:\", \"FIXME:\", \"[Your code here]\", \"// ... rest of\",\n",
    "        \"// Original code\", \"// Explanation:\", \"Note that\", \n",
    "        \"< begin of sentence >\", \"<begin of sentence>\",\n",
    "        \"< end of sentence >\", \"<end of sentence>\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in suspicious:\n",
    "        if pattern in code_str:\n",
    "            return False, f\"Contains suspicious pattern: {pattern}\"\n",
    "    \n",
    "    # Check basic syntax balance - Relaxed to avoid false positives on generics or bitwise ops\n",
    "    if code_str.count('{') != code_str.count('}'):\n",
    "        return False, \"Unbalanced braces\"\n",
    "    \n",
    "    if code_str.count('(') != code_str.count(')'):\n",
    "        return False, \"Unbalanced parentheses\"\n",
    "    \n",
    "    # Check for incomplete statements\n",
    "    trimmed = code_str.strip()\n",
    "    if trimmed and trimmed[-1] not in ['}', ';', '*', '/']:\n",
    "        return False, \"Code appears incomplete\"\n",
    "    \n",
    "    return True, \"OK\"\n",
    "\n",
    "# [REMAINING VALIDATION FUNCTIONS KEPT AS IS]\n",
    "def compile_java(temp_dir):\n",
    "    \"\"\"Compile Main.java in temp_dir.\"\"\"\n",
    "    java_file = Path(temp_dir) / \"Main.java\"\n",
    "    \n",
    "    if not java_file.exists():\n",
    "        return False, \"Main.java not found\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"javac\", str(java_file)],\n",
    "            cwd=temp_dir,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=30,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return False, f\"Compilation error: {error[:500]}\"\n",
    "        \n",
    "        return True, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Compilation timeout\"\n",
    "    except FileNotFoundError:\n",
    "        return False, \"javac not found. Please install JDK.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Compilation exception: {str(e)}\"\n",
    "\n",
    "def run_java_with_input(temp_dir, input_str, timeout=3):\n",
    "    \"\"\"Run compiled Java program with given input.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"java\", \"Main\"],\n",
    "            cwd=temp_dir,\n",
    "            input=input_str.encode('utf-8'),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return None, f\"Runtime error: {error[:500]}\"\n",
    "        \n",
    "        output = result.stdout.decode('utf-8', errors='ignore')\n",
    "        return output, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, \"Execution timeout\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Execution exception: {str(e)}\"\n",
    "\n",
    "def normalize_output(text):\n",
    "    \"\"\"Normalize output text.\"\"\"\n",
    "    lines = text.strip().split('\\n')\n",
    "    return '\\n'.join(line.rstrip() for line in lines)\n",
    "\n",
    "def validate_java(code_str, problem_id):\n",
    "    \"\"\"Validate Java code by compiling and running against testcases.\"\"\"\n",
    "    testcases = load_testcases(problem_id)\n",
    "    \n",
    "    if not testcases:\n",
    "        return \"no_tests\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        java_file = Path(temp_dir) / \"Main.java\"\n",
    "        \n",
    "        try:\n",
    "            java_file.write_text(code_str, encoding='utf-8')\n",
    "        except Exception:\n",
    "            return \"compile_error\"\n",
    "        \n",
    "        compile_success, compile_error = compile_java(temp_dir)\n",
    "        \n",
    "        if not compile_success:\n",
    "            return f\"compile_error: {compile_error}\" # Enhanced return to include error message\n",
    "        \n",
    "        for idx, (input_text, expected_output) in enumerate(testcases):\n",
    "            output, error = run_java_with_input(temp_dir, input_text, timeout=TIMEOUT_SECONDS)\n",
    "            \n",
    "            if error:\n",
    "                if \"timeout\" in error.lower():\n",
    "                    return \"timeout\"\n",
    "                else:\n",
    "                    return f\"runtime_error: {error}\" # Enhanced return\n",
    "            \n",
    "            norm_output = normalize_output(output)\n",
    "            norm_expected = normalize_output(expected_output)\n",
    "            \n",
    "            if norm_output != norm_expected:\n",
    "                return \"wrong_answer\"\n",
    "        \n",
    "        return \"passed\"\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Java validation functions defined (Updated checks and error reporting)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439af73",
   "metadata": {},
   "source": [
    "## 2. Model Selection Logic\n",
    "Define the hybrid model selection strategy based on clone type complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3530907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Checking Ollama Connection...\n",
      "============================================================\n",
      "\n",
      "✓ Ollama is running and accessible\n",
      "\n",
      "Available models:\n",
      "  • deepseek-coder:6.7b\n",
      "  • qwen2.5-coder:7b\n",
      "  • qwen2.5-coder:0.5b\n",
      "  • starcoder:1b\n",
      "  • codegemma:2b\n",
      "\n",
      "✓ All required models are available\n",
      "\n",
      "✓ Pre-flight checks complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check Ollama connectivity before starting generation\n",
    "\"\"\"\n",
    "\n",
    "def check_ollama_connection():\n",
    "    \"\"\"Check if Ollama is running and accessible.\"\"\"\n",
    "    url = \"http://localhost:11434/api/tags\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get('models', [])\n",
    "            model_names = [m.get('name', '') for m in models]\n",
    "            return True, model_names\n",
    "        else:\n",
    "            return False, []\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return False, []\n",
    "    except Exception as e:\n",
    "        return False, []\n",
    "\n",
    "# Check Ollama connection\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Checking Ollama Connection...\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "is_connected, available_models = check_ollama_connection()\n",
    "\n",
    "if is_connected:\n",
    "    print(f\"{Fore.GREEN}✓ Ollama is running and accessible\")\n",
    "    print(f\"\\n{Fore.CYAN}Available models:\")\n",
    "    for model in available_models:\n",
    "        print(f\"  • {model}\")\n",
    "    \n",
    "    # Check if required models are available\n",
    "    required_models = [EASY_MODEL, HARD_MODEL]\n",
    "    missing_models = []\n",
    "    \n",
    "    for req_model in set(required_models):  # Use set to avoid duplicates\n",
    "        if not any(req_model in available for available in available_models):\n",
    "            missing_models.append(req_model)\n",
    "    \n",
    "    if missing_models:\n",
    "        print(f\"\\n{Fore.YELLOW}⚠ Warning: Required models not found:\")\n",
    "        for model in missing_models:\n",
    "            print(f\"  • {model}\")\n",
    "        print(f\"\\n{Fore.CYAN}To download missing models, run:\")\n",
    "        for model in missing_models:\n",
    "            print(f\"  ollama pull {model}\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}✓ All required models are available\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ Cannot connect to Ollama\")\n",
    "    print(f\"\\n{Fore.YELLOW}Please ensure Ollama is running:\")\n",
    "    print(f\"  1. Open a new terminal\")\n",
    "    print(f\"  2. Run: ollama serve\")\n",
    "    print(f\"  3. Then re-run this notebook\")\n",
    "    print(f\"\\n{Fore.CYAN}If you don't have Ollama installed:\")\n",
    "    print(f\"  Visit: https://ollama.ai/download\")\n",
    "    \n",
    "    raise RuntimeError(\"Ollama is not running. Please start Ollama and try again.\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}✓ Pre-flight checks complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a97f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.360160Z",
     "start_time": "2025-12-13T05:36:17.333814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model selection logic & Repair loop defined\n"
     ]
    }
   ],
   "source": [
    "REPAIR_PROMPT_TEMPLATE = \"\"\"You are a Java code repair assistant. The following Java code has errors. Fix the validation errors and output the corrected code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "Rules:\n",
    "1. MUST have class name as \"Main\"\n",
    "2. Fix SPECIFICALLY the error reported below\n",
    "3. Preserve the original logic as much as possible\n",
    "4. Output raw Java code ONLY\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Validation Error:\n",
    "<<<ERROR_PLACEHOLDER>>>\n",
    "\n",
    "Fixed Code:\"\"\"\n",
    "\n",
    "def get_model_for_clone_type(clone_type):\n",
    "    \"\"\"\n",
    "    Return the appropriate model based on clone type complexity.\n",
    "    \n",
    "    Easy types (Type-1, Type-2): Use fast codegemma:2b\n",
    "    Hard types (Type-3, Type-4): Use capable deepseek-coder:6.7b\n",
    "    \"\"\"\n",
    "    if clone_type in ['type1', 'type2']:\n",
    "        return EASY_MODEL\n",
    "    elif clone_type in ['type3', 'type4']:\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        # Default to hard model for unknown types\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_with_repair(prompt, model_name, problem_id=None, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate code with a repair loop. \n",
    "    If validation fails, ask the model to fix it using the error message.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Initial Generation\n",
    "    temperatures = [0.1, 0.3, 0.5]\n",
    "    best_candidate = None\n",
    "    \n",
    "    for attempt in range(2): # 2 attempts at initial generation\n",
    "        temp = temperatures[min(attempt, len(temperatures) - 1)]\n",
    "        raw, error = ask_model_ollama(prompt, model_name, max_tokens=1500, temperature=temp)\n",
    "        \n",
    "        if error:\n",
    "            log(f\"[MODEL ERROR] {error}\", Fore.RED)\n",
    "            continue\n",
    "            \n",
    "        code = sanitize_code_from_model(raw)\n",
    "        if not code:\n",
    "            continue\n",
    "            \n",
    "        # Quick check\n",
    "        valid_syntax, reason = quick_check_code_quality(code)\n",
    "        if not valid_syntax:\n",
    "            print(f\"  {Fore.YELLOW}Syntax check failed: {reason}\")\n",
    "            # Try to repair syntax immediately\n",
    "            # (Fall through to repair loop with this reason as error)\n",
    "            error_msg = f\"Syntax error: {reason}\"\n",
    "        else:\n",
    "            # Full validation if problem_id is provided\n",
    "            if problem_id:\n",
    "                result = validate_java(code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    return code # Success!\n",
    "                else:\n",
    "                    error_msg = result\n",
    "            else:\n",
    "                 return code # No problem ID to validate against, so return code\n",
    "        \n",
    "        # If we are here, we have code that failed. Enter repair loop.\n",
    "        # We only try to repair the FIRST valid-looking code we get from initial generation\n",
    "        # to save time.\n",
    "        \n",
    "        print(f\"  {Fore.YELLOW}Attempting repair for error: {error_msg}\")\n",
    "        \n",
    "        current_code = code\n",
    "        for repair_attempt in range(2): # 2 repair attempts\n",
    "            repair_prompt = REPAIR_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", current_code).replace(\"<<<ERROR_PLACEHOLDER>>>\", str(error_msg))\n",
    "            \n",
    "            # Use the harder model for repairs usually, or same model\n",
    "            repair_model = HARD_MODEL \n",
    "            \n",
    "            raw_repair, err = ask_model_ollama(repair_prompt, repair_model, max_tokens=1500, temperature=0.1)\n",
    "            \n",
    "            if err: \n",
    "                break\n",
    "                \n",
    "            repaired_code = sanitize_code_from_model(raw_repair)\n",
    "            if not repaired_code:\n",
    "                continue\n",
    "                \n",
    "            # Validate repaired code\n",
    "            valid_syntax, reason = quick_check_code_quality(repaired_code)\n",
    "            if not valid_syntax:\n",
    "                error_msg = f\"Syntax error after repair: {reason}\"\n",
    "                current_code = repaired_code # Try to repair the repaired code?\n",
    "                continue\n",
    "            \n",
    "            if problem_id:\n",
    "                result = validate_java(repaired_code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    print(f\"  {Fore.GREEN}Repair successful!\")\n",
    "                    return repaired_code\n",
    "                else:\n",
    "                    error_msg = result\n",
    "                    current_code = repaired_code\n",
    "            else:\n",
    "                return repaired_code\n",
    "                \n",
    "        # If repair failed, we continue to next initial generation attempt (with different temp)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def generate_clone(code, clone_type):\n",
    "    \"\"\"Generate a clone based on the type using the appropriate model.\"\"\"\n",
    "    if clone_type == 'type1':\n",
    "        prompt = TYPE1_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type2':\n",
    "        prompt = TYPE2_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type3':\n",
    "        prompt = TYPE3_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type4':\n",
    "        prompt = TYPE4_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    model_name = get_model_for_clone_type(clone_type)\n",
    "    \n",
    "    # We don't pass problem_id here because generate_clone signature match\n",
    "    # We will need to change how this is called or use a wrapper. \n",
    "    # Actually, let's just return the prompt and model and handle the loop in the main function?\n",
    "    # No, to minimize changes, let's keep the signature but we can't do full validation inside here\n",
    "    # without problem_id.\n",
    "    # So we will modify the caller to pass problem_id to a new function `generate_clone_with_id`\n",
    "    # OR we modify this function signature (it's defined in the notebook, so we can change it).\n",
    "    \n",
    "    return generate_with_retry(prompt, clone_type) # Fallback to old if not updated? \n",
    "    # Wait, we are replacing this cell.\n",
    "    # We should update the signature to accept problem_id\n",
    "    pass \n",
    "\n",
    "# Redefining generate_clone to accept problem_id is better, but requires changing the caller too.\n",
    "# The caller is in Cell 22. We will update that too.\n",
    "\n",
    "def generate_clone_v2(code, clone_type, problem_id):\n",
    "    if clone_type == 'type1':\n",
    "        prompt = TYPE1_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type2':\n",
    "        prompt = TYPE2_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type3':\n",
    "        prompt = TYPE3_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type4':\n",
    "        prompt = TYPE4_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_clone_type(clone_type)\n",
    "    return generate_with_repair(prompt, model, problem_id)\n",
    "\n",
    "def get_model_for_nonclone_type(nonclone_type):\n",
    "    if nonclone_type == 'easy':\n",
    "        return EASY_MODEL\n",
    "    elif nonclone_type == 'hard':\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_nonclone_v2(code, nonclone_type, problem_id=None):\n",
    "    if nonclone_type == 'easy':\n",
    "        prompt = EASY_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif nonclone_type == 'hard':\n",
    "        prompt = HARD_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_nonclone_type(nonclone_type)\n",
    "    # For non-clones, we just check compilation/sanity, we can't check 'passed' against original tests\n",
    "    # because the problem is DIFFERENT. So passing problem_id might be misleading if used for test validation.\n",
    "    # However, generate_with_repair uses problem_id to run tests.\n",
    "    # For non-clones, we should probably pass None for problem_id to skip testcase validation inside the repair loop,\n",
    "    # OR update generate_with_repair to handle 'compile_only' mode.\n",
    "    \n",
    "    return generate_with_repair(prompt, model, problem_id=None) \n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Model selection logic & Repair loop defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ec0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:36:17.406835Z",
     "start_time": "2025-12-13T05:36:17.391960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Core generation function defined (Updated with repair loop)\n"
     ]
    }
   ],
   "source": [
    "def generate_clones_for_types(clone_types, output_path, target_per_type):\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='w', flush=True)\n",
    "    \n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED}✗ No problems found in CodeNet directory\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "    \n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "    \n",
    "    # Clone counters\n",
    "    clone_counters = {ct: 0 for ct in clone_types}\n",
    "    \n",
    "    stats = {\n",
    "        'no_seed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'failed': 0\n",
    "    }\n",
    "    \n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "    \n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(clone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(clone_types)}\") as pbar:\n",
    "        while any(clone_counters[ct] < target_per_type for ct in clone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "                \n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "            \n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "            \n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "                \n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Load testcases\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\" # Normalize for check\n",
    "                \n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Generate clones for this problem\n",
    "                clones_generated_this_problem = 0\n",
    "                \n",
    "                # Generate each type of clone\n",
    "                for clone_type in clone_types:\n",
    "                    if clone_counters[clone_type] >= target_per_type:\n",
    "                        continue\n",
    "                    \n",
    "                    if clones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "                    \n",
    "                    # Skip Type-4 for complex files\n",
    "                    if clone_type == 'type4' and len(seed_code.split('\\n')) >= 75:\n",
    "                        continue\n",
    "                    \n",
    "                    # Generate clone\n",
    "                    try:\n",
    "                        # UPDATED CALL: Pass problem_id for repair loop\n",
    "                        generated_code = generate_clone_v2(seed_code, clone_type, problem_id)\n",
    "                        \n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Already validated inside generate_clone_v2 (mostly), but double check if returned\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        result = validate_java(generated_code, problem_id)\n",
    "                        \n",
    "                        if result == \"passed\":\n",
    "                            pair_id = f\"{problem_id}_{clone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "                            \n",
    "                            record = {\n",
    "                                'id': pair_id,\n",
    "                                'code_1': seed_code,\n",
    "                                'code_2': generated_code,\n",
    "                                'label': \"clone\",\n",
    "                                'clone_type': clone_type,\n",
    "                                'language': 'Java',\n",
    "                                'problem_id': problem_id,\n",
    "                                'generator': get_model_for_clone_type(clone_type),\n",
    "                                'timestamp': time.time()\n",
    "                            }\n",
    "                            \n",
    "                            dataset_writer.write(record)\n",
    "                            clone_counters[clone_type] += 1\n",
    "                            clones_generated_this_problem += 1\n",
    "                            pbar.update(1)\n",
    "                        else:\n",
    "                            stats['failed'] += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        log(f\"[{problem_id}] {clone_type} error: {repr(e)}\", Fore.RED)\n",
    "                \n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for ct, count in clone_counters.items():\n",
    "                        status = \"✓\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {ct}: {status}\")\n",
    "                    print()\n",
    "            \n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "    \n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "    \n",
    "    return clone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Core generation function defined (Updated with repair loop)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819e473",
   "metadata": {},
   "source": [
    "## 3. Generate Easy Clones (Type-1 and Type-2)\n",
    "Use the fast `codegemma:2b` model to generate Type-1 and Type-2 clones efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379000c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:46:33.765848Z",
     "start_time": "2025-12-13T05:36:17.424118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: Generating Easy Clones (Type-1, Type-2)\n",
      "Model: deepseek-coder:6.7b\n",
      "Output: dataset\\java_clones_easy_types.jsonl\n",
      "============================================================\n",
      "\n",
      "Found 4053 problems in CodeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating type1, type2: 100%|██████████| 2/2 [01:08<00:00, 34.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ EASY CLONES GENERATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Clone Counts:\n",
      "  type1: 1/1 ✓ COMPLETE\n",
      "  type2: 1/1 ✓ COMPLETE\n",
      "\n",
      "Total easy clones: 2\n",
      "Time taken: 2.12 minutes\n",
      "Dataset saved to: dataset\\java_clones_easy_types.jsonl\n",
      "\n",
      "Statistics:\n",
      "  No seed found: 1\n",
      "  Seed validation failed: 0\n",
      "  Generation/validation failed: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: Generate Easy Clones (Type-1 and Type-2) using codegemma:2b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 1: Generating Easy Clones (Type-1, Type-2)\")\n",
    "print(f\"{Fore.CYAN}Model: {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {EASY_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "easy_counters, easy_stats = generate_clones_for_types(\n",
    "    clone_types=['type1', 'type2'],\n",
    "    output_path=EASY_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ EASY CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_easy = 0\n",
    "for clone_type, count in easy_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_easy += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total easy clones: {total_easy}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {easy_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {easy_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {easy_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bddba",
   "metadata": {},
   "source": [
    "## 4. Generate Hard Clones (Type-3 and Type-4)\n",
    "Use the more capable `deepseek-coder:6.7b` model to generate complex Type-3 and Type-4 clones.\n",
    "\n",
    "**Note:** This step will be significantly slower due to the larger model, but it ensures correct semantic transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d02a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:00:05.706078Z",
     "start_time": "2025-12-13T05:46:33.945412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: Generating Hard Clones (Type-3, Type-4)\n",
      "Model: deepseek-coder:6.7b\n",
      "Output: dataset\\java_clones_hard_types.jsonl\n",
      "============================================================\n",
      "\n",
      "Found 4053 problems in CodeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating type3, type4:  50%|█████     | 1/2 [00:28<00:28, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting repair for error: wrong_answer\n",
      "  Attempting repair for error: wrong_answer\n",
      "  Repair successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating type3, type4: 100%|██████████| 2/2 [02:31<00:00, 75.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ HARD CLONES GENERATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Clone Counts:\n",
      "  type3: 1/1 ✓ COMPLETE\n",
      "  type4: 1/1 ✓ COMPLETE\n",
      "\n",
      "Total hard clones: 2\n",
      "Time taken: 2.55 minutes\n",
      "Dataset saved to: dataset\\java_clones_hard_types.jsonl\n",
      "\n",
      "Statistics:\n",
      "  No seed found: 1\n",
      "  Seed validation failed: 0\n",
      "  Generation/validation failed: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 2: Generate Hard Clones (Type-3 and Type-4) using deepseek-coder:6.7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 2: Generating Hard Clones (Type-3, Type-4)\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_counters, hard_stats = generate_clones_for_types(\n",
    "    clone_types=['type3', 'type4'],\n",
    "    output_path=HARD_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ HARD CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_hard = 0\n",
    "for clone_type, count in hard_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_hard += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard clones: {total_hard}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba43fd5",
   "metadata": {},
   "source": [
    "## 5. Combine Datasets\n",
    "Merge the easy and hard clone datasets into a single comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1367d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:00:05.884862Z",
     "start_time": "2025-12-13T06:00:05.812134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: Combining Datasets\n",
      "============================================================\n",
      "\n",
      "✓ Loaded 2 records from dataset\\java_clones_easy_types.jsonl\n",
      "✓ Loaded 2 records from dataset\\java_clones_hard_types.jsonl\n",
      "\n",
      "Total records to write: 4\n",
      "✓ Combined dataset written to: dataset\\java_clones_10k.jsonl\n",
      "\n",
      "Distribution by Clone Type:\n",
      "  type1: 1\n",
      "  type2: 1\n",
      "  type3: 1\n",
      "  type4: 1\n",
      "\n",
      "============================================================\n",
      "✓ DATASET COMBINATION COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 3: Combine Easy and Hard Clone Datasets\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 3: Combining Datasets\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read both datasets\n",
    "easy_records = []\n",
    "hard_records = []\n",
    "\n",
    "if EASY_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_OUTPUT_PATH) as reader:\n",
    "        easy_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(easy_records)} records from {EASY_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Easy clones file not found: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_OUTPUT_PATH) as reader:\n",
    "        hard_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(hard_records)} records from {HARD_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Hard clones file not found: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine records\n",
    "all_records = easy_records + hard_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_records)}\")\n",
    "\n",
    "# Write combined dataset\n",
    "with jsonlines.open(COMBINED_OUTPUT_PATH, mode='w') as writer:\n",
    "    for record in all_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Combined dataset written to: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "# Count by type\n",
    "type_counts = {}\n",
    "for record in all_records:\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Clone Type:\")\n",
    "for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "    count = type_counts.get(clone_type, 0)\n",
    "    print(f\"  {clone_type}: {count}\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ DATASET COMBINATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024152d6",
   "metadata": {},
   "source": [
    "## 6. Validate Combined Dataset\n",
    "Perform validation and quality checks on the final combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a4653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:00:06.055198Z",
     "start_time": "2025-12-13T06:00:05.896058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: Dataset Validation\n",
      "============================================================\n",
      "\n",
      "✓ Loaded 4 records from dataset\\java_clones_10k.jsonl\n",
      "\n",
      "Validation Checks:\n",
      "\n",
      "1. Clone Type Distribution:\n",
      "  ✓ type1: 1 (25.0%)\n",
      "  ✓ type2: 1 (25.0%)\n",
      "  ✓ type3: 1 (25.0%)\n",
      "  ✓ type4: 1 (25.0%)\n",
      "\n",
      "2. Model Distribution:\n",
      "  deepseek-coder:6.7b: 4 (100.0%)\n",
      "\n",
      "3. Model Assignment Verification:\n",
      "  ✓ All 4 records have correct model assignments\n",
      "\n",
      "4. Required Fields Check:\n",
      "  ✓ All records have all required fields\n",
      "\n",
      "============================================================\n",
      "FINAL DATASET SUMMARY\n",
      "============================================================\n",
      "Total Records: 4\n",
      "Dataset Path: dataset\\java_clones_10k.jsonl\n",
      "File Size: 0.00 MB\n",
      "\n",
      "Clone Type Breakdown:\n",
      "  type1: 1/1\n",
      "  type2: 1/1\n",
      "  type3: 1/1\n",
      "  type4: 1/1\n",
      "\n",
      "✓ Validation Complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 4: Validate the Combined Dataset\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 4: Dataset Validation\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Load combined dataset\n",
    "combined_records = []\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        combined_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(combined_records)} records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ Combined dataset not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if combined_records:\n",
    "    # Validation checks\n",
    "    print(f\"\\n{Fore.CYAN}Validation Checks:\")\n",
    "    \n",
    "    # 1. Check all clone types are present\n",
    "    type_distribution = {}\n",
    "    model_distribution = {}\n",
    "    \n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', 'unknown')\n",
    "        model = record.get('generator', 'unknown')\n",
    "        \n",
    "        type_distribution[clone_type] = type_distribution.get(clone_type, 0) + 1\n",
    "        model_distribution[model] = model_distribution.get(model, 0) + 1\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}1. Clone Type Distribution:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        status = \"✓\" if count > 0 else \"✗\"\n",
    "        print(f\"  {status} {clone_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}2. Model Distribution:\")\n",
    "    for model, count in model_distribution.items():\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        print(f\"  {model}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 3. Verify model assignment correctness\n",
    "    print(f\"\\n{Fore.CYAN}3. Model Assignment Verification:\")\n",
    "    correct_assignments = 0\n",
    "    incorrect_assignments = 0\n",
    "    \n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', '')\n",
    "        model = record.get('generator', '')\n",
    "        expected_model = get_model_for_clone_type(clone_type)\n",
    "        \n",
    "        if model == expected_model:\n",
    "            correct_assignments += 1\n",
    "        else:\n",
    "            incorrect_assignments += 1\n",
    "    \n",
    "    if incorrect_assignments == 0:\n",
    "        print(f\"  ✓ All {correct_assignments} records have correct model assignments\")\n",
    "    else:\n",
    "        print(f\"  ⚠ {correct_assignments} correct, {incorrect_assignments} incorrect\")\n",
    "    \n",
    "    # 4. Check for required fields\n",
    "    print(f\"\\n{Fore.CYAN}4. Required Fields Check:\")\n",
    "    required_fields = ['id', 'code_1', 'code_2', 'label', 'clone_type', 'language', 'problem_id', 'generator']\n",
    "    \n",
    "    missing_fields = {}\n",
    "    for record in combined_records:\n",
    "        for field in required_fields:\n",
    "            if field not in record or not record[field]:\n",
    "                missing_fields[field] = missing_fields.get(field, 0) + 1\n",
    "    \n",
    "    if not missing_fields:\n",
    "        print(f\"  ✓ All records have all required fields\")\n",
    "    else:\n",
    "        for field, count in missing_fields.items():\n",
    "            print(f\"  ⚠ {field}: missing in {count} records\")\n",
    "    \n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.GREEN}FINAL DATASET SUMMARY\")\n",
    "    print(f\"{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.CYAN}Total Records: {len(combined_records)}\")\n",
    "    print(f\"{Fore.CYAN}Dataset Path: {COMBINED_OUTPUT_PATH}\")\n",
    "    print(f\"{Fore.CYAN}File Size: {COMBINED_OUTPUT_PATH.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}Clone Type Breakdown:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE}\")\n",
    "    \n",
    "    print(f\"\\n{Fore.GREEN}✓ Validation Complete!\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ No records found for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc01fb64bbbd69c",
   "metadata": {},
   "source": [
    "## 7. Generate Easy Non-Clones\n",
    "Use the fast `codegemma:2b` model to generate easy non-clones with simple algorithmic differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c04ab3855fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:03:41.731486Z",
     "start_time": "2025-12-13T06:00:06.069304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Non-clone generation function defined\n"
     ]
    }
   ],
   "source": [
    "def generate_nonclones_for_types(nonclone_types, output_path, target_per_type):\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='w', flush=True)\n",
    "\n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED}✗ No problems found in CodeNet directory\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "\n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "\n",
    "    # Non-clone counters\n",
    "    nonclone_counters = {nt: 0 for nt in nonclone_types}\n",
    "\n",
    "    stats = {\n",
    "        'failed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'no_seed': 0,\n",
    "        'identical_skipped': 0\n",
    "    }\n",
    "\n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "\n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(nonclone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(nonclone_types)} non-clones\") as pbar:\n",
    "        while any(nonclone_counters[nt] < target_per_type for nt in nonclone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "\n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "\n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "\n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "\n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Load testcases (for validation of generated code)\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\"\n",
    "                \n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Generate non-clones for this problem\n",
    "                nonclones_generated_this_problem = 0\n",
    "\n",
    "                # Generate each type of non-clone\n",
    "                for nonclone_type in nonclone_types:\n",
    "                    if nonclone_counters[nonclone_type] >= target_per_type:\n",
    "                        continue\n",
    "\n",
    "                    if nonclones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "\n",
    "                    # Generate non-clone\n",
    "                    try:\n",
    "                        # UPDATED: Use v2 with None for problem_id (syntax repair only)\n",
    "                        generated_code = generate_nonclone_v2(seed_code, nonclone_type, problem_id=None)\n",
    "\n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # Quick quality check\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # For non-clones, we just need to check if it compiles and runs\n",
    "                        # (it doesn't need to pass the original test cases)\n",
    "                        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                            java_file = Path(temp_dir) / \"Main.java\"\n",
    "\n",
    "                            try:\n",
    "                                java_file.write_text(generated_code, encoding='utf-8')\n",
    "                                compile_success, compile_error = compile_java(temp_dir)\n",
    "\n",
    "                                if compile_success:\n",
    "                                    # Try to run it with empty input to see if it executes\n",
    "                                    output, error = run_java_with_input(temp_dir, \"\", timeout=5)\n",
    "\n",
    "                                    # As long as it compiles and doesn't crash, it's valid\n",
    "                                    if error is None or \"timeout\" not in error.lower():\n",
    "                                        pair_id = f\"{problem_id}_nonclone_{nonclone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "                                        record = {\n",
    "                                            'id': pair_id,\n",
    "                                            'code_1': seed_code,\n",
    "                                            'code_2': generated_code,\n",
    "                                            'label': \"non-clone\",\n",
    "                                            'clone_type': f\"nonclone_{nonclone_type}\",\n",
    "                                            'language': 'Java',\n",
    "                                            'problem_id': problem_id,\n",
    "                                            'generator': get_model_for_nonclone_type(nonclone_type),\n",
    "                                            'timestamp': time.time()\n",
    "                                        }\n",
    "\n",
    "                                        dataset_writer.write(record)\n",
    "                                        nonclone_counters[nonclone_type] += 1\n",
    "                                        nonclones_generated_this_problem += 1\n",
    "                                        pbar.update(1)\n",
    "                                    else:\n",
    "                                        stats['failed'] += 1\n",
    "                                else:\n",
    "                                    stats['failed'] += 1\n",
    "                            except Exception:\n",
    "                                stats['failed'] += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        # print(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\") # debug\n",
    "                        # log(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\", Fore.RED)\n",
    "\n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for nt, count in nonclone_counters.items():\n",
    "                        status = \"✓\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {nt} non-clones: {status}\")\n",
    "                    print()\n",
    "\n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                # log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "\n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "\n",
    "    return nonclone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Non-clone generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f13427f2a8a9a",
   "metadata": {},
   "source": [
    "## 8. Generate Hard Non-Clones\n",
    "Use the more capable `deepseek-coder:6.7b` model to generate hard non-clones with different problem domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb4b9cc57b1dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:07:52.772971Z",
     "start_time": "2025-12-13T06:03:41.807315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6: Generating Hard Non-Clones\n",
      "Model: deepseek-coder:6.7b\n",
      "Output: dataset\\java_nonclones_hard_types.jsonl\n",
      "============================================================\n",
      "\n",
      "Found 4053 problems in CodeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hard non-clones: 100%|██████████| 1/1 [00:58<00:00, 58.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ HARD NON-CLONES GENERATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Non-Clone Counts:\n",
      "  hard: 1/1 ✓ COMPLETE\n",
      "\n",
      "Total hard non-clones: 1\n",
      "Time taken: 0.99 minutes\n",
      "Dataset saved to: dataset\\java_nonclones_hard_types.jsonl\n",
      "\n",
      "Statistics:\n",
      "  No seed found: 1\n",
      "  Seed validation failed: 0\n",
      "  Generation/validation failed: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 6: Generate Hard Non-Clones using deepseek-coder:6.7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 6: Generating Hard Non-Clones\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_nonclone_counters, hard_nonclone_stats = generate_nonclones_for_types(\n",
    "    nonclone_types=['hard'],\n",
    "    output_path=HARD_NONCLONES_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_NONCLONES_HARD\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ HARD NON-CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Non-Clone Counts:\")\n",
    "total_hard_nonclones = 0\n",
    "for nonclone_type, count in hard_nonclone_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_NONCLONES_HARD else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {nonclone_type}: {count}/{TARGET_NONCLONES_HARD} {status}\")\n",
    "    total_hard_nonclones += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard non-clones: {total_hard_nonclones}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_nonclone_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_nonclone_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_nonclone_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77f42bf1f6c11e",
   "metadata": {},
   "source": [
    "## 9. Create Complete Dataset\n",
    "Combine all clones and non-clones into a single comprehensive dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e3fb54d31fff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T06:07:53.273897Z",
     "start_time": "2025-12-13T06:07:52.863339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 7: Creating Complete Dataset\n",
      "============================================================\n",
      "\n",
      "✓ Loaded 4 clone records from dataset\\java_clones_10k.jsonl\n",
      "⚠ Easy non-clones file not found: dataset\\java_nonclones_easy_types.jsonl\n",
      "✓ Loaded 1 hard non-clone records from dataset\\java_nonclones_hard_types.jsonl\n",
      "\n",
      "Total records to write: 5\n",
      "  Clones: 4\n",
      "  Easy Non-clones: 0\n",
      "  Hard Non-clones: 1\n",
      "✓ Complete dataset written to: dataset\\java_complete_dataset.jsonl\n",
      "\n",
      "Distribution by Label:\n",
      "  clone: 4 (80.0%)\n",
      "  non-clone: 1 (20.0%)\n",
      "\n",
      "Distribution by Type:\n",
      "  type1: 1 (20.0%)\n",
      "  type2: 1 (20.0%)\n",
      "  type3: 1 (20.0%)\n",
      "  type4: 1 (20.0%)\n",
      "  nonclone_easy: 0 (0.0%)\n",
      "  nonclone_hard: 1 (20.0%)\n",
      "\n",
      "============================================================\n",
      "✓ COMPLETE DATASET CREATION FINISHED!\n",
      "============================================================\n",
      "Final Dataset: dataset\\java_complete_dataset.jsonl\n",
      "Total Records: 5\n",
      "File Size: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 7: Create Complete Dataset (Clones + Non-Clones)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 7: Creating Complete Dataset\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read all datasets\n",
    "clone_records = []\n",
    "easy_nonclone_records = []\n",
    "hard_nonclone_records = []\n",
    "\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        clone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(clone_records)} clone records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Clone dataset file not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if EASY_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        easy_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(easy_nonclone_records)} easy non-clone records from {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Easy non-clones file not found: {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        hard_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(hard_nonclone_records)} hard non-clone records from {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Hard non-clones file not found: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine all records\n",
    "all_complete_records = clone_records + easy_nonclone_records + hard_nonclone_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_complete_records)}\")\n",
    "print(f\"  Clones: {len(clone_records)}\")\n",
    "print(f\"  Easy Non-clones: {len(easy_nonclone_records)}\")\n",
    "print(f\"  Hard Non-clones: {len(hard_nonclone_records)}\")\n",
    "\n",
    "# Write complete dataset\n",
    "with jsonlines.open(FINAL_DATASET_PATH, mode='w') as writer:\n",
    "    for record in all_complete_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Complete dataset written to: {FINAL_DATASET_PATH}\")\n",
    "\n",
    "# Count by type and label\n",
    "label_counts = {}\n",
    "type_counts = {}\n",
    "for record in all_complete_records:\n",
    "    label = record.get('label', 'unknown')\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Label:\")\n",
    "for label in ['clone', 'non-clone']:\n",
    "    count = label_counts.get(label, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Type:\")\n",
    "for type_name in ['type1', 'type2', 'type3', 'type4', 'nonclone_easy', 'nonclone_hard']:\n",
    "    count = type_counts.get(type_name, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {type_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ COMPLETE DATASET CREATION FINISHED!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Final Dataset: {FINAL_DATASET_PATH}\")\n",
    "print(f\"{Fore.CYAN}Total Records: {len(all_complete_records)}\")\n",
    "print(f\"{Fore.CYAN}File Size: {FINAL_DATASET_PATH.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
