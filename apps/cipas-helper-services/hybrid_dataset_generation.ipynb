{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76ae403",
   "metadata": {},
   "source": [
    "# Hybrid Model Code Clone Dataset Generator\n",
    "\n",
    "## Problem Statement\n",
    "The original script used a small model (`codegemma:2b`) for all clone types. While fast, this model lacks the capability to handle complex Type-3 and Type-4 semantic transformations, resulting in mislabeled clones.\n",
    "\n",
    "## Solution: Hybrid Approach\n",
    "- **Easy Clones (Type-1, Type-2)**: Use `qwen2.5-coder:7b` for fast, reliable generation\n",
    "- **Hard Clones (Type-3, Type-4)**: Use `qwen2.5-coder:7b` for accurate semantic transformations\n",
    "\n",
    "This notebook implements the complete hybrid workflow in a step-by-step manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178dae36",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "Import all required libraries and set up the configuration for the hybrid generation process."
   ]
  },
  {
   "cell_type": "code",
   "id": "93eef59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:00.996270Z",
     "start_time": "2025-12-16T09:13:00.978386Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Import all required libraries\n",
    "\"\"\"\n",
    "import uuid\n",
    "import time\n",
    "import subprocess\n",
    "import tempfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from colorama import Fore, Style, init\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Initialize colorama for Windows compatibility\n",
    "init(autoreset=True)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ All libraries imported successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "127dd5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:01.055021Z",
     "start_time": "2025-12-16T09:13:01.015780Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Configuration - Edit these paths and parameters\n",
    "\"\"\"\n",
    "\n",
    "# Path to CodeNet root directory\n",
    "CODENET_ROOT = Path(r\"D:/Projects/SLIIT/Research/Datasets/Project_CodeNet\")\n",
    "\n",
    "# CodeNet subdirectories\n",
    "RAW_CODENET_DIR = CODENET_ROOT / \"data\"\n",
    "METADATA_DIR = CODENET_ROOT / \"metadata\"\n",
    "\n",
    "# Output paths\n",
    "EASY_OUTPUT_PATH = Path(\"dataset/java_clones_easy_types.jsonl\")\n",
    "HARD_OUTPUT_PATH = Path(\"dataset/java_clones_hard_types.jsonl\")\n",
    "COMBINED_OUTPUT_PATH = Path(\"dataset/java_clones_10k.jsonl\")\n",
    "# Non-clone output paths\n",
    "EASY_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_easy_types.jsonl\")\n",
    "HARD_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_hard_types.jsonl\")\n",
    "FINAL_DATASET_PATH = Path(\"dataset/java_complete_dataset.jsonl\")\n",
    "GENERATED_DIR = Path(\"generated\")\n",
    "SEEDS_DIR = Path(\"seeds\")\n",
    "\n",
    "# Execution settings\n",
    "TIMEOUT_SECONDS = 30\n",
    "MAX_PROBLEMS = None  # None for all problems, or int to limit\n",
    "\n",
    "# Clone generation settings\n",
    "TARGET_CLONES_PER_TYPE = 100  # Target per type - reasonable for testing, can increase later\n",
    "# Non-clone generation settings\n",
    "TARGET_NONCLONES_EASY = 100 # Target easy non-clones (simple algorithmic differences)\n",
    "TARGET_NONCLONES_HARD = 100  # Target hard non-clones (different problem domains)\n",
    "MAX_CLONES_PER_PROBLEM = 5\n",
    "MAX_CYCLES = 50\n",
    "\n",
    "# Model settings - HYBRID APPROACH\n",
    "EASY_MODEL = \"qwen2.5-coder:7b\"       # Fast model for Type-1, Type-2\n",
    "HARD_MODEL = \"qwen2.5-coder:7b\"\n",
    "# EASY_MODEL = \"codegemma:7b\"       # Fast model for Type-1, Type-2\n",
    "# HARD_MODEL = \"codegemma:7b\"  # Capable model for Type-3, Type-4\n",
    "\n",
    "# Logging\n",
    "VERBOSE = True\n",
    "\n",
    "# Create directories\n",
    "for directory in [GENERATED_DIR, SEEDS_DIR, EASY_OUTPUT_PATH.parent]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Configuration loaded\")\n",
    "print(f\"{Fore.CYAN}Easy Model (Type-1/2): {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Hard Model (Type-3/4): {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Target per type: {TARGET_CLONES_PER_TYPE}\")\n",
    "print(f\"{Fore.CYAN}CodeNet Root: {CODENET_ROOT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "Easy Model (Type-1/2): qwen2.5-coder:7b\n",
      "Hard Model (Type-3/4): qwen2.5-coder:7b\n",
      "Target per type: 100\n",
      "CodeNet Root: D:\\Projects\\SLIIT\\Research\\Datasets\\Project_CodeNet\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "8a5526e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:01.081563Z",
     "start_time": "2025-12-16T09:13:01.064527Z"
    }
   },
   "source": [
    "def normalize_unicode_to_ascii(text):\n",
    "    \"\"\"Convert Unicode characters to ASCII equivalents.\"\"\"\n",
    "    replacements = {\n",
    "        '\\u201c': '\"', '\\u201d': '\"', '\\u2018': \"'\", '\\u2019': \"'\",\n",
    "        '\\u201b': \"'\", '\\u2013': '-', '\\u2014': '-', '\\u2015': '-',\n",
    "        '\\u00a0': ' ', '\\u2009': ' ', '\\u200a': ' ', '\\u2026': '...',\n",
    "        '\\u00b4': \"'\", '\\u02bb': \"'\", '\\u02bc': \"'\"\n",
    "    }\n",
    "    \n",
    "    for unicode_char, ascii_char in replacements.items():\n",
    "        text = text.replace(unicode_char, ascii_char)\n",
    "    \n",
    "    cleaned = []\n",
    "    for char in text:\n",
    "        if ord(char) < 128 or char in ['\\n', '\\r', '\\t']:\n",
    "            cleaned.append(char)\n",
    "        else:\n",
    "            cleaned.append(' ')\n",
    "    \n",
    "    return ''.join(cleaned)\n",
    "\n",
    "def sanitize_code_from_model(raw_text):\n",
    "    \"\"\"Sanitize and extract Java code from model output.\"\"\"\n",
    "    if raw_text is None:\n",
    "        return None\n",
    "    \n",
    "    text = raw_text.strip()\n",
    "    text = normalize_unicode_to_ascii(text)\n",
    "    \n",
    "    # Handle fenced code blocks\n",
    "    if \"```\" in text:\n",
    "        parts = text.split(\"```\")\n",
    "        for part in parts:\n",
    "            if part.lower().startswith(\"java\"):\n",
    "                text = part[4:].lstrip()\n",
    "                break\n",
    "        else:\n",
    "            # Fallback: find the largest block inside backticks\n",
    "            candidates = [p for p in parts if len(p.strip()) > 20]\n",
    "            if candidates:\n",
    "                text = max(candidates, key=len)\n",
    "    \n",
    "    # Remove common LLM artifacts\n",
    "    llm_artifacts = [\n",
    "        r'< begin of sentence >', r'<begin of sentence>', r'< end of sentence >',\n",
    "        r'<end of sentence>', r'<\\|begin_of_text\\|>', r'<\\|end_of_text\\|>',\n",
    "        r'<s>', r'</s>', r'<\\|startoftext\\|>', r'<\\|endoftext\\|>',\n",
    "        r'<\\|file_separator\\|>', r'<\\|code_start\\|>', r'<\\|code_end\\|>'\n",
    "    ]\n",
    "    \n",
    "    for artifact in llm_artifacts:\n",
    "        text = re.sub(artifact, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up specific System.out artifacts if they leaked into code\n",
    "    # e.g., System.out< begin of sentence >println\n",
    "    text = re.sub(r'System\\.out\\s*<[^>]+>\\s*', 'System.out.', text)\n",
    "    \n",
    "    # Basic validation\n",
    "    if \"class Main\" not in text:\n",
    "        # Try to wrap it if it looks like code but missing class\n",
    "        if \"public static void main\" in text:\n",
    "             text = \"public class Main {\\n\" + text + \"\\n}\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Helper functions defined (Updated with improved sanitization)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined (Updated with improved sanitization)\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "4824f439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:01.130232Z",
     "start_time": "2025-12-16T09:13:01.102745Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Prompt templates for clone generation\n",
    "\"\"\"\n",
    "TYPE1_PROMPT_TEMPLATE = \"\"\"You are a Java code formatter. Transform this Java code by ONLY changing formatting while preserving all semantics.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. ONLY change formatting: whitespace, indentation, line breaks, comments\n",
    "4. MUST preserve all identifiers, literals, and code structure\n",
    "5. DO NOT rename variables, methods, or classes\n",
    "6. DO NOT change any literals or expressions\n",
    "7. DO NOT add, remove, or modify any statements\n",
    "8. DO NOT change control flow structure\n",
    "9. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Formatted Code:\"\"\"\n",
    "\n",
    "TYPE2_PROMPT_TEMPLATE = \"\"\"You are a Java refactoring assistant. Transform this code by renaming identifiers and changing literals while preserving exact behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. CAN rename variables, parameters, and method names (EXCEPT main method)\n",
    "4. CAN change literals (e.g., 10→0xA, true→(1==1), \"test\"→\"TEST\".toLowerCase())\n",
    "5. MUST preserve exact control flow and structure\n",
    "6. DO NOT add, remove, or reorder any statements\n",
    "7. DO NOT change the algorithmic logic or approach\n",
    "8. DO NOT modify control flow patterns (if/else, loops, etc.)\n",
    "9. Structure and statement order MUST remain identical\n",
    "10. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Refactored Code:\"\"\"\n",
    "\n",
    "TYPE3_PROMPT_TEMPLATE = \"\"\"You are a Java code mutator. Transform this code with SIGNIFICANT statement-level modifications while preserving exact program behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "**TYPE-3 CLONE REQUIREMENTS - YOU MUST DO AT LEAST 3 OF THESE:**\n",
    "1. Replace for loops with while loops (or vice versa)\n",
    "2. Add temporary variables to break up complex expressions: `result = a + b + c` → `temp = a + b; result = temp + c`\n",
    "3. Add dead code: unused variables, unreachable statements after return/break\n",
    "4. Reorder independent statements (declarations, assignments that don't depend on each other)\n",
    "5. Replace if-else with ternary operators (or vice versa): `if(x>0) y=1; else y=0;` → `y = (x>0) ? 1 : 0;`\n",
    "6. Add redundant calculations: `x = 5` → `x = 3 + 2` or `x = 10/2`\n",
    "7. Extract inline calculations into separate statements\n",
    "8. Add extra variable assignments that don't change behavior\n",
    "9. Change loop increment styles: `i++` → `i = i + 1` → `i += 1`\n",
    "10. Add null checks or bounds checks that are always true/false\n",
    "\n",
    "**CONCRETE EXAMPLES OF REQUIRED CHANGES:**\n",
    "\n",
    "Example 1 - Loop Conversion:\n",
    "BEFORE: `for(int i=0; i<n; i++) { sum += arr[i]; }`\n",
    "AFTER: `int i = 0; while(i < n) { sum += arr[i]; i = i + 1; }`\n",
    "\n",
    "Example 2 - Expression Breakdown:\n",
    "BEFORE: `int result = (a + b) * (c - d);`\n",
    "AFTER: `int temp1 = a + b; int temp2 = c - d; int result = temp1 * temp2;`\n",
    "\n",
    "Example 3 - Dead Code Addition:\n",
    "BEFORE: `return result;`\n",
    "AFTER: `int unused = 42; return result; System.out.println(\"never reached\");`\n",
    "\n",
    "**FORBIDDEN (these make Type-1 clones, NOT Type-3):**\n",
    "- Only changing whitespace/formatting\n",
    "- Only renaming variables\n",
    "- Only changing comments\n",
    "- Only changing literal values without structural impact\n",
    "\n",
    "**REQUIRED STRUCTURE:**\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST preserve exact input/output behavior\n",
    "4. MUST have noticeable structural differences from original\n",
    "5. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Structurally Modified Code:\"\"\"\n",
    "\n",
    "TYPE4_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Rewrite this code using a completely different algorithm while maintaining identical observable behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST preserve exact input format and parsing\n",
    "4. MUST preserve exact output format and content\n",
    "5. MUST have identical behavior for ALL possible inputs\n",
    "6. CAN use completely different algorithms, data structures, approaches\n",
    "7. CAN restructure the entire program logic\n",
    "8. CAN use different computational strategies\n",
    "9. Structure and implementation MAY be completely different\n",
    "10. Observable input/output behavior MUST be identical\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Rewritten Code:\"\"\"\n",
    "\n",
    "EASY_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are a Java programmer. Create a simple, different Java program that solves a basic algorithmic problem.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. Create a program for a COMPLETELY DIFFERENT problem domain\n",
    "4. DO NOT reuse any variable names from the reference code\n",
    "5. DO NOT use similar control-flow patterns\n",
    "6. DO NOT use similar data structures\n",
    "7. Must solve a clearly different algorithmic problem\n",
    "8. Use basic concepts: simple loops, arrays, basic arithmetic\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem goal and output meaning required\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SOMETHING COMPLETELY DIFFERENT):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Different Program:\"\"\"\n",
    "\n",
    "HARD_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Create a sophisticated Java program that has similar structure but different semantics from the reference code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST have similar control flow patterns (similar if/else, loop structures)\n",
    "4. MUST have similar program skeleton and structure\n",
    "5. MUST solve a DIFFERENT semantic problem with DIFFERENT output meaning\n",
    "6. MUST NOT have behavioral equivalence with the reference code\n",
    "7. Use advanced concepts: collections, recursion, object-oriented design\n",
    "8. High structural similarity but different algorithmic goal required\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem domain but similar complexity\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SIMILAR STRUCTURE, DIFFERENT SEMANTICS):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Structurally Similar Program:\"\"\"\n",
    "\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Prompt templates defined (including non-clone templates)\")\n",
    "print(f\"{Fore.CYAN}  Clone templates: Type-1, Type-2, Type-3, Type-4\")\n",
    "print(f\"{Fore.CYAN}  Non-clone templates: Easy, Hard\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prompt templates defined (including non-clone templates)\n",
      "  Clone templates: Type-1, Type-2, Type-3, Type-4\n",
      "  Non-clone templates: Easy, Hard\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "3d773ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:01.164094Z",
     "start_time": "2025-12-16T09:13:01.145833Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "CodeNet data loading functions\n",
    "\"\"\"\n",
    "\n",
    "def list_problems():\n",
    "    \"\"\"List all available problem directories in CodeNet.\"\"\"\n",
    "    if not RAW_CODENET_DIR.exists():\n",
    "        log(f\"CodeNet directory not found: {RAW_CODENET_DIR}\", Fore.RED)\n",
    "        return []\n",
    "    \n",
    "    problems = []\n",
    "    for item in RAW_CODENET_DIR.iterdir():\n",
    "        if item.is_dir() and item.name.startswith('p') and len(item.name) == 6 and item.name[1:].isdigit():\n",
    "            problems.append(item.name)\n",
    "    \n",
    "    return sorted(problems)\n",
    "\n",
    "def load_submissions_csv(problem_id):\n",
    "    \"\"\"Load metadata CSV for a problem.\"\"\"\n",
    "    csv_path = METADATA_DIR / f\"{problem_id}.csv\"\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log(f\"Error reading CSV {csv_path}: {e}\", Fore.RED)\n",
    "        return None\n",
    "\n",
    "def choose_seed(problem_id):\n",
    "    \"\"\"Select a seed Java submission from the problem.\"\"\"\n",
    "    df = load_submissions_csv(problem_id)\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        return None, None\n",
    "    \n",
    "    java_accepted = df[\n",
    "        (df['language'] == 'Java') &\n",
    "        (df['status'] == 'Accepted')\n",
    "    ]\n",
    "    \n",
    "    if java_accepted.empty:\n",
    "        return None, None\n",
    "    \n",
    "    for _, row in java_accepted.iterrows():\n",
    "        submission_id = row['submission_id']\n",
    "        java_path = RAW_CODENET_DIR / problem_id / \"Java\" / f\"{submission_id}.java\"\n",
    "        \n",
    "        if not java_path.exists():\n",
    "            continue\n",
    "        \n",
    "        if java_path.stat().st_size > 10240:  # 10KB limit\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            code = java_path.read_text(encoding='utf-8')\n",
    "            return code, submission_id\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def load_testcases(problem_id):\n",
    "    \"\"\"Load input/output testcases for a problem.\"\"\"\n",
    "    testcases_dir = CODENET_ROOT / \"derived\" / \"input_output\" / \"data\" / problem_id\n",
    "    \n",
    "    input_file = testcases_dir / \"input.txt\"\n",
    "    output_file = testcases_dir / \"output.txt\"\n",
    "    \n",
    "    if not input_file.exists() or not output_file.exists():\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        input_text = input_file.read_text(encoding='utf-8')\n",
    "        output_text = output_file.read_text(encoding='utf-8')\n",
    "        return [(input_text, output_text)]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ CodeNet loading functions defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CodeNet loading functions defined\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "171eb097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:01.212812Z",
     "start_time": "2025-12-16T09:13:01.181473Z"
    }
   },
   "source": [
    "def log(message, color=Fore.WHITE):\n",
    "    \"\"\"Simple logger function.\"\"\"\n",
    "    try:\n",
    "        print(f\"{color}{message}{Style.RESET_ALL}\")\n",
    "    except Exception:\n",
    "        print(message)\n",
    "\n",
    "def ask_model_ollama(prompt, model_name, max_tokens=1500, temperature=0.1, max_retries=3):\n",
    "    import time as _time\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": max_tokens\n",
    "        },\n",
    "        \"keep_alive\": \"5m\"  # Keep model loaded for 5 minutes after last use\n",
    "    }\n",
    "    backoff = 2\n",
    "    consecutive_timeouts = 0\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, timeout=300)  # Increased timeout\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                generated_text = result.get(\"response\", \"\")\n",
    "                consecutive_timeouts = 0\n",
    "                return generated_text, None\n",
    "            else:\n",
    "                error_msg = f\"Ollama API error: HTTP {response.status_code}\"\n",
    "                return None, error_msg\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            return None, \"Cannot connect to Ollama. Is it running? (ollama serve)\"\n",
    "        except requests.exceptions.Timeout:\n",
    "            consecutive_timeouts += 1\n",
    "            if attempt < max_retries - 1:\n",
    "                log(f\"[MODEL ERROR] Ollama API timeout (attempt {attempt+1}/{max_retries}), retrying in {backoff}s...\", Fore.YELLOW)\n",
    "                _time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "                # Cool-down after 3 consecutive timeouts\n",
    "                if consecutive_timeouts >= 3:\n",
    "                    log(f\"[MODEL ERROR] 3 consecutive timeouts. Cooling down for 60 seconds...\", Fore.YELLOW)\n",
    "                    _time.sleep(60)\n",
    "                    consecutive_timeouts = 0\n",
    "                continue\n",
    "            else:\n",
    "                return None, \"Ollama API timeout\"\n",
    "        except Exception as e:\n",
    "            return None, f\"Ollama API error: {str(e)}\"\n",
    "\n",
    "def quick_check_code_quality(code_str):\n",
    "    \"\"\"Check code quality without compilation.\"\"\"\n",
    "    if not code_str or len(code_str) < 50:\n",
    "        return False, \"Code too short\"\n",
    "    \n",
    "    if \"class Main\" not in code_str:\n",
    "        return False, \"Missing 'class Main'\"\n",
    "    \n",
    "    if \"main(\" not in code_str:\n",
    "        return False, \"Missing main method\"\n",
    "    \n",
    "    # Check for suspicious patterns\n",
    "    suspicious = [\n",
    "        \"TODO:\", \"FIXME:\", \"[Your code here]\", \"// ... rest of\",\n",
    "        \"// Original code\", \"// Explanation:\", \"Note that\", \n",
    "        \"< begin of sentence >\", \"<begin of sentence>\",\n",
    "        \"< end of sentence >\", \"<end of sentence>\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in suspicious:\n",
    "        if pattern in code_str:\n",
    "            return False, f\"Contains suspicious pattern: {pattern}\"\n",
    "    \n",
    "    # Check basic syntax balance - Relaxed to avoid false positives on generics or bitwise ops\n",
    "    if code_str.count('{') != code_str.count('}'):\n",
    "        return False, \"Unbalanced braces\"\n",
    "    \n",
    "    if code_str.count('(') != code_str.count(')'):\n",
    "        return False, \"Unbalanced parentheses\"\n",
    "    \n",
    "    # Check for incomplete statements\n",
    "    trimmed = code_str.strip()\n",
    "    if trimmed and trimmed[-1] not in ['}', ';', '*', '/']:\n",
    "        return False, \"Code appears incomplete\"\n",
    "    \n",
    "    return True, \"OK\"\n",
    "\n",
    "# [REMAINING VALIDATION FUNCTIONS KEPT AS IS]\n",
    "def compile_java(temp_dir):\n",
    "    \"\"\"Compile Main.java in temp_dir.\"\"\"\n",
    "    java_file = Path(temp_dir) / \"Main.java\"\n",
    "    \n",
    "    if not java_file.exists():\n",
    "        return False, \"Main.java not found\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"javac\", str(java_file)],\n",
    "            cwd=temp_dir,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=30,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return False, f\"Compilation error: {error[:500]}\"\n",
    "        \n",
    "        return True, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Compilation timeout\"\n",
    "    except FileNotFoundError:\n",
    "        return False, \"javac not found. Please install JDK.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Compilation exception: {str(e)}\"\n",
    "\n",
    "def run_java_with_input(temp_dir, input_str, timeout=3):\n",
    "    \"\"\"Run compiled Java program with given input.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"java\", \"Main\"],\n",
    "            cwd=temp_dir,\n",
    "            input=input_str.encode('utf-8'),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return None, f\"Runtime error: {error[:500]}\"\n",
    "        \n",
    "        output = result.stdout.decode('utf-8', errors='ignore')\n",
    "        return output, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, \"Execution timeout\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Execution exception: {str(e)}\"\n",
    "\n",
    "def normalize_output(text):\n",
    "    \"\"\"Normalize output text.\"\"\"\n",
    "    lines = text.strip().split('\\n')\n",
    "    return '\\n'.join(line.rstrip() for line in lines)\n",
    "\n",
    "def validate_java(code_str, problem_id):\n",
    "    \"\"\"Validate Java code by compiling and running against testcases.\"\"\"\n",
    "    testcases = load_testcases(problem_id)\n",
    "    \n",
    "    if not testcases:\n",
    "        return \"no_tests\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        java_file = Path(temp_dir) / \"Main.java\"\n",
    "        \n",
    "        try:\n",
    "            java_file.write_text(code_str, encoding='utf-8')\n",
    "        except Exception:\n",
    "            return \"compile_error\"\n",
    "        \n",
    "        compile_success, compile_error = compile_java(temp_dir)\n",
    "        \n",
    "        if not compile_success:\n",
    "            return f\"compile_error: {compile_error}\" # Enhanced return to include error message\n",
    "        \n",
    "        for idx, (input_text, expected_output) in enumerate(testcases):\n",
    "            output, error = run_java_with_input(temp_dir, input_text, timeout=TIMEOUT_SECONDS)\n",
    "            \n",
    "            if error:\n",
    "                if \"timeout\" in error.lower():\n",
    "                    return \"timeout\"\n",
    "                else:\n",
    "                    return f\"runtime_error: {error}\" # Enhanced return\n",
    "            \n",
    "            norm_output = normalize_output(output)\n",
    "            norm_expected = normalize_output(expected_output)\n",
    "            \n",
    "            if norm_output != norm_expected:\n",
    "                return \"wrong_answer\"\n",
    "        \n",
    "        return \"passed\"\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Java validation functions defined (Updated checks and error reporting)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Java validation functions defined (Updated checks and error reporting)\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "id": "5439af73",
   "metadata": {},
   "source": [
    "## 2. Model Selection Logic\n",
    "Define the hybrid model selection strategy based on clone type complexity."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3530907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:03.386596Z",
     "start_time": "2025-12-16T09:13:01.227905Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Check Ollama connectivity before starting generation\n",
    "\"\"\"\n",
    "\n",
    "def check_ollama_connection():\n",
    "    \"\"\"Check if Ollama is running and accessible.\"\"\"\n",
    "    url = \"http://localhost:11434/api/tags\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get('models', [])\n",
    "            model_names = [m.get('name', '') for m in models]\n",
    "            return True, model_names\n",
    "        else:\n",
    "            return False, []\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return False, []\n",
    "    except Exception as e:\n",
    "        return False, []\n",
    "\n",
    "# Check Ollama connection\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Checking Ollama Connection...\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "is_connected, available_models = check_ollama_connection()\n",
    "\n",
    "if is_connected:\n",
    "    print(f\"{Fore.GREEN}✓ Ollama is running and accessible\")\n",
    "    print(f\"\\n{Fore.CYAN}Available models:\")\n",
    "    for model in available_models:\n",
    "        print(f\"  • {model}\")\n",
    "    \n",
    "    # Check if required models are available\n",
    "    required_models = [EASY_MODEL, HARD_MODEL]\n",
    "    missing_models = []\n",
    "    \n",
    "    for req_model in set(required_models):  # Use set to avoid duplicates\n",
    "        if not any(req_model in available for available in available_models):\n",
    "            missing_models.append(req_model)\n",
    "    \n",
    "    if missing_models:\n",
    "        print(f\"\\n{Fore.YELLOW}⚠ Warning: Required models not found:\")\n",
    "        for model in missing_models:\n",
    "            print(f\"  • {model}\")\n",
    "        print(f\"\\n{Fore.CYAN}To download missing models, run:\")\n",
    "        for model in missing_models:\n",
    "            print(f\"  ollama pull {model}\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}✓ All required models are available\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ Cannot connect to Ollama\")\n",
    "    print(f\"\\n{Fore.YELLOW}Please ensure Ollama is running:\")\n",
    "    print(f\"  1. Open a new terminal\")\n",
    "    print(f\"  2. Run: ollama serve\")\n",
    "    print(f\"  3. Then re-run this notebook\")\n",
    "    print(f\"\\n{Fore.CYAN}If you don't have Ollama installed:\")\n",
    "    print(f\"  Visit: https://ollama.ai/download\")\n",
    "    \n",
    "    raise RuntimeError(\"Ollama is not running. Please start Ollama and try again.\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}✓ Pre-flight checks complete!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Checking Ollama Connection...\n",
      "============================================================\n",
      "\n",
      "✓ Ollama is running and accessible\n",
      "\n",
      "Available models:\n",
      "  • codegemma:7b\n",
      "  • qwen2.5-coder:14b\n",
      "  • deepseek-coder:6.7b\n",
      "  • qwen2.5-coder:7b\n",
      "  • qwen2.5-coder:0.5b\n",
      "  • starcoder:1b\n",
      "  • codegemma:2b\n",
      "\n",
      "✓ All required models are available\n",
      "\n",
      "✓ Pre-flight checks complete!\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "b95a97f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:03.487919Z",
     "start_time": "2025-12-16T09:13:03.461920Z"
    }
   },
   "source": [
    "REPAIR_PROMPT_TEMPLATE = \"\"\"You are a Java code repair assistant. The following Java code has errors. Fix the validation errors and output the corrected code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "Rules:\n",
    "1. MUST have class name as \"Main\"\n",
    "2. Fix SPECIFICALLY the error reported below\n",
    "3. Preserve the original logic as much as possible\n",
    "4. Output raw Java code ONLY\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Validation Error:\n",
    "<<<ERROR_PLACEHOLDER>>>\n",
    "\n",
    "Fixed Code:\"\"\"\n",
    "\n",
    "def get_model_for_clone_type(clone_type):\n",
    "    \"\"\"\n",
    "    Return the appropriate model based on clone type complexity.\n",
    "    \n",
    "    Easy types (Type-1, Type-2): Use qwen2.5-coder:7b\n",
    "    Hard types (Type-3, Type-4): Use qwen2.5-coder:7b\n",
    "    \"\"\"\n",
    "    if clone_type in ['type1', 'type2']:\n",
    "        return EASY_MODEL\n",
    "    elif clone_type in ['type3', 'type4']:\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        # Default to hard model for unknown types\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_with_repair(prompt, model_name, problem_id=None, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate code with a repair loop. \n",
    "    If validation fails, ask the model to fix it using the error message.\n",
    "    Handles API timeouts with retry logic.\n",
    "    \"\"\"\n",
    "    # 1. Initial Generation\n",
    "    temperatures = [0.1, 0.3, 0.5]\n",
    "    best_candidate = None\n",
    "    for attempt in range(2): # 2 attempts at initial generation\n",
    "        temp = temperatures[min(attempt, len(temperatures) - 1)]\n",
    "        raw, error = ask_model_ollama(prompt, model_name, max_tokens=1500, temperature=temp, max_retries=3)\n",
    "        if error:\n",
    "            log(f\"[MODEL ERROR] {error}\", Fore.RED)\n",
    "            if \"timeout\" in str(error).lower():\n",
    "                log(f\"[MODEL ERROR] Ollama API timeout after retries. Skipping this attempt.\", Fore.RED)\n",
    "            continue\n",
    "        code = sanitize_code_from_model(raw)\n",
    "        if not code:\n",
    "            continue\n",
    "        # Quick check\n",
    "        valid_syntax, reason = quick_check_code_quality(code)\n",
    "        if not valid_syntax:\n",
    "            print(f\"  {Fore.YELLOW}Syntax check failed: {reason}\")\n",
    "            error_msg = f\"Syntax error: {reason}\"\n",
    "        else:\n",
    "            if problem_id:\n",
    "                result = validate_java(code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    return code # Success!\n",
    "                else:\n",
    "                    error_msg = result\n",
    "            else:\n",
    "                return code # No problem ID to validate against, so return code\n",
    "        print(f\"  {Fore.YELLOW}Attempting repair for error: {error_msg}\")\n",
    "        current_code = code\n",
    "        for repair_attempt in range(2): # 2 repair attempts\n",
    "            repair_prompt = REPAIR_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", current_code).replace(\"<<<ERROR_PLACEHOLDER>>>\", str(error_msg))\n",
    "            repair_model = HARD_MODEL\n",
    "            raw_repair, err = ask_model_ollama(repair_prompt, repair_model, max_tokens=1500, temperature=0.1, max_retries=3)\n",
    "            if err:\n",
    "                log(f\"[MODEL ERROR] {err}\", Fore.RED)\n",
    "                if \"timeout\" in str(err).lower():\n",
    "                    log(f\"[MODEL ERROR] Ollama API timeout during repair after retries. Skipping this repair attempt.\", Fore.RED)\n",
    "                break\n",
    "            repaired_code = sanitize_code_from_model(raw_repair)\n",
    "            if not repaired_code:\n",
    "                continue\n",
    "            valid_syntax, reason = quick_check_code_quality(repaired_code)\n",
    "            if not valid_syntax:\n",
    "                error_msg = f\"Syntax error after repair: {reason}\"\n",
    "                current_code = repaired_code\n",
    "                continue\n",
    "            if problem_id:\n",
    "                result = validate_java(repaired_code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    print(f\"  {Fore.GREEN}Repair successful!\")\n",
    "                    return repaired_code\n",
    "                else:\n",
    "                    error_msg = result\n",
    "                    current_code = repaired_code\n",
    "            else:\n",
    "                return repaired_code\n",
    "    return None\n",
    "\n",
    "def generate_clone_v2(code, clone_type, problem_id):\n",
    "    if clone_type == 'type1':\n",
    "        prompt = TYPE1_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type2':\n",
    "        prompt = TYPE2_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type3':\n",
    "        prompt = TYPE3_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type4':\n",
    "        prompt = TYPE4_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_clone_type(clone_type)\n",
    "\n",
    "    # For Type-3 clones, we need to validate that it's actually Type-3 and not Type-1\n",
    "    if clone_type == 'type3':\n",
    "        # Try multiple times to get a proper Type-3 clone\n",
    "        for attempt in range(5):  # 5 attempts for Type-3\n",
    "            generated_code = generate_with_repair(prompt, model, problem_id)\n",
    "\n",
    "            if not generated_code:\n",
    "                continue\n",
    "\n",
    "            # Validate that this is actually a Type-3 clone\n",
    "            is_type3, reason = validate_type3_clone(code, generated_code)\n",
    "\n",
    "            if is_type3:\n",
    "                print(f\"  {Fore.GREEN}✓ Type-3 validation passed: {reason}\")\n",
    "                return generated_code\n",
    "            else:\n",
    "                print(f\"  {Fore.YELLOW}⚠ Type-3 validation failed (attempt {attempt + 1}): {reason}\")\n",
    "                # Try again with modified prompt to be more explicit\n",
    "                if attempt < 4:  # Don't modify on last attempt\n",
    "                    enhanced_prompt = prompt + f\"\\n\\nIMPORTANT: The previous attempt was rejected because: {reason}\\nMake MORE SIGNIFICANT structural changes. Remember: You MUST do at least 3 major modifications from the requirements list.\"\n",
    "                    prompt = enhanced_prompt\n",
    "\n",
    "        # If all attempts failed, return None\n",
    "        print(f\"  {Fore.RED}✗ Failed to generate proper Type-3 clone after 5 attempts\")\n",
    "        return None\n",
    "    else:\n",
    "        # For other types, use normal generation\n",
    "        return generate_with_repair(prompt, model, problem_id)\n",
    "\n",
    "def get_model_for_nonclone_type(nonclone_type):\n",
    "    if nonclone_type == 'easy':\n",
    "        return EASY_MODEL\n",
    "    elif nonclone_type == 'hard':\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_nonclone_v2(code, nonclone_type, problem_id=None):\n",
    "    if nonclone_type == 'easy':\n",
    "        prompt = EASY_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif nonclone_type == 'hard':\n",
    "        prompt = HARD_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_nonclone_type(nonclone_type)\n",
    "    # For non-clones, we just check compilation/sanity, we can't check 'passed' against original tests\n",
    "    # because the problem is DIFFERENT. So passing problem_id might be misleading if used for test validation.\n",
    "    # However, generate_with_repair uses problem_id to run tests.\n",
    "    # For non-clones, we should probably pass None for problem_id to skip testcase validation inside the repair loop,\n",
    "    # OR update generate_with_repair to handle 'compile_only' mode.\n",
    "    \n",
    "    return generate_with_repair(prompt, model, problem_id=None) \n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Model selection logic & Repair loop defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model selection logic & Repair loop defined\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:03.523268Z",
     "start_time": "2025-12-16T09:13:03.496207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_clones_for_types(clone_types, output_path, target_per_type):\n",
    "    import json\n",
    "    # Resume logic: collect already generated (problem_id, clone_type) pairs\n",
    "    existing_pairs = set()\n",
    "    if output_path.exists():\n",
    "        try:\n",
    "            with open(output_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        record = json.loads(line)\n",
    "                        pid = record.get('problem_id')\n",
    "                        ctype = record.get('clone_type')\n",
    "                        if pid and ctype:\n",
    "                            existing_pairs.add((pid, ctype))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='a', flush=True)  # append mode\n",
    "\n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED}✗ No problems found in CodeNet directory\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "    \n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "    \n",
    "    clone_counters = {ct: 0 for ct in clone_types}\n",
    "    # Count already generated clones for each type\n",
    "    for (pid, ctype) in existing_pairs:\n",
    "        if ctype in clone_counters:\n",
    "            clone_counters[ctype] += 1\n",
    "\n",
    "    stats = {\n",
    "        'no_seed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'failed': 0\n",
    "    }\n",
    "    \n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "    \n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(clone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(clone_types)}\") as pbar:\n",
    "        # Set progress bar to already completed\n",
    "        completed = sum(clone_counters.values())\n",
    "        if completed > 0:\n",
    "            pbar.update(completed)\n",
    "        while any(clone_counters[ct] < target_per_type for ct in clone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "\n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "\n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "\n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "\n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Load testcases\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\" # Normalize for check\n",
    "\n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Generate clones for this problem\n",
    "                clones_generated_this_problem = 0\n",
    "\n",
    "                # Generate each type of clone\n",
    "                for clone_type in clone_types:\n",
    "                    if clone_counters[clone_type] >= target_per_type:\n",
    "                        continue\n",
    "\n",
    "                    if clones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "\n",
    "                    # Skip Type-4 for complex files\n",
    "                    if clone_type == 'type4' and len(seed_code.split('\\n')) >= 75:\n",
    "                        continue\n",
    "\n",
    "                    # SKIP if already generated for this (problem_id, clone_type)\n",
    "                    if (problem_id, clone_type) in existing_pairs:\n",
    "                        continue\n",
    "\n",
    "                    # Generate clone\n",
    "                    try:\n",
    "                        # UPDATED CALL: Pass problem_id for repair loop\n",
    "                        generated_code = generate_clone_v2(seed_code, clone_type, problem_id)\n",
    "\n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # Already validated inside generate_clone_v2 (mostly), but double check if returned\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        result = validate_java(generated_code, problem_id)\n",
    "\n",
    "                        if result == \"passed\":\n",
    "                            pair_id = f\"{problem_id}_{clone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "                            record = {\n",
    "                                'id': pair_id,\n",
    "                                'code_1': seed_code,\n",
    "                                'code_2': generated_code,\n",
    "                                'label': \"clone\",\n",
    "                                'clone_type': clone_type,\n",
    "                                'language': 'Java',\n",
    "                                'problem_id': problem_id,\n",
    "                                'generator': get_model_for_clone_type(clone_type),\n",
    "                                'timestamp': time.time()\n",
    "                            }\n",
    "\n",
    "                            dataset_writer.write(record)\n",
    "                            clone_counters[clone_type] += 1\n",
    "                            clones_generated_this_problem += 1\n",
    "                            pbar.update(1)\n",
    "                            # Add to existing_pairs to prevent duplicate in same run\n",
    "                            existing_pairs.add((problem_id, clone_type))\n",
    "                        else:\n",
    "                            stats['failed'] += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        log(f\"[{problem_id}] {clone_type} error: {repr(e)}\", Fore.RED)\n",
    "\n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for ct, count in clone_counters.items():\n",
    "                        status = \"✓\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {ct}: {status}\")\n",
    "                    print()\n",
    "\n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "\n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "\n",
    "    return clone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Core generation function defined (Updated with repair loop)\")"
   ],
   "id": "21ece64b9b03739e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Core generation function defined (Updated with repair loop)\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Generate Easy Clones (Type-1 and Type-2)\n",
    "Use the fast `codegemma:2b` model to generate Type-1 and Type-2 clones efficiently."
   ],
   "id": "677cdffefc29a06c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T09:13:51.129725Z",
     "start_time": "2025-12-16T09:13:03.532219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 1: Generate Easy Clones (Type-1 and Type-2) using qwen2.5-coder:7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 1: Generating Easy Clones (Type-1, Type-2)\")\n",
    "print(f\"{Fore.CYAN}Model: {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {EASY_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "easy_counters, easy_stats = generate_clones_for_types(\n",
    "    clone_types=['type1', 'type2'],\n",
    "    output_path=EASY_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ EASY CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_easy = 0\n",
    "for clone_type, count in easy_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_easy += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total easy clones: {total_easy}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {easy_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {easy_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {easy_stats['failed']}\")"
   ],
   "id": "86197a952d0e2c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: Generating Easy Clones (Type-1, Type-2)\n",
      "Model: qwen2.5-coder:7b\n",
      "Output: dataset\\java_clones_easy_types.jsonl\n",
      "============================================================\n",
      "\n",
      "Found 4053 problems in CodeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating type1, type2: 204it [00:00, 2222436.41it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ EASY CLONES GENERATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Clone Counts:\n",
      "  type1: 102/100 ✓ COMPLETE\n",
      "  type2: 102/100 ✓ COMPLETE\n",
      "\n",
      "Total easy clones: 204\n",
      "Time taken: 0.79 minutes\n",
      "Dataset saved to: dataset\\java_clones_easy_types.jsonl\n",
      "\n",
      "Statistics:\n",
      "  No seed found: 0\n",
      "  Seed validation failed: 0\n",
      "  Generation/validation failed: 0\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Generate Hard Clones (Type-3 and Type-4)\n",
    "Use the more capable `qwen2.5-coder:7b` model to generate complex Type-3 and Type-4 clones.\n",
    "\n",
    "**Note:** This step will be significantly slower due to the larger model, but it ensures correct semantic transformations."
   ],
   "id": "5b9b326498558d30"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-16T09:13:51.173279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Step 2: Generate Hard Clones (Type-3 and Type-4) using qwen2.5-coder:7b\n",
    "\"\"\"\n",
    "\n",
    "def validate_type3_clone(original_code, generated_code):\n",
    "    \"\"\"\n",
    "    Validates if generated_code is a type-3 clone of original_code.\n",
    "    Type-3 clones are syntactically similar with some modifications (e.g., added/removed statements, reordered code),\n",
    "    but not identical (not type-1) and not just renamed (not type-2).\n",
    "    Returns (is_type3: bool, reason: str)\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    def normalize_code(code):\n",
    "        # Remove comments\n",
    "        code = re.sub(r\"//.*?$|/\\*.*?\\*/\", \"\", code, flags=re.DOTALL | re.MULTILINE)\n",
    "        # Remove whitespace and blank lines\n",
    "        code = '\\n'.join([line.strip() for line in code.splitlines() if line.strip()])\n",
    "        return code\n",
    "\n",
    "    norm_orig = normalize_code(original_code)\n",
    "    norm_gen = normalize_code(generated_code)\n",
    "\n",
    "    # If identical, not type-3\n",
    "    if norm_orig == norm_gen:\n",
    "        return False, \"Identical code (type-1)\"\n",
    "\n",
    "    # Compute similarity ratio\n",
    "    ratio = SequenceMatcher(None, norm_orig, norm_gen).ratio()\n",
    "    if ratio > 0.6:\n",
    "        return True, f\"Syntactically similar (ratio={ratio:.2f})\"\n",
    "    else:\n",
    "        return False, f\"Not similar enough (ratio={ratio:.2f})\"\n",
    "\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 2: Generating Hard Clones (Type-3, Type-4)\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_counters, hard_stats = generate_clones_for_types(\n",
    "    clone_types=['type3', 'type4'],\n",
    "    output_path=HARD_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ HARD CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_hard = 0\n",
    "for clone_type, count in hard_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_hard += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard clones: {total_hard}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_stats['failed']}\")"
   ],
   "id": "845d8538541698e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: Generating Hard Clones (Type-3, Type-4)\n",
      "Model: qwen2.5-coder:7b\n",
      "Output: dataset\\java_clones_hard_types.jsonl\n",
      "============================================================\n",
      "\n",
      "Found 4053 problems in CodeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating type3, type4:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Combine Datasets\n",
    "Merge the easy and hard clone datasets into a single comprehensive dataset."
   ],
   "id": "c83ffc5beba8cc0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Step 3: Combine Easy and Hard Clone Datasets\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 3: Combining Datasets\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read both datasets\n",
    "easy_records = []\n",
    "hard_records = []\n",
    "\n",
    "if EASY_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_OUTPUT_PATH) as reader:\n",
    "        easy_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(easy_records)} records from {EASY_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Easy clones file not found: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_OUTPUT_PATH) as reader:\n",
    "        hard_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(hard_records)} records from {HARD_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Hard clones file not found: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine records\n",
    "all_records = easy_records + hard_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_records)}\")\n",
    "\n",
    "# Write combined dataset\n",
    "with jsonlines.open(COMBINED_OUTPUT_PATH, mode='w') as writer:\n",
    "    for record in all_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Combined dataset written to: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "# Count by type\n",
    "type_counts = {}\n",
    "for record in all_records:\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Clone Type:\")\n",
    "for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "    count = type_counts.get(clone_type, 0)\n",
    "    print(f\"  {clone_type}: {count}\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ DATASET COMBINATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")"
   ],
   "id": "16815b44b712ba86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Validate Combined Dataset\n",
    "Perform validation and quality checks on the final combined dataset."
   ],
   "id": "29c2af517858cb61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Step 4: Validate the Combined Dataset\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 4: Dataset Validation\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Load combined dataset\n",
    "combined_records = []\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        combined_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(combined_records)} records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ Combined dataset not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if combined_records:\n",
    "    # Validation checks\n",
    "    print(f\"\\n{Fore.CYAN}Validation Checks:\")\n",
    "\n",
    "    # 1. Check all clone types are present\n",
    "    type_distribution = {}\n",
    "    model_distribution = {}\n",
    "\n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', 'unknown')\n",
    "        model = record.get('generator', 'unknown')\n",
    "\n",
    "        type_distribution[clone_type] = type_distribution.get(clone_type, 0) + 1\n",
    "        model_distribution[model] = model_distribution.get(model, 0) + 1\n",
    "\n",
    "    print(f\"\\n{Fore.CYAN}1. Clone Type Distribution:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        status = \"✓\" if count > 0 else \"✗\"\n",
    "        print(f\"  {status} {clone_type}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    print(f\"\\n{Fore.CYAN}2. Model Distribution:\")\n",
    "    for model, count in model_distribution.items():\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        print(f\"  {model}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    # 3. Verify model assignment correctness\n",
    "    print(f\"\\n{Fore.CYAN}3. Model Assignment Verification:\")\n",
    "    correct_assignments = 0\n",
    "    incorrect_assignments = 0\n",
    "\n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', '')\n",
    "        model = record.get('generator', '')\n",
    "        expected_model = get_model_for_clone_type(clone_type)\n",
    "\n",
    "        if model == expected_model:\n",
    "            correct_assignments += 1\n",
    "        else:\n",
    "            incorrect_assignments += 1\n",
    "\n",
    "    if incorrect_assignments == 0:\n",
    "        print(f\"  ✓ All {correct_assignments} records have correct model assignments\")\n",
    "    else:\n",
    "        print(f\"  ⚠ {correct_assignments} correct, {incorrect_assignments} incorrect\")\n",
    "\n",
    "    # 4. Check for required fields\n",
    "    print(f\"\\n{Fore.CYAN}4. Required Fields Check:\")\n",
    "    required_fields = ['id', 'code_1', 'code_2', 'label', 'clone_type', 'language', 'problem_id', 'generator']\n",
    "\n",
    "    missing_fields = {}\n",
    "    for record in combined_records:\n",
    "        for field in required_fields:\n",
    "            if field not in record or not record[field]:\n",
    "                missing_fields[field] = missing_fields.get(field, 0) + 1\n",
    "\n",
    "    if not missing_fields:\n",
    "        print(f\"  ✓ All records have all required fields\")\n",
    "    else:\n",
    "        for field, count in missing_fields.items():\n",
    "            print(f\"  ⚠ {field}: missing in {count} records\")\n",
    "\n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.GREEN}FINAL DATASET SUMMARY\")\n",
    "    print(f\"{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.CYAN}Total Records: {len(combined_records)}\")\n",
    "    print(f\"{Fore.CYAN}Dataset Path: {COMBINED_OUTPUT_PATH}\")\n",
    "    print(f\"{Fore.CYAN}File Size: {COMBINED_OUTPUT_PATH.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "    print(f\"\\n{Fore.CYAN}Clone Type Breakdown:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE}\")\n",
    "\n",
    "    print(f\"\\n{Fore.GREEN}✓ Validation Complete!\")\n",
    "else:\n",
    "    print(f\"{Fore.RED}✗ No records found for validation\")"
   ],
   "id": "c255b61bdca6dd7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Generate Easy Non-Clones\n",
    "Use the fast `codegemma:2b` model to generate easy non-clones with simple algorithmic differences."
   ],
   "id": "d6589d46e6d69124"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_nonclones_for_types(nonclone_types, output_path, target_per_type):\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='w', flush=True)\n",
    "\n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED}✗ No problems found in CodeNet directory\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "\n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "\n",
    "    # Non-clone counters\n",
    "    nonclone_counters = {nt: 0 for nt in nonclone_types}\n",
    "\n",
    "    stats = {\n",
    "        'failed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'no_seed': 0,\n",
    "        'identical_skipped': 0\n",
    "    }\n",
    "\n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "\n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(nonclone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(nonclone_types)} non-clones\") as pbar:\n",
    "        while any(nonclone_counters[nt] < target_per_type for nt in nonclone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "\n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "\n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "\n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "\n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Load testcases (for validation of generated code)\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\"\n",
    "\n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Generate non-clones for this problem\n",
    "                nonclones_generated_this_problem = 0\n",
    "\n",
    "                # Generate each type of non-clone\n",
    "                for nonclone_type in nonclone_types:\n",
    "                    if nonclone_counters[nonclone_type] >= target_per_type:\n",
    "                        continue\n",
    "\n",
    "                    if nonclones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "\n",
    "                    # Generate non-clone\n",
    "                    try:\n",
    "                        # UPDATED: Use v2 with None for problem_id (syntax repair only)\n",
    "                        generated_code = generate_nonclone_v2(seed_code, nonclone_type, problem_id=None)\n",
    "\n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # Quick quality check\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # For non-clones, we just need to check if it compiles and runs\n",
    "                        # (it doesn't need to pass the original test cases)\n",
    "                        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                            java_file = Path(temp_dir) / \"Main.java\"\n",
    "\n",
    "                            try:\n",
    "                                java_file.write_text(generated_code, encoding='utf-8')\n",
    "                                compile_success, compile_error = compile_java(temp_dir)\n",
    "\n",
    "                                if compile_success:\n",
    "                                    # Try to run it with empty input to see if it executes\n",
    "                                    output, error = run_java_with_input(temp_dir, \"\", timeout=5)\n",
    "\n",
    "                                    # As long as it compiles and doesn't crash, it's valid\n",
    "                                    if error is None or \"timeout\" not in error.lower():\n",
    "                                        pair_id = f\"{problem_id}_nonclone_{nonclone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "                                        record = {\n",
    "                                            'id': pair_id,\n",
    "                                            'code_1': seed_code,\n",
    "                                            'code_2': generated_code,\n",
    "                                            'label': \"non-clone\",\n",
    "                                            'clone_type': f\"nonclone_{nonclone_type}\",\n",
    "                                            'language': 'Java',\n",
    "                                            'problem_id': problem_id,\n",
    "                                            'generator': get_model_for_nonclone_type(nonclone_type),\n",
    "                                            'timestamp': time.time()\n",
    "                                        }\n",
    "\n",
    "                                        dataset_writer.write(record)\n",
    "                                        nonclone_counters[nonclone_type] += 1\n",
    "                                        nonclones_generated_this_problem += 1\n",
    "                                        pbar.update(1)\n",
    "                                    else:\n",
    "                                        stats['failed'] += 1\n",
    "                                else:\n",
    "                                    stats['failed'] += 1\n",
    "                            except Exception:\n",
    "                                stats['failed'] += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        # print(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\") # debug\n",
    "                        # log(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\", Fore.RED)\n",
    "\n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for nt, count in nonclone_counters.items():\n",
    "                        status = \"✓\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {nt} non-clones: {status}\")\n",
    "                    print()\n",
    "\n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                # log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "\n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "\n",
    "    return nonclone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Non-clone generation function defined\")"
   ],
   "id": "56cdf34b92c420da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Generate Hard Non-Clones\n",
    "Use the more capable `deepseek-coder:6.7b` model to generate hard non-clones with different problem domains."
   ],
   "id": "809b71c557303103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Step 6: Generate Hard Non-Clones using deepseek-coder:6.7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 6: Generating Hard Non-Clones\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_nonclone_counters, hard_nonclone_stats = generate_nonclones_for_types(\n",
    "    nonclone_types=['hard'],\n",
    "    output_path=HARD_NONCLONES_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_NONCLONES_HARD\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ HARD NON-CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Non-Clone Counts:\")\n",
    "total_hard_nonclones = 0\n",
    "for nonclone_type, count in hard_nonclone_counters.items():\n",
    "    status = \"✓ COMPLETE\" if count >= TARGET_NONCLONES_HARD else \"⚠ INCOMPLETE\"\n",
    "    print(f\"  {nonclone_type}: {count}/{TARGET_NONCLONES_HARD} {status}\")\n",
    "    total_hard_nonclones += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard non-clones: {total_hard_nonclones}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_nonclone_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_nonclone_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_nonclone_stats['failed']}\")"
   ],
   "id": "46f2afbf69aa09f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Create Complete Dataset\n",
    "Combine all clones and non-clones into a single comprehensive dataset for training."
   ],
   "id": "747fe23fdc8b5f96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Step 7: Create Complete Dataset (Clones + Non-Clones)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 7: Creating Complete Dataset\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read all datasets\n",
    "clone_records = []\n",
    "easy_nonclone_records = []\n",
    "hard_nonclone_records = []\n",
    "\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        clone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(clone_records)} clone records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Clone dataset file not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if EASY_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        easy_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(easy_nonclone_records)} easy non-clone records from {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Easy non-clones file not found: {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        hard_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN}✓ Loaded {len(hard_nonclone_records)} hard non-clone records from {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}⚠ Hard non-clones file not found: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine all records\n",
    "all_complete_records = clone_records + easy_nonclone_records + hard_nonclone_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_complete_records)}\")\n",
    "print(f\"  Clones: {len(clone_records)}\")\n",
    "print(f\"  Easy Non-clones: {len(easy_nonclone_records)}\")\n",
    "print(f\"  Hard Non-clones: {len(hard_nonclone_records)}\")\n",
    "\n",
    "# Write complete dataset\n",
    "with jsonlines.open(FINAL_DATASET_PATH, mode='w') as writer:\n",
    "    for record in all_complete_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN}✓ Complete dataset written to: {FINAL_DATASET_PATH}\")\n",
    "\n",
    "# Count by type and label\n",
    "label_counts = {}\n",
    "type_counts = {}\n",
    "for record in all_complete_records:\n",
    "    label = record.get('label', 'unknown')\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Label:\")\n",
    "for label in ['clone', 'non-clone']:\n",
    "    count = label_counts.get(label, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Type:\")\n",
    "for type_name in ['type1', 'type2', 'type3', 'type4', 'nonclone_easy', 'nonclone_hard']:\n",
    "    count = type_counts.get(type_name, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {type_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN}✓ COMPLETE DATASET CREATION FINISHED!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Final Dataset: {FINAL_DATASET_PATH}\")\n",
    "print(f\"{Fore.CYAN}Total Records: {len(all_complete_records)}\")\n",
    "print(f\"{Fore.CYAN}File Size: {FINAL_DATASET_PATH.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n"
   ],
   "id": "6949c2f364398e9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
