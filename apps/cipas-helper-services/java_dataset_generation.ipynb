{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6662a0b28eab0316",
   "metadata": {},
   "source": [
    "# Hybrid Model Code Clone Dataset Generator\n",
    "\n",
    "## Problem Statement\n",
    "The original script used a small model (`codegemma:2b`) for all clone types. While fast, this model lacks the capability to handle complex Type-3 and Type-4 semantic transformations, resulting in mislabeled clones.\n",
    "\n",
    "## Solution: Hybrid Approach\n",
    "- **Easy Clones (Type-1, Type-2)**: Use `qwen2.5-coder:7b` for fast, reliable generation\n",
    "- **Hard Clones (Type-3, Type-4)**: Use `qwen2.5-coder:7b` for accurate semantic transformations\n",
    "\n",
    "This notebook implements the complete hybrid workflow in a step-by-step manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce01722bc52179d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:16.681076Z",
     "start_time": "2025-12-16T08:43:10.897506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 0: Environment setup for Python 3.11, no ipywidgets, and progress bars disabled\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66209e78f671cf2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.016589Z",
     "start_time": "2025-12-16T08:43:16.694492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\dasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: transformers in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (4.57.2)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.49.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.1.3)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Using cached torch-2.9.1-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-22.0.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.2-cp311-cp311-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp311-cp311-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.5.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dasun\\appdata\\roaming\\python\\python311\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
      "  Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "Using cached sentencepiece-0.2.1-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "Using cached bitsandbytes-0.49.0-py3-none-win_amd64.whl (54.7 MB)\n",
      "Downloading torch-2.9.1-cp311-cp311-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/111.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.0/111.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.0/111.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.0/111.0 MB 5.0 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.3/111.0 MB 1.1 MB/s eta 0:01:40\n",
      "   ---------------------------------------- 1.3/111.0 MB 1.1 MB/s eta 0:01:40\n",
      "   ---------------------------------------- 1.3/111.0 MB 1.1 MB/s eta 0:01:40\n",
      "    --------------------------------------- 2.1/111.0 MB 1.1 MB/s eta 0:01:38\n",
      "   - -------------------------------------- 3.1/111.0 MB 1.6 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 3.1/111.0 MB 1.6 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 3.4/111.0 MB 1.4 MB/s eta 0:01:19\n",
      "   - -------------------------------------- 4.5/111.0 MB 1.7 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 4.5/111.0 MB 1.7 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 4.5/111.0 MB 1.7 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 4.7/111.0 MB 1.5 MB/s eta 0:01:13\n",
      "   - -------------------------------------- 5.2/111.0 MB 1.5 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 6.3/111.0 MB 1.8 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.3/111.0 MB 1.8 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.3/111.0 MB 1.8 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.3/111.0 MB 1.8 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.6/111.0 MB 1.5 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 7.6/111.0 MB 1.6 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 7.6/111.0 MB 1.6 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 7.6/111.0 MB 1.6 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 8.1/111.0 MB 1.5 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 8.9/111.0 MB 1.6 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 9.7/111.0 MB 1.7 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 10.0/111.0 MB 1.7 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 10.0/111.0 MB 1.7 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 10.0/111.0 MB 1.7 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 10.2/111.0 MB 1.6 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 10.7/111.0 MB 1.6 MB/s eta 0:01:04\n",
      "   ---- ----------------------------------- 11.3/111.0 MB 1.6 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 11.8/111.0 MB 1.6 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 12.1/111.0 MB 1.6 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 12.6/111.0 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 13.1/111.0 MB 1.7 MB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 13.6/111.0 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.2/111.0 MB 1.7 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 14.2/111.0 MB 1.7 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 14.4/111.0 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 14.7/111.0 MB 1.7 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 15.2/111.0 MB 1.7 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 15.7/111.0 MB 1.7 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 16.3/111.0 MB 1.7 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 16.5/111.0 MB 1.7 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 17.0/111.0 MB 1.7 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 17.6/111.0 MB 1.7 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 18.1/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 18.4/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 18.6/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 19.1/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 19.7/111.0 MB 1.7 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 19.9/111.0 MB 1.7 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 19.9/111.0 MB 1.7 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 20.2/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 20.4/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 20.7/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 21.2/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 21.5/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 21.8/111.0 MB 1.7 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 22.3/111.0 MB 1.7 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 22.8/111.0 MB 1.7 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 23.1/111.0 MB 1.7 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 23.1/111.0 MB 1.7 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 23.1/111.0 MB 1.7 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 23.3/111.0 MB 1.6 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 23.6/111.0 MB 1.6 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 23.9/111.0 MB 1.6 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 24.4/111.0 MB 1.6 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 24.6/111.0 MB 1.6 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 25.2/111.0 MB 1.6 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 25.4/111.0 MB 1.6 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 25.7/111.0 MB 1.6 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 26.0/111.0 MB 1.6 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 26.5/111.0 MB 1.6 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 26.7/111.0 MB 1.6 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 27.0/111.0 MB 1.6 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 27.5/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 27.8/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 28.3/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 28.3/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 28.6/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 28.8/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 29.1/111.0 MB 1.6 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 29.6/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 29.9/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 30.1/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 30.7/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 30.9/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 31.2/111.0 MB 1.6 MB/s eta 0:00:50\n",
      "   ----------- ---------------------------- 31.5/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 32.0/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 32.2/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 32.5/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 32.8/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 33.0/111.0 MB 1.6 MB/s eta 0:00:49\n",
      "   ------------ --------------------------- 33.6/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 33.8/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 34.1/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 34.3/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 34.6/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 35.1/111.0 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------ --------------------------- 35.4/111.0 MB 1.6 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 35.7/111.0 MB 1.6 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 35.9/111.0 MB 1.6 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 36.4/111.0 MB 1.6 MB/s eta 0:00:47\n",
      "   ------------- -------------------------- 36.7/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 37.0/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 37.2/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 37.5/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 37.7/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 38.0/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 38.3/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 38.5/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 38.5/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 38.8/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 39.1/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 39.3/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 39.3/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 39.6/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 39.8/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 40.1/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 40.4/111.0 MB 1.6 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 40.6/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 40.9/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 40.9/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 41.2/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   -------------- ------------------------- 41.4/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 41.7/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 41.9/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 42.2/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 42.5/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 42.7/111.0 MB 1.5 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 43.0/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 43.3/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 43.5/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 43.5/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 43.8/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 44.0/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 44.3/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 44.6/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 44.8/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 45.1/111.0 MB 1.5 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 45.6/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 45.9/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 45.9/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 45.9/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 46.1/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 46.4/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 46.7/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 47.2/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 47.4/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 47.7/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 48.0/111.0 MB 1.5 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 48.2/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 48.5/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 49.0/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 49.3/111.0 MB 1.5 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 49.5/111.0 MB 1.5 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 50.1/111.0 MB 1.5 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 50.3/111.0 MB 1.5 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 50.6/111.0 MB 1.5 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 50.6/111.0 MB 1.5 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 50.6/111.0 MB 1.5 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 50.9/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 50.9/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 51.4/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 51.6/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 51.9/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 52.4/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 52.4/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 52.4/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 52.7/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 53.0/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 53.2/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 53.7/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.0/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.3/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.5/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.5/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.5/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 54.8/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 55.1/111.0 MB 1.4 MB/s eta 0:00:42\n",
      "   ------------------- -------------------- 55.3/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 55.6/111.0 MB 1.4 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 55.8/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 56.1/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 56.6/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 56.9/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 57.1/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 57.4/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 57.4/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 57.4/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 57.7/111.0 MB 1.3 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 57.9/111.0 MB 1.3 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 58.2/111.0 MB 1.3 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 58.5/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 58.7/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.0/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.2/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.5/111.0 MB 1.3 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.8/111.0 MB 1.3 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 60.0/111.0 MB 1.3 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 60.3/111.0 MB 1.3 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 60.6/111.0 MB 1.3 MB/s eta 0:00:40\n",
      "   --------------------- ------------------ 60.8/111.0 MB 1.3 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 61.1/111.0 MB 1.3 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 61.3/111.0 MB 1.3 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 61.6/111.0 MB 1.3 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 61.9/111.0 MB 1.3 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 62.4/111.0 MB 1.3 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 62.7/111.0 MB 1.3 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 62.9/111.0 MB 1.3 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 63.2/111.0 MB 1.3 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 63.7/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 63.7/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.0/111.0 MB 1.3 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 64.2/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.5/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.7/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 65.0/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 65.3/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 65.5/111.0 MB 1.3 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 66.1/111.0 MB 1.3 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 66.3/111.0 MB 1.3 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 66.6/111.0 MB 1.3 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 67.1/111.0 MB 1.3 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.4/111.0 MB 1.3 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.9/111.0 MB 1.3 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 68.4/111.0 MB 1.3 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 68.7/111.0 MB 1.3 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 69.2/111.0 MB 1.3 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 69.7/111.0 MB 1.3 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 70.3/111.0 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 70.8/111.0 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 71.3/111.0 MB 1.3 MB/s eta 0:00:31\n",
      "   ------------------------- -------------- 71.8/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 71.8/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 72.1/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 72.1/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 72.6/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 73.1/111.0 MB 1.3 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 73.7/111.0 MB 1.3 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 74.2/111.0 MB 1.3 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 74.4/111.0 MB 1.3 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 75.0/111.0 MB 1.3 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 75.2/111.0 MB 1.3 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 75.8/111.0 MB 1.3 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 76.0/111.0 MB 1.3 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 76.5/111.0 MB 1.3 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 76.8/111.0 MB 1.3 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 77.3/111.0 MB 1.3 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 77.9/111.0 MB 1.3 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 78.4/111.0 MB 1.4 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 78.6/111.0 MB 1.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 79.2/111.0 MB 1.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 79.7/111.0 MB 1.4 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 79.7/111.0 MB 1.4 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 79.7/111.0 MB 1.4 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 80.2/111.0 MB 1.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 80.5/111.0 MB 1.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 81.0/111.0 MB 1.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 81.5/111.0 MB 1.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 81.8/111.0 MB 1.4 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 82.3/111.0 MB 1.4 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 82.8/111.0 MB 1.4 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 83.4/111.0 MB 1.4 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 83.6/111.0 MB 1.4 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 84.1/111.0 MB 1.4 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 84.4/111.0 MB 1.4 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 84.9/111.0 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 85.2/111.0 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 85.7/111.0 MB 1.5 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 86.2/111.0 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 86.8/111.0 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 87.0/111.0 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 87.6/111.0 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 88.1/111.0 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 88.3/111.0 MB 1.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 88.9/111.0 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 89.1/111.0 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 89.7/111.0 MB 1.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 89.9/111.0 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 90.4/111.0 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 90.7/111.0 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 91.2/111.0 MB 1.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 91.8/111.0 MB 1.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 92.3/111.0 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 92.5/111.0 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 93.1/111.0 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 93.6/111.0 MB 1.6 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 93.8/111.0 MB 1.6 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 94.4/111.0 MB 1.6 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 94.9/111.0 MB 1.6 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 95.4/111.0 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 95.9/111.0 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 96.5/111.0 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 97.0/111.0 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 97.5/111.0 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 97.8/111.0 MB 1.6 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 98.3/111.0 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 98.6/111.0 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 99.1/111.0 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 99.4/111.0 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 99.9/111.0 MB 1.7 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 100.4/111.0 MB 1.7 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 100.9/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 101.4/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 101.4/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 101.4/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 102.0/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 102.5/111.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.0/111.0 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 103.3/111.0 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 103.5/111.0 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 104.1/111.0 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 104.3/111.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 104.6/111.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 105.1/111.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 105.4/111.0 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 105.9/111.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 106.2/111.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 106.7/111.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 107.0/111.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 107.5/111.0 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 108.0/111.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  108.5/111.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  109.1/111.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  109.6/111.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.8/111.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.1/111.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.6/111.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 111.0/111.0 MB 1.8 MB/s  0:01:10\n",
      "Downloading aiohttp-3.13.2-cp311-cp311-win_amd64.whl (456 kB)\n",
      "Using cached multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/28.1 MB 2.1 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 1.3/28.1 MB 2.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.8/28.1 MB 2.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 2.4/28.1 MB 2.3 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 2.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 3.4/28.1 MB 2.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.5/28.1 MB 2.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 4.7/28.1 MB 2.1 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 5.2/28.1 MB 2.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.8/28.1 MB 2.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 6.3/28.1 MB 2.1 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.8/28.1 MB 2.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 2.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.6/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 8.1/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 8.4/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.9/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.2/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.7/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.2/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.5/28.1 MB 2.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 10.7/28.1 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 11.3/28.1 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 11.5/28.1 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 12.1/28.1 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 12.6/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 13.1/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.4/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.4/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.6/28.1 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 14.2/28.1 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 14.7/28.1 MB 2.0 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 15.2/28.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 15.7/28.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 16.3/28.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 16.5/28.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 17.0/28.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 17.8/28.1 MB 2.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 18.4/28.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 18.6/28.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 18.6/28.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 18.9/28.1 MB 2.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 19.1/28.1 MB 2.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 19.7/28.1 MB 2.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 20.2/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 20.4/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 21.0/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 21.2/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 21.5/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 22.0/28.1 MB 2.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 22.5/28.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 23.1/28.1 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 23.6/28.1 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 24.1/28.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 24.9/28.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 25.4/28.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 25.7/28.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 26.2/28.1 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/28.1 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.8/28.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 2.0 MB/s  0:00:13\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Installing collected packages: mpmath, xxhash, sympy, sentencepiece, pyarrow, propcache, networkx, multidict, MarkupSafe, h11, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, jinja2, httpcore, aiosignal, torch, httpx, aiohttp, bitsandbytes, accelerate, datasets\n",
      "\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   ----------------------------------------  0/25 [mpmath]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   --- ------------------------------------  2/25 [sympy]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   ------ ---------------------------------  4/25 [pyarrow]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   --------- ------------------------------  6/25 [networkx]\n",
      "   -------------- -------------------------  9/25 [h11]\n",
      "   ----------------- ---------------------- 11/25 [dill]\n",
      "   ------------------- -------------------- 12/25 [attrs]\n",
      "   ------------------------ --------------- 15/25 [multiprocess]\n",
      "   ------------------------- -------------- 16/25 [jinja2]\n",
      "   --------------------------- ------------ 17/25 [httpcore]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   ------------------------------ --------- 19/25 [torch]\n",
      "   --------------------------------- ------ 21/25 [aiohttp]\n",
      "   --------------------------------- ------ 21/25 [aiohttp]\n",
      "   --------------------------------- ------ 21/25 [aiohttp]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ----------------------------------- ---- 22/25 [bitsandbytes]\n",
      "   ------------------------------------ --- 23/25 [accelerate]\n",
      "   ------------------------------------ --- 23/25 [accelerate]\n",
      "   -------------------------------------- - 24/25 [datasets]\n",
      "   -------------------------------------- - 24/25 [datasets]\n",
      "   -------------------------------------- - 24/25 [datasets]\n",
      "   ---------------------------------------- 25/25 [datasets]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 bitsandbytes-0.49.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jinja2-3.1.6 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6.1 propcache-0.4.1 pyarrow-22.0.0 sentencepiece-0.2.1 sympy-1.14.0 torch-2.9.1 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\dasun\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\dasun\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\dasun\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'c:\\Users\\dasun\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'c:\\Users\\dasun\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Install all required packages and JDK (Ubuntu-based)\n",
    "%pip install --upgrade pip\n",
    "%pip install pandas numpy transformers accelerate datasets sentencepiece bitsandbytes gdown\n",
    "# %apt-get update && apt-get install -y openjdk-17-jdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c78997fac796e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:44.963742700Z",
     "start_time": "2025-12-16T08:43:25.122460Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Download Project_CodeNet_Java.parquet if missing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "PARQUET_PATH = Path(\"Project_CodeNet_Java.parquet\")\n",
    "if not PARQUET_PATH.exists():\n",
    "    print(\"Project_CodeNet_Java.parquet not found. Downloading from Google Drive...\")\n",
    "    try:\n",
    "        import gdown\n",
    "    except ImportError:\n",
    "        print(\"gdown not found, installing via pip...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "        import gdown\n",
    "    gdown.download(\n",
    "        url=\"https://drive.google.com/uc?id=1rOGafVqqzl2JM7bvoS-2kkBK6PCbNFsZ\",\n",
    "        output=str(PARQUET_PATH),\n",
    "        quiet=False\n",
    "    )\n",
    "    if PARQUET_PATH.exists():\n",
    "        print(\" Download complete.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Failed to download Project_CodeNet_Java.parquet.\")\n",
    "else:\n",
    "    print(\" Project_CodeNet_Java.parquet already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc5d010d36d38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.371789Z",
     "start_time": "2025-12-16T08:43:25.175414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: GPU and environment verification\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def check_env():\n",
    "    print(\"\\n--- Environment Verification ---\")\n",
    "    # PyTorch version\n",
    "    try:\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"PyTorch not installed: {e}\")\n",
    "    # CUDA availability\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    if cuda_available:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"No CUDA GPU detected.\")\n",
    "    # Java version\n",
    "    try:\n",
    "        result = subprocess.run([\"java\", \"-version\"], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"Java version:\")\n",
    "            print(result.stderr.strip() or result.stdout.strip())\n",
    "        else:\n",
    "            print(\"Java not found or failed to run.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Java not available: {e}\")\n",
    "    print(\"--- End of Environment Verification ---\\n\")\n",
    "\n",
    "check_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a18a5c45c183df",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "Import all required libraries and set up the configuration for the hybrid generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eef59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.397930Z",
     "start_time": "2025-12-16T08:43:25.379904Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import all required libraries\n",
    "\"\"\"\n",
    "%pip install colorama jsonlines hf-transfer\n",
    "\n",
    "import uuid\n",
    "import time\n",
    "import tempfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from colorama import Fore, Style, init\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# Initialize colorama for Windows compatibility\n",
    "init(autoreset=True)\n",
    "\n",
    "print(f\"{Fore.GREEN} All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dd5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.467564Z",
     "start_time": "2025-12-16T08:43:25.406283Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration - Edit these paths and parameters\n",
    "\"\"\"\n",
    "\n",
    "# Path to CodeNet root directory\n",
    "CODENET_ROOT = Path(r\"Project_CodeNet_Java.parquet\")\n",
    "\n",
    "\n",
    "# Output paths\n",
    "EASY_OUTPUT_PATH = Path(\"dataset/java_clones_easy_types.jsonl\")\n",
    "HARD_OUTPUT_PATH = Path(\"dataset/java_clones_hard_types.jsonl\")\n",
    "COMBINED_OUTPUT_PATH = Path(\"dataset/java_clones_10k.jsonl\")\n",
    "# Non-clone output paths\n",
    "EASY_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_easy_types.jsonl\")\n",
    "HARD_NONCLONES_OUTPUT_PATH = Path(\"dataset/java_nonclones_hard_types.jsonl\")\n",
    "FINAL_DATASET_PATH = Path(\"dataset/java_complete_dataset.jsonl\")\n",
    "GENERATED_DIR = Path(\"generated\")\n",
    "SEEDS_DIR = Path(\"seeds\")\n",
    "\n",
    "# Execution settings\n",
    "TIMEOUT_SECONDS = 30\n",
    "MAX_PROBLEMS = None  # None for all problems, or int to limit\n",
    "\n",
    "# Clone generation settings\n",
    "TARGET_CLONES_PER_TYPE = 1  # Target per type - reasonable for testing, can increase later\n",
    "# Non-clone generation settings\n",
    "TARGET_NONCLONES_EASY = 1 # Target easy non-clones (simple algorithmic differences)\n",
    "TARGET_NONCLONES_HARD = 1  # Target hard non-clones (different problem domains)\n",
    "MAX_CLONES_PER_PROBLEM = 5\n",
    "MAX_CYCLES = 50\n",
    "\n",
    "# Model settings - HYBRID APPROACH\n",
    "EASY_MODEL = \"qwen2.5-coder:7b\"       # Fast model for Type-1, Type-2\n",
    "HARD_MODEL = \"qwen2.5-coder:7b\"\n",
    "# EASY_MODEL = \"codegemma:7b\"       # Fast model for Type-1, Type-2\n",
    "# HARD_MODEL = \"codegemma:7b\"  # Capable model for Type-3, Type-4\n",
    "\n",
    "# Logging\n",
    "VERBOSE = True\n",
    "\n",
    "# Create directories\n",
    "for directory in [GENERATED_DIR, SEEDS_DIR, EASY_OUTPUT_PATH.parent]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"{Fore.GREEN} Configuration loaded\")\n",
    "print(f\"{Fore.CYAN}Easy Model (Type-1/2): {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Hard Model (Type-3/4): {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Target per type: {TARGET_CLONES_PER_TYPE}\")\n",
    "print(f\"{Fore.CYAN}CodeNet Root: {CODENET_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5526e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.505200Z",
     "start_time": "2025-12-16T08:43:25.477823Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_unicode_to_ascii(text):\n",
    "    \"\"\"Convert Unicode characters to ASCII equivalents.\"\"\"\n",
    "    replacements = {\n",
    "        '\\u201c': '\"', '\\u201d': '\"', '\\u2018': \"'\", '\\u2019': \"'\",\n",
    "        '\\u201b': \"'\", '\\u2013': '-', '\\u2014': '-', '\\u2015': '-',\n",
    "        '\\u00a0': ' ', '\\u2009': ' ', '\\u200a': ' ', '\\u2026': '...',\n",
    "        '\\u00b4': \"'\", '\\u02bb': \"'\", '\\u02bc': \"'\"\n",
    "    }\n",
    "    \n",
    "    for unicode_char, ascii_char in replacements.items():\n",
    "        text = text.replace(unicode_char, ascii_char)\n",
    "    \n",
    "    cleaned = []\n",
    "    for char in text:\n",
    "        if ord(char) < 128 or char in ['\\n', '\\r', '\\t']:\n",
    "            cleaned.append(char)\n",
    "        else:\n",
    "            cleaned.append(' ')\n",
    "    \n",
    "    return ''.join(cleaned)\n",
    "\n",
    "def sanitize_code_from_model(raw_text):\n",
    "    \"\"\"Sanitize and extract Java code from model output.\"\"\"\n",
    "    if raw_text is None:\n",
    "        return None\n",
    "    \n",
    "    text = raw_text.strip()\n",
    "    text = normalize_unicode_to_ascii(text)\n",
    "    \n",
    "    # Handle fenced code blocks\n",
    "    if \"```\" in text:\n",
    "        parts = text.split(\"```\")\n",
    "        for part in parts:\n",
    "            if part.lower().startswith(\"java\"):\n",
    "                text = part[4:].lstrip()\n",
    "                break\n",
    "        else:\n",
    "            # Fallback: find the largest block inside backticks\n",
    "            candidates = [p for p in parts if len(p.strip()) > 20]\n",
    "            if candidates:\n",
    "                text = max(candidates, key=len)\n",
    "    \n",
    "    # Remove common LLM artifacts\n",
    "    llm_artifacts = [\n",
    "        r'< begin of sentence >', r'<begin of sentence>', r'< end of sentence >',\n",
    "        r'<end of sentence>', r'<\\|begin_of_text\\|>', r'<\\|end_of_text\\|>',\n",
    "        r'<s>', r'</s>', r'<\\|startoftext\\|>', r'<\\|endoftext\\|>',\n",
    "        r'<\\|file_separator\\|>', r'<\\|code_start\\|>', r'<\\|code_end\\|>'\n",
    "    ]\n",
    "    \n",
    "    for artifact in llm_artifacts:\n",
    "        text = re.sub(artifact, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up specific System.out artifacts if they leaked into code\n",
    "    # e.g., System.out< begin of sentence >println\n",
    "    text = re.sub(r'System\\.out\\s*<[^>]+>\\s*', 'System.out.', text)\n",
    "    \n",
    "    # Basic validation\n",
    "    if \"class Main\" not in text:\n",
    "        # Try to wrap it if it looks like code but missing class\n",
    "        if \"public static void main\" in text:\n",
    "             text = \"public class Main {\\n\" + text + \"\\n}\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "print(f\"{Fore.GREEN} Helper functions defined (Updated with improved sanitization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824f439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:25.567797Z",
     "start_time": "2025-12-16T08:43:25.522790Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prompt templates for clone generation\n",
    "\"\"\"\n",
    "TYPE1_PROMPT_TEMPLATE = \"\"\"You are a Java code formatter. Transform this Java code by ONLY changing formatting while preserving all semantics.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. ONLY change formatting: whitespace, indentation, line breaks, comments\n",
    "4. MUST preserve all identifiers, literals, and code structure\n",
    "5. DO NOT rename variables, methods, or classes\n",
    "6. DO NOT change any literals or expressions\n",
    "7. DO NOT add, remove, or modify any statements\n",
    "8. DO NOT change control flow structure\n",
    "9. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Formatted Code:\"\"\"\n",
    "\n",
    "TYPE2_PROMPT_TEMPLATE = \"\"\"You are a Java refactoring assistant. Transform this code by renaming identifiers and changing literals while preserving exact behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. CAN rename variables, parameters, and method names (EXCEPT main method)\n",
    "4. CAN change literals (e.g., 100xA, true(1==1), \"test\"\"TEST\".toLowerCase())\n",
    "5. MUST preserve exact control flow and structure\n",
    "6. DO NOT add, remove, or reorder any statements\n",
    "7. DO NOT change the algorithmic logic or approach\n",
    "8. DO NOT modify control flow patterns (if/else, loops, etc.)\n",
    "9. Structure and statement order MUST remain identical\n",
    "10. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Refactored Code:\"\"\"\n",
    "\n",
    "TYPE3_PROMPT_TEMPLATE = \"\"\"You are a Java code mutator. Transform this code with SIGNIFICANT statement-level modifications while preserving exact program behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "**TYPE-3 CLONE REQUIREMENTS - YOU MUST DO AT LEAST 3 OF THESE:**\n",
    "1. Replace for loops with while loops (or vice versa)\n",
    "2. Add temporary variables to break up complex expressions: `result = a + b + c`  `temp = a + b; result = temp + c`\n",
    "3. Add dead code: unused variables, unreachable statements after return/break\n",
    "4. Reorder independent statements (declarations, assignments that don't depend on each other)\n",
    "5. Replace if-else with ternary operators (or vice versa): `if(x>0) y=1; else y=0;`  `y = (x>0) ? 1 : 0;`\n",
    "6. Add redundant calculations: `x = 5`  `x = 3 + 2` or `x = 10/2`\n",
    "7. Extract inline calculations into separate statements\n",
    "8. Add extra variable assignments that don't change behavior\n",
    "9. Change loop increment styles: `i++`  `i = i + 1`  `i += 1`\n",
    "10. Add null checks or bounds checks that are always true/false\n",
    "\n",
    "**CONCRETE EXAMPLES OF REQUIRED CHANGES:**\n",
    "\n",
    "Example 1 - Loop Conversion:\n",
    "BEFORE: `for(int i=0; i<n; i++) { sum += arr[i]; }`\n",
    "AFTER: `int i = 0; while(i < n) { sum += arr[i]; i = i + 1; }`\n",
    "\n",
    "Example 2 - Expression Breakdown:\n",
    "BEFORE: `int result = (a + b) * (c - d);`\n",
    "AFTER: `int temp1 = a + b; int temp2 = c - d; int result = temp1 * temp2;`\n",
    "\n",
    "Example 3 - Dead Code Addition:\n",
    "BEFORE: `return result;`\n",
    "AFTER: `int unused = 42; return result; System.out.println(\"never reached\");`\n",
    "\n",
    "**FORBIDDEN (these make Type-1 clones, NOT Type-3):**\n",
    "- Only changing whitespace/formatting\n",
    "- Only renaming variables\n",
    "- Only changing comments\n",
    "- Only changing literal values without structural impact\n",
    "\n",
    "**REQUIRED STRUCTURE:**\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST preserve exact input/output behavior\n",
    "4. MUST have noticeable structural differences from original\n",
    "5. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Structurally Modified Code:\"\"\"\n",
    "\n",
    "TYPE4_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Rewrite this code using a completely different algorithm while maintaining identical observable behavior.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST preserve exact input format and parsing\n",
    "4. MUST preserve exact output format and content\n",
    "5. MUST have identical behavior for ALL possible inputs\n",
    "6. CAN use completely different algorithms, data structures, approaches\n",
    "7. CAN restructure the entire program logic\n",
    "8. CAN use different computational strategies\n",
    "9. Structure and implementation MAY be completely different\n",
    "10. Observable input/output behavior MUST be identical\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Rewritten Code:\"\"\"\n",
    "\n",
    "EASY_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are a Java programmer. Create a simple, different Java program that solves a basic algorithmic problem.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. Create a program for a COMPLETELY DIFFERENT problem domain\n",
    "4. DO NOT reuse any variable names from the reference code\n",
    "5. DO NOT use similar control-flow patterns\n",
    "6. DO NOT use similar data structures\n",
    "7. Must solve a clearly different algorithmic problem\n",
    "8. Use basic concepts: simple loops, arrays, basic arithmetic\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem goal and output meaning required\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SOMETHING COMPLETELY DIFFERENT):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Different Program:\"\"\"\n",
    "\n",
    "HARD_NONCLONE_PROMPT_TEMPLATE = \"\"\"You are an expert Java programmer. Create a sophisticated Java program that has similar structure but different semantics from the reference code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "RULES:\n",
    "1. MUST have class name as \"Main\" (CRITICAL for compilation)\n",
    "2. MUST have public static void main(String[] args) method\n",
    "3. MUST have similar control flow patterns (similar if/else, loop structures)\n",
    "4. MUST have similar program skeleton and structure\n",
    "5. MUST solve a DIFFERENT semantic problem with DIFFERENT output meaning\n",
    "6. MUST NOT have behavioral equivalence with the reference code\n",
    "7. Use advanced concepts: collections, recursion, object-oriented design\n",
    "8. High structural similarity but different algorithmic goal required\n",
    "9. Must be functionally complete and compilable\n",
    "10. Different problem domain but similar complexity\n",
    "11. Output raw Java code ONLY (no markdown, no explanation)\n",
    "\n",
    "Reference Code (CREATE SIMILAR STRUCTURE, DIFFERENT SEMANTICS):\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "New Structurally Similar Program:\"\"\"\n",
    "\n",
    "\n",
    "print(f\"{Fore.GREEN} Prompt templates defined (including non-clone templates)\")\n",
    "print(f\"{Fore.CYAN}  Clone templates: Type-1, Type-2, Type-3, Type-4\")\n",
    "print(f\"{Fore.CYAN}  Non-clone templates: Easy, Hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d773ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:37.025115Z",
     "start_time": "2025-12-16T08:43:25.577710Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CodeNet data loading functions\n",
    "\"\"\"\n",
    "\n",
    "# Load the Project_CodeNet_Java.parquet as a DataFrame\n",
    "PARQUET_PATH = Path(\"Project_CodeNet_Java.parquet\")\n",
    "print(f\"{Fore.CYAN}Loading Project_CodeNet_Java.parquet ...\")\n",
    "codenet_df = pd.read_parquet(PARQUET_PATH)\n",
    "print(f\"{Fore.GREEN} Loaded {len(codenet_df)} records from Project_CodeNet_Java.parquet\")\n",
    "print(\"Columns in Project_CodeNet_Java.parquet:\", codenet_df.columns.tolist())  # DEBUG: Show columns for fixing 'code' KeyError\n",
    "\n",
    "# Refactored data access functions\n",
    "\n",
    "def list_problems():\n",
    "    \"\"\"List all unique problem IDs in the Parquet dataset.\"\"\"\n",
    "    return sorted(codenet_df['problem_id'].unique())\n",
    "\n",
    "def choose_seed(problem_id):\n",
    "    \"\"\"Select a seed Java submission from the Parquet DataFrame.\"\"\"\n",
    "    df = codenet_df[codenet_df['problem_id'] == problem_id]\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    # Filter for Java and Accepted submissions if columns exist\n",
    "    if 'language' in df.columns:\n",
    "        df = df[df['language'].str.lower() == 'java']\n",
    "    if 'status' in df.columns:\n",
    "        df = df[df['status'].str.lower() == 'accepted']\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    # Use 'source_code' as the code column\n",
    "    df = df.assign(_code_len=df['source_code'].str.len()).sort_values('_code_len')\n",
    "    row = df.iloc[0]\n",
    "    code = row['source_code'] if 'source_code' in row else None\n",
    "    submission_id = row['submission_id'] if 'submission_id' in row else None\n",
    "    if code and len(code) <= 10240:\n",
    "        return code, submission_id\n",
    "    return None, None\n",
    "\n",
    "def load_testcases(problem_id):\n",
    "    \"\"\"Load input/output testcases for a problem from the parquet file.\"\"\"\n",
    "    # The parquet file has 'inputs' and 'outputs' columns for each submission\n",
    "    # We'll select the first Java/Accepted submission for the problem with non-null inputs/outputs\n",
    "    df = codenet_df[codenet_df['problem_id'] == problem_id]\n",
    "    if 'language' in df.columns:\n",
    "        df = df[df['language'].str.lower() == 'java']\n",
    "    if 'status' in df.columns:\n",
    "        df = df[df['status'].str.lower() == 'accepted']\n",
    "    # Only keep rows with non-null inputs and outputs\n",
    "    df = df[df['inputs'].notnull() & df['outputs'].notnull()]\n",
    "    if df.empty:\n",
    "        return []\n",
    "    # Use the first available testcase\n",
    "    row = df.iloc[0]\n",
    "    input_text = row['inputs']\n",
    "    output_text = row['outputs']\n",
    "    # If these are lists/strings of testcases, split if needed\n",
    "    if isinstance(input_text, str) and '\\n' in input_text and isinstance(output_text, str) and '\\n' in output_text:\n",
    "        # Assume each line is a testcase\n",
    "        input_lines = input_text.strip().split('\\n')\n",
    "        output_lines = output_text.strip().split('\\n')\n",
    "        # Pair up lines (if counts match)\n",
    "        if len(input_lines) == len(output_lines):\n",
    "            return list(zip(input_lines, output_lines))\n",
    "    # Otherwise, just return as a single testcase\n",
    "    return [(input_text, output_text)]\n",
    "\n",
    "print(f\"{Fore.GREEN} CodeNet loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f132c9ec16a8033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:44.858547Z",
     "start_time": "2025-12-16T08:43:37.188850Z"
    }
   },
   "outputs": [],
   "source": [
    "def log(message, color=Fore.WHITE):\n",
    "    \"\"\"Simple logger function.\"\"\"\n",
    "    try:\n",
    "        print(f\"{color}{message}{Style.RESET_ALL}\")\n",
    "    except Exception:\n",
    "        print(message)\n",
    "\n",
    "# Cell: Hugging Face Transformers model loading and prompt formatting\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Use Qwen2.5-Coder-7B from Hugging Face\n",
    "HF_MODEL_NAME = \"Qwen/Qwen2.5-Coder-7B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    HF_MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "def get_system_prompt():\n",
    "    return (\n",
    "        \"You are a highly accurate, concise, and reliable Java code assistant. \"\n",
    "        \"You never hallucinate, always follow instructions, and only output valid Java code. \"\n",
    "        \"If you are unsure, say so.\"\n",
    "    )\n",
    "\n",
    "def format_prompt(user_instruction, code=None):\n",
    "    prompt = get_system_prompt() + \"\\n\\n\" + user_instruction.strip()\n",
    "    if code is not None:\n",
    "        prompt += f\"\\n\\nInput Code:\\n{code.strip()}\"\n",
    "    return prompt\n",
    "\n",
    "def ask_model_transformers(prompt, max_tokens=1500, temperature=0.1):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # Remove the prompt from the output if present\n",
    "    if generated.startswith(prompt):\n",
    "        generated = generated[len(prompt):].strip()\n",
    "    return generated\n",
    "\n",
    "def quick_check_code_quality(code_str):\n",
    "    \"\"\"Check code quality without compilation.\"\"\"\n",
    "    if not code_str or len(code_str) < 50:\n",
    "        return False, \"Code too short\"\n",
    "    \n",
    "    if \"class Main\" not in code_str:\n",
    "        return False, \"Missing 'class Main'\"\n",
    "    \n",
    "    if \"main(\" not in code_str:\n",
    "        return False, \"Missing main method\"\n",
    "    \n",
    "    # Check for suspicious patterns\n",
    "    suspicious = [\n",
    "        \"TODO:\", \"FIXME:\", \"[Your code here]\", \"// ... rest of\",\n",
    "        \"// Original code\", \"// Explanation:\", \"Note that\", \n",
    "        \"< begin of sentence >\", \"<begin of sentence>\",\n",
    "        \"< end of sentence >\", \"<end of sentence>\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in suspicious:\n",
    "        if pattern in code_str:\n",
    "            return False, f\"Contains suspicious pattern: {pattern}\"\n",
    "    \n",
    "    # Check basic syntax balance - Relaxed to avoid false positives on generics or bitwise ops\n",
    "    if code_str.count('{') != code_str.count('}'):\n",
    "        return False, \"Unbalanced braces\"\n",
    "    \n",
    "    if code_str.count('(') != code_str.count(')'):\n",
    "        return False, \"Unbalanced parentheses\"\n",
    "    \n",
    "    # Check for incomplete statements\n",
    "    trimmed = code_str.strip()\n",
    "    if trimmed and trimmed[-1] not in ['}', ';', '*', '/']:\n",
    "        return False, \"Code appears incomplete\"\n",
    "    \n",
    "    return True, \"OK\"\n",
    "\n",
    "# [REMAINING VALIDATION FUNCTIONS KEPT AS IS]\n",
    "def compile_java(temp_dir):\n",
    "    \"\"\"Compile Main.java in temp_dir.\"\"\"\n",
    "    java_file = Path(temp_dir) / \"Main.java\"\n",
    "    \n",
    "    if not java_file.exists():\n",
    "        return False, \"Main.java not found\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"javac\", str(java_file)],\n",
    "            cwd=temp_dir,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=30,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return False, f\"Compilation error: {error[:500]}\"\n",
    "        \n",
    "        return True, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Compilation timeout\"\n",
    "    except FileNotFoundError:\n",
    "        return False, \"javac not found. Please install JDK.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Compilation exception: {str(e)}\"\n",
    "\n",
    "def run_java_with_input(temp_dir, input_str, timeout=3):\n",
    "    \"\"\"Run compiled Java program with given input.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"java\", \"Main\"],\n",
    "            cwd=temp_dir,\n",
    "            input=input_str.encode('utf-8'),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            timeout=timeout,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            error = result.stderr.decode('utf-8', errors='ignore')\n",
    "            return None, f\"Runtime error: {error[:500]}\"\n",
    "        \n",
    "        output = result.stdout.decode('utf-8', errors='ignore')\n",
    "        return output, None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, \"Execution timeout\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Execution exception: {str(e)}\"\n",
    "\n",
    "def normalize_output(text):\n",
    "    \"\"\"Normalize output text.\"\"\"\n",
    "    lines = text.strip().split('\\n')\n",
    "    return '\\n'.join(line.rstrip() for line in lines)\n",
    "\n",
    "def validate_java(code_str, problem_id):\n",
    "    \"\"\"Validate Java code by compiling and running against testcases.\"\"\"\n",
    "    testcases = load_testcases(problem_id)\n",
    "    \n",
    "    if not testcases:\n",
    "        return \"no_tests\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        java_file = Path(temp_dir) / \"Main.java\"\n",
    "        \n",
    "        try:\n",
    "            java_file.write_text(code_str, encoding='utf-8')\n",
    "        except Exception:\n",
    "            return \"compile_error\"\n",
    "        \n",
    "        compile_success, compile_error = compile_java(temp_dir)\n",
    "        \n",
    "        if not compile_success:\n",
    "            return f\"compile_error: {compile_error}\" # Enhanced return to include error message\n",
    "        \n",
    "        for idx, (input_text, expected_output) in enumerate(testcases):\n",
    "            output, error = run_java_with_input(temp_dir, input_text, timeout=TIMEOUT_SECONDS)\n",
    "            \n",
    "            if error:\n",
    "                if \"timeout\" in error.lower():\n",
    "                    return \"timeout\"\n",
    "                else:\n",
    "                    return f\"runtime_error: {error}\" # Enhanced return\n",
    "            \n",
    "            norm_output = normalize_output(output)\n",
    "            norm_expected = normalize_output(expected_output)\n",
    "            \n",
    "            if norm_output != norm_expected:\n",
    "                return \"wrong_answer\"\n",
    "        \n",
    "        return \"passed\"\n",
    "\n",
    "print(f\"{Fore.GREEN} Java validation functions defined (Updated checks and error reporting)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b78abd08cc57d0",
   "metadata": {},
   "source": [
    "## 2. Model Selection Logic\n",
    "Define the hybrid model selection strategy based on clone type complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c697783b834bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove Ollama connectivity check and related code\n",
    "\"\"\"\n",
    "\n",
    "# Check Ollama connection\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Checking Ollama Connection...\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# is_connected, available_models = check_ollama_connection()\n",
    "\n",
    "# if is_connected:\n",
    "#     print(f\"{Fore.GREEN} Ollama is running and accessible\")\n",
    "#     print(f\"\\n{Fore.CYAN}Available models:\")\n",
    "#     for model in available_models:\n",
    "#         print(f\"   {model}\")\n",
    "\n",
    "#     # Check if required models are available\n",
    "#     required_models = [EASY_MODEL, HARD_MODEL]\n",
    "#     missing_models = []\n",
    "\n",
    "#     for req_model in set(required_models):  # Use set to avoid duplicates\n",
    "#         if not any(req_model in available for available in available_models):\n",
    "#             missing_models.append(req_model)\n",
    "\n",
    "#     if missing_models:\n",
    "#         print(f\"\\n{Fore.YELLOW} Warning: Required models not found:\")\n",
    "#         for model in missing_models:\n",
    "#             print(f\"   {model}\")\n",
    "#         print(f\"\\n{Fore.CYAN}To download missing models, run:\")\n",
    "#         for model in missing_models:\n",
    "#             print(f\"  ollama pull {model}\")\n",
    "#     else:\n",
    "#         print(f\"\\n{Fore.GREEN} All required models are available\")\n",
    "# else:\n",
    "#     print(f\"{Fore.RED} Cannot connect to Ollama\")\n",
    "#     print(f\"\\n{Fore.YELLOW}Please ensure Ollama is running:\")\n",
    "#     print(f\"  1. Open a new terminal\")\n",
    "#     print(f\"  2. Run: ollama serve\")\n",
    "#     print(f\"  3. Then re-run this notebook\")\n",
    "#     print(f\"\\n{Fore.CYAN}If you don't have Ollama installed:\")\n",
    "#     print(f\"  Visit: https://ollama.ai/download\")\n",
    "\n",
    "#     raise RuntimeError(\"Ollama is not running. Please start Ollama and try again.\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN} Pre-flight checks complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a97f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:44.913364Z",
     "start_time": "2025-12-15T20:34:16.193854Z"
    }
   },
   "outputs": [],
   "source": [
    "REPAIR_PROMPT_TEMPLATE = \"\"\"You are a Java code repair assistant. The following Java code has errors. Fix the validation errors and output the corrected code.\n",
    "\n",
    "**CRITICAL:** Your output must be raw Java code ONLY. Do not include any markdown, explanations, or special tokens.\n",
    "\n",
    "Rules:\n",
    "1. MUST have class name as \"Main\"\n",
    "2. Fix SPECIFICALLY the error reported below\n",
    "3. Preserve the original logic as much as possible\n",
    "4. Output raw Java code ONLY\n",
    "\n",
    "Original Code:\n",
    "<<<CODE_PLACEHOLDER>>>\n",
    "\n",
    "Validation Error:\n",
    "<<<ERROR_PLACEHOLDER>>>\n",
    "\n",
    "Fixed Code:\"\"\"\n",
    "\n",
    "def get_model_for_clone_type(clone_type):\n",
    "    \"\"\"\n",
    "    Return the appropriate model based on clone type complexity.\n",
    "    \n",
    "    Easy types (Type-1, Type-2): Use qwen2.5-coder:7b\n",
    "    Hard types (Type-3, Type-4): Use qwen2.5-coder:7b\n",
    "    \"\"\"\n",
    "    if clone_type in ['type1', 'type2']:\n",
    "        return EASY_MODEL\n",
    "    elif clone_type in ['type3', 'type4']:\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        # Default to hard model for unknown types\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_with_repair(prompt, model_name, problem_id=None, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate code with a repair loop. \n",
    "    If validation fails, ask the model to fix it using the error message.\n",
    "    Handles API timeouts with retry logic.\n",
    "    \"\"\"\n",
    "    # 1. Initial Generation\n",
    "    temperatures = [0.1, 0.3, 0.5]\n",
    "    best_candidate = None\n",
    "    for attempt in range(2): # 2 attempts at initial generation\n",
    "        temp = temperatures[min(attempt, len(temperatures) - 1)]\n",
    "        raw, error = ask_model_transformers(prompt, max_tokens=1500, temperature=temp)\n",
    "        if error:\n",
    "            log(f\"[MODEL ERROR] {error}\", Fore.RED)\n",
    "            if \"timeout\" in str(error).lower():\n",
    "                log(f\"[MODEL ERROR] Ollama API timeout after retries. Skipping this attempt.\", Fore.RED)\n",
    "            continue\n",
    "        code = sanitize_code_from_model(raw)\n",
    "        if not code:\n",
    "            continue\n",
    "        # Quick check\n",
    "        valid_syntax, reason = quick_check_code_quality(code)\n",
    "        if not valid_syntax:\n",
    "            print(f\"  {Fore.YELLOW}Syntax check failed: {reason}\")\n",
    "            error_msg = f\"Syntax error: {reason}\"\n",
    "        else:\n",
    "            if problem_id:\n",
    "                result = validate_java(code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    return code # Success!\n",
    "                else:\n",
    "                    error_msg = result\n",
    "            else:\n",
    "                return code # No problem ID to validate against, so return code\n",
    "        print(f\"  {Fore.YELLOW}Attempting repair for error: {error_msg}\")\n",
    "        current_code = code\n",
    "        for repair_attempt in range(2): # 2 repair attempts\n",
    "            repair_prompt = REPAIR_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", current_code).replace(\"<<<ERROR_PLACEHOLDER>>>\", str(error_msg))\n",
    "            repair_model = HARD_MODEL\n",
    "            raw_repair, err = ask_model_transformers(repair_prompt, max_tokens=1500, temperature=0.1)\n",
    "            if err:\n",
    "                log(f\"[MODEL ERROR] {err}\", Fore.RED)\n",
    "                if \"timeout\" in str(err).lower():\n",
    "                    log(f\"[MODEL ERROR] Ollama API timeout during repair after retries. Skipping this repair attempt.\", Fore.RED)\n",
    "                break\n",
    "            repaired_code = sanitize_code_from_model(raw_repair)\n",
    "            if not repaired_code:\n",
    "                continue\n",
    "            valid_syntax, reason = quick_check_code_quality(repaired_code)\n",
    "            if not valid_syntax:\n",
    "                error_msg = f\"Syntax error after repair: {reason}\"\n",
    "                current_code = repaired_code\n",
    "                continue\n",
    "            if problem_id:\n",
    "                result = validate_java(repaired_code, problem_id)\n",
    "                if result == \"passed\":\n",
    "                    print(f\"  {Fore.GREEN}Repair successful!\")\n",
    "                    return repaired_code\n",
    "                else:\n",
    "                    error_msg = result\n",
    "                    current_code = repaired_code\n",
    "            else:\n",
    "                return repaired_code\n",
    "    return None\n",
    "\n",
    "def generate_clone_v2(code, clone_type, problem_id):\n",
    "    if clone_type == 'type1':\n",
    "        prompt = TYPE1_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type2':\n",
    "        prompt = TYPE2_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type3':\n",
    "        prompt = TYPE3_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif clone_type == 'type4':\n",
    "        prompt = TYPE4_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_clone_type(clone_type)\n",
    "\n",
    "    # For Type-3 clones, we need to validate that it's actually Type-3 and not Type-1\n",
    "    if clone_type == 'type3':\n",
    "        # Try multiple times to get a proper Type-3 clone\n",
    "        for attempt in range(5):  # 5 attempts for Type-3\n",
    "            generated_code = generate_with_repair(prompt, model, problem_id)\n",
    "\n",
    "            if not generated_code:\n",
    "                continue\n",
    "\n",
    "            # Validate that this is actually a Type-3 clone\n",
    "            is_type3, reason = validate_type3_clone(code, generated_code)\n",
    "\n",
    "            if is_type3:\n",
    "                print(f\"  {Fore.GREEN} Type-3 validation passed: {reason}\")\n",
    "                return generated_code\n",
    "            else:\n",
    "                print(f\"  {Fore.YELLOW} Type-3 validation failed (attempt {attempt + 1}): {reason}\")\n",
    "                # Try again with modified prompt to be more explicit\n",
    "                if attempt < 4:  # Don't modify on last attempt\n",
    "                    enhanced_prompt = prompt + f\"\\n\\nIMPORTANT: The previous attempt was rejected because: {reason}\\nMake MORE SIGNIFICANT structural changes. Remember: You MUST do at least 3 major modifications from the requirements list.\"\n",
    "                    prompt = enhanced_prompt\n",
    "\n",
    "        # If all attempts failed, return None\n",
    "        print(f\"  {Fore.RED} Failed to generate proper Type-3 clone after 5 attempts\")\n",
    "        return None\n",
    "    else:\n",
    "        # For other types, use normal generation\n",
    "        return generate_with_repair(prompt, model, problem_id)\n",
    "\n",
    "def get_model_for_nonclone_type(nonclone_type):\n",
    "    if nonclone_type == 'easy':\n",
    "        return EASY_MODEL\n",
    "    elif nonclone_type == 'hard':\n",
    "        return HARD_MODEL\n",
    "    else:\n",
    "        return HARD_MODEL\n",
    "\n",
    "def generate_nonclone_v2(code, nonclone_type, problem_id=None):\n",
    "    if nonclone_type == 'easy':\n",
    "        prompt = EASY_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    elif nonclone_type == 'hard':\n",
    "        prompt = HARD_NONCLONE_PROMPT_TEMPLATE.replace(\"<<<CODE_PLACEHOLDER>>>\", code)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    model = get_model_for_nonclone_type(nonclone_type)\n",
    "    # For non-clones, we just check compilation/sanity, we can't check 'passed' against original tests\n",
    "    # because the problem is DIFFERENT. So passing problem_id might be misleading if used for test validation.\n",
    "    # However, generate_with_repair uses problem_id to run tests.\n",
    "    # For non-clones, we should probably pass None for problem_id to skip testcase validation inside the repair loop,\n",
    "    # OR update generate_with_repair to handle 'compile_only' mode.\n",
    "    \n",
    "    return generate_with_repair(prompt, model, problem_id=None) \n",
    "\n",
    "print(f\"{Fore.GREEN} Model selection logic & Repair loop defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3826246803f2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:44.932354500Z",
     "start_time": "2025-12-15T20:34:16.241539Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_clones_for_types(clone_types, output_path, target_per_type):\n",
    "    import json\n",
    "    # Resume logic: collect already generated (problem_id, clone_type) pairs\n",
    "    existing_pairs = set()\n",
    "    if output_path.exists():\n",
    "        try:\n",
    "            with open(output_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        record = json.loads(line)\n",
    "                        pid = record.get('problem_id')\n",
    "                        ctype = record.get('clone_type')\n",
    "                        if pid and ctype:\n",
    "                            existing_pairs.add((pid, ctype))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='a', flush=True)  # append mode\n",
    "\n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED} No problems found in CodeNet directory\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "    \n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "    \n",
    "    clone_counters = {ct: 0 for ct in clone_types}\n",
    "    # Count already generated clones for each type\n",
    "    for (pid, ctype) in existing_pairs:\n",
    "        if ctype in clone_counters:\n",
    "            clone_counters[ctype] += 1\n",
    "\n",
    "    stats = {\n",
    "        'no_seed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'failed': 0\n",
    "    }\n",
    "    \n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "    \n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(clone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(clone_types)}\") as pbar:\n",
    "        # Set progress bar to already completed\n",
    "        completed = sum(clone_counters.values())\n",
    "        if completed > 0:\n",
    "            pbar.update(completed)\n",
    "        while any(clone_counters[ct] < target_per_type for ct in clone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "                \n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "            \n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "            \n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "                \n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Load testcases\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\" # Normalize for check\n",
    "                \n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Generate clones for this problem\n",
    "                clones_generated_this_problem = 0\n",
    "                \n",
    "                # Generate each type of clone\n",
    "                for clone_type in clone_types:\n",
    "                    if clone_counters[clone_type] >= target_per_type:\n",
    "                        continue\n",
    "                    \n",
    "                    if clones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "                    \n",
    "                    # Skip Type-4 for complex files\n",
    "                    if clone_type == 'type4' and len(seed_code.split('\\n')) >= 75:\n",
    "                        continue\n",
    "                    \n",
    "                    # SKIP if already generated for this (problem_id, clone_type)\n",
    "                    if (problem_id, clone_type) in existing_pairs:\n",
    "                        continue\n",
    "\n",
    "                    # Generate clone\n",
    "                    try:\n",
    "                        # UPDATED CALL: Pass problem_id for repair loop\n",
    "                        generated_code = generate_clone_v2(seed_code, clone_type, problem_id)\n",
    "                        \n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Already validated inside generate_clone_v2 (mostly), but double check if returned\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        result = validate_java(generated_code, problem_id)\n",
    "                        \n",
    "                        if result == \"passed\":\n",
    "                            pair_id = f\"{problem_id}_{clone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "                            \n",
    "                            record = {\n",
    "                                'id': pair_id,\n",
    "                                'code_1': seed_code,\n",
    "                                'code_2': generated_code,\n",
    "                                'label': \"clone\",\n",
    "                                'clone_type': clone_type,\n",
    "                                'language': 'Java',\n",
    "                                'problem_id': problem_id,\n",
    "                                'generator': get_model_for_clone_type(clone_type),\n",
    "                                'timestamp': time.time()\n",
    "                            }\n",
    "                            \n",
    "                            dataset_writer.write(record)\n",
    "                            clone_counters[clone_type] += 1\n",
    "                            clones_generated_this_problem += 1\n",
    "                            pbar.update(1)\n",
    "                            # Add to existing_pairs to prevent duplicate in same run\n",
    "                            existing_pairs.add((problem_id, clone_type))\n",
    "                        else:\n",
    "                            stats['failed'] += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        log(f\"[{problem_id}] {clone_type} error: {repr(e)}\", Fore.RED)\n",
    "                \n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for ct, count in clone_counters.items():\n",
    "                        status = \"\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {ct}: {status}\")\n",
    "                    print()\n",
    "            \n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "    \n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "    \n",
    "    return clone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN} Core generation function defined (Updated with repair loop)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c03afa04cce12",
   "metadata": {},
   "source": [
    "## 3. Generate Easy Clones (Type-1 and Type-2)\n",
    "Use the fast `codegemma:2b` model to generate Type-1 and Type-2 clones efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ff88c687c8d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T08:43:44.933355Z",
     "start_time": "2025-12-15T20:34:16.293279Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1: Generate Easy Clones (Type-1 and Type-2) using qwen2.5-coder:7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 1: Generating Easy Clones (Type-1, Type-2)\")\n",
    "print(f\"{Fore.CYAN}Model: {EASY_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {EASY_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "easy_counters, easy_stats = generate_clones_for_types(\n",
    "    clone_types=['type1', 'type2'],\n",
    "    output_path=EASY_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN} EASY CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_easy = 0\n",
    "for clone_type, count in easy_counters.items():\n",
    "    status = \" COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \" INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_easy += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total easy clones: {total_easy}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {easy_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {easy_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {easy_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6c1949ab1cbfd",
   "metadata": {},
   "source": [
    "## 4. Generate Hard Clones (Type-3 and Type-4)\n",
    "Use the more capable `qwen2.5-coder:7b` model to generate complex Type-3 and Type-4 clones.\n",
    "\n",
    "**Note:** This step will be significantly slower due to the larger model, but it ensures correct semantic transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbd7fa1701c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: Generate Hard Clones (Type-3 and Type-4) using qwen2.5-coder:7b\n",
    "\"\"\"\n",
    "\n",
    "def validate_type3_clone(original_code, generated_code):\n",
    "    \"\"\"\n",
    "    Validates if generated_code is a type-3 clone of original_code.\n",
    "    Type-3 clones are syntactically similar with some modifications (e.g., added/removed statements, reordered code),\n",
    "    but not identical (not type-1) and not just renamed (not type-2).\n",
    "    Returns (is_type3: bool, reason: str)\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    def normalize_code(code):\n",
    "        # Remove comments\n",
    "        code = re.sub(r\"//.*?$|/\\*.*?\\*/\", \"\", code, flags=re.DOTALL | re.MULTILINE)\n",
    "        # Remove whitespace and blank lines\n",
    "        code = '\\n'.join([line.strip() for line in code.splitlines() if line.strip()])\n",
    "        return code\n",
    "\n",
    "    norm_orig = normalize_code(original_code)\n",
    "    norm_gen = normalize_code(generated_code)\n",
    "\n",
    "    # If identical, not type-3\n",
    "    if norm_orig == norm_gen:\n",
    "        return False, \"Identical code (type-1)\"\n",
    "\n",
    "    # Compute similarity ratio\n",
    "    ratio = SequenceMatcher(None, norm_orig, norm_gen).ratio()\n",
    "    if ratio > 0.6:\n",
    "        return True, f\"Syntactically similar (ratio={ratio:.2f})\"\n",
    "    else:\n",
    "        return False, f\"Not similar enough (ratio={ratio:.2f})\"\n",
    "\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 2: Generating Hard Clones (Type-3, Type-4)\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_counters, hard_stats = generate_clones_for_types(\n",
    "    clone_types=['type3', 'type4'],\n",
    "    output_path=HARD_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_CLONES_PER_TYPE\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN} HARD CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Clone Counts:\")\n",
    "total_hard = 0\n",
    "for clone_type, count in hard_counters.items():\n",
    "    status = \" COMPLETE\" if count >= TARGET_CLONES_PER_TYPE else \" INCOMPLETE\"\n",
    "    print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE} {status}\")\n",
    "    total_hard += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard clones: {total_hard}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e577993c0a1d72",
   "metadata": {},
   "source": [
    "## 5. Combine Datasets\n",
    "Merge the easy and hard clone datasets into a single comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517b6a7417a81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: Combine Easy and Hard Clone Datasets\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 3: Combining Datasets\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read both datasets\n",
    "easy_records = []\n",
    "hard_records = []\n",
    "\n",
    "if EASY_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_OUTPUT_PATH) as reader:\n",
    "        easy_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(easy_records)} records from {EASY_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW} Easy clones file not found: {EASY_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_OUTPUT_PATH) as reader:\n",
    "        hard_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(hard_records)} records from {HARD_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW} Hard clones file not found: {HARD_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine records\n",
    "all_records = easy_records + hard_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_records)}\")\n",
    "\n",
    "# Write combined dataset\n",
    "with jsonlines.open(COMBINED_OUTPUT_PATH, mode='w') as writer:\n",
    "    for record in all_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN} Combined dataset written to: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "# Count by type\n",
    "type_counts = {}\n",
    "for record in all_records:\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Clone Type:\")\n",
    "for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "    count = type_counts.get(clone_type, 0)\n",
    "    print(f\"  {clone_type}: {count}\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN} DATASET COMBINATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f0ae8e2a912eb",
   "metadata": {},
   "source": [
    "## 6. Validate Combined Dataset\n",
    "Perform validation and quality checks on the final combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f75c4be0b4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 4: Validate the Combined Dataset\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 4: Dataset Validation\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Load combined dataset\n",
    "combined_records = []\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        combined_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(combined_records)} records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.RED} Combined dataset not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if combined_records:\n",
    "    # Validation checks\n",
    "    print(f\"\\n{Fore.CYAN}Validation Checks:\")\n",
    "    \n",
    "    # 1. Check all clone types are present\n",
    "    type_distribution = {}\n",
    "    model_distribution = {}\n",
    "    \n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', 'unknown')\n",
    "        model = record.get('generator', 'unknown')\n",
    "        \n",
    "        type_distribution[clone_type] = type_distribution.get(clone_type, 0) + 1\n",
    "        model_distribution[model] = model_distribution.get(model, 0) + 1\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}1. Clone Type Distribution:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        status = \"\" if count > 0 else \"\"\n",
    "        print(f\"  {status} {clone_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}2. Model Distribution:\")\n",
    "    for model, count in model_distribution.items():\n",
    "        percentage = (count / len(combined_records) * 100) if combined_records else 0\n",
    "        print(f\"  {model}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 3. Verify model assignment correctness\n",
    "    print(f\"\\n{Fore.CYAN}3. Model Assignment Verification:\")\n",
    "    correct_assignments = 0\n",
    "    incorrect_assignments = 0\n",
    "    \n",
    "    for record in combined_records:\n",
    "        clone_type = record.get('clone_type', '')\n",
    "        model = record.get('generator', '')\n",
    "        expected_model = get_model_for_clone_type(clone_type)\n",
    "        \n",
    "        if model == expected_model:\n",
    "            correct_assignments += 1\n",
    "        else:\n",
    "            incorrect_assignments += 1\n",
    "    \n",
    "    if incorrect_assignments == 0:\n",
    "        print(f\"   All {correct_assignments} records have correct model assignments\")\n",
    "    else:\n",
    "        print(f\"   {correct_assignments} correct, {incorrect_assignments} incorrect\")\n",
    "    \n",
    "    # 4. Check for required fields\n",
    "    print(f\"\\n{Fore.CYAN}4. Required Fields Check:\")\n",
    "    required_fields = ['id', 'code_1', 'code_2', 'label', 'clone_type', 'language', 'problem_id', 'generator']\n",
    "    \n",
    "    missing_fields = {}\n",
    "    for record in combined_records:\n",
    "        for field in required_fields:\n",
    "            if field not in record or not record[field]:\n",
    "                missing_fields[field] = missing_fields.get(field, 0) + 1\n",
    "    \n",
    "    if not missing_fields:\n",
    "        print(f\"   All records have all required fields\")\n",
    "    else:\n",
    "        for field, count in missing_fields.items():\n",
    "            print(f\"   {field}: missing in {count} records\")\n",
    "    \n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.GREEN}FINAL DATASET SUMMARY\")\n",
    "    print(f\"{Fore.GREEN}{'='*60}\")\n",
    "    print(f\"{Fore.CYAN}Total Records: {len(combined_records)}\")\n",
    "    print(f\"{Fore.CYAN}Dataset Path: {COMBINED_OUTPUT_PATH}\")\n",
    "    print(f\"{Fore.CYAN}File Size: {COMBINED_OUTPUT_PATH.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}Clone Type Breakdown:\")\n",
    "    for clone_type in ['type1', 'type2', 'type3', 'type4']:\n",
    "        count = type_distribution.get(clone_type, 0)\n",
    "        print(f\"  {clone_type}: {count}/{TARGET_CLONES_PER_TYPE}\")\n",
    "    \n",
    "    print(f\"\\n{Fore.GREEN} Validation Complete!\")\n",
    "else:\n",
    "    print(f\"{Fore.RED} No records found for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e80bc0ba94ee9",
   "metadata": {},
   "source": [
    "## 7. Generate Easy Non-Clones\n",
    "Use the fast `codegemma:2b` model to generate easy non-clones with simple algorithmic differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317428d3cdedf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nonclones_for_types(nonclone_types, output_path, target_per_type):\n",
    "    # Initialize dataset writer\n",
    "    dataset_writer = jsonlines.open(output_path, mode='w', flush=True)\n",
    "\n",
    "    # Load problems\n",
    "    problems = list_problems()\n",
    "    if not problems:\n",
    "        print(f\"{Fore.RED} No problems found in CodeNet directory\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(problems)} problems in CodeNet\")\n",
    "\n",
    "    problems_to_process = problems[:MAX_PROBLEMS] if MAX_PROBLEMS else problems\n",
    "\n",
    "    # Non-clone counters\n",
    "    nonclone_counters = {nt: 0 for nt in nonclone_types}\n",
    "\n",
    "    stats = {\n",
    "        'failed': 0,\n",
    "        'seed_failed': 0,\n",
    "        'no_seed': 0,\n",
    "        'identical_skipped': 0\n",
    "    }\n",
    "\n",
    "    current_problem_idx = 0\n",
    "    problems_processed = 0\n",
    "\n",
    "    # Main generation loop\n",
    "    total_target = target_per_type * len(nonclone_types)\n",
    "    with tqdm(total=total_target, desc=f\"Generating {', '.join(nonclone_types)} non-clones\") as pbar:\n",
    "        while any(nonclone_counters[nt] < target_per_type for nt in nonclone_types):\n",
    "            # Check if we've exhausted all problems and need to cycle through again\n",
    "            if current_problem_idx >= len(problems_to_process):\n",
    "                current_problem_idx = 0\n",
    "                problems_processed += 1\n",
    "                print(f\"\\n{Fore.YELLOW}Completed cycle {problems_processed}, cycling through problems again...\")\n",
    "\n",
    "                # Safety check to prevent infinite loop\n",
    "                if problems_processed >= MAX_CYCLES:\n",
    "                    print(f\"\\n{Fore.RED}Reached maximum cycles limit ({MAX_CYCLES}). Stopping generation.\")\n",
    "                    break\n",
    "\n",
    "            problem_id = problems_to_process[current_problem_idx]\n",
    "            current_problem_idx += 1\n",
    "\n",
    "            try:\n",
    "                # Load seed code\n",
    "                seed_code, sub_id = choose_seed(problem_id)\n",
    "\n",
    "                if not seed_code:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Load testcases (for validation of generated code)\n",
    "                test_cases = load_testcases(problem_id)\n",
    "                if not test_cases:\n",
    "                    stats['no_seed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Validate seed\n",
    "                seed_result = validate_java(seed_code, problem_id)\n",
    "                if isinstance(seed_result, str) and seed_result.startswith(\"compile_error\"):\n",
    "                     seed_result = \"compile_error\"\n",
    "                \n",
    "                if seed_result != \"passed\":\n",
    "                    stats['seed_failed'] += 1\n",
    "                    continue\n",
    "\n",
    "                # Generate non-clones for this problem\n",
    "                nonclones_generated_this_problem = 0\n",
    "\n",
    "                # Generate each type of non-clone\n",
    "                for nonclone_type in nonclone_types:\n",
    "                    if nonclone_counters[nonclone_type] >= target_per_type:\n",
    "                        continue\n",
    "\n",
    "                    if nonclones_generated_this_problem >= MAX_CLONES_PER_PROBLEM:\n",
    "                        break\n",
    "\n",
    "                    # Generate non-clone\n",
    "                    try:\n",
    "                        # UPDATED: Use v2 with None for problem_id (syntax repair only)\n",
    "                        generated_code = generate_nonclone_v2(seed_code, nonclone_type, problem_id=None)\n",
    "\n",
    "                        if not generated_code:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # Quick quality check\n",
    "                        is_valid, reason = quick_check_code_quality(generated_code)\n",
    "                        if not is_valid:\n",
    "                            stats['failed'] += 1\n",
    "                            continue\n",
    "\n",
    "                        # For non-clones, we just need to check if it compiles and runs\n",
    "                        # (it doesn't need to pass the original test cases)\n",
    "                        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                            java_file = Path(temp_dir) / \"Main.java\"\n",
    "\n",
    "                            try:\n",
    "                                java_file.write_text(generated_code, encoding='utf-8')\n",
    "                                compile_success, compile_error = compile_java(temp_dir)\n",
    "\n",
    "                                if compile_success:\n",
    "                                    # Try to run it with empty input to see if it executes\n",
    "                                    output, error = run_java_with_input(temp_dir, \"\", timeout=5)\n",
    "\n",
    "                                    # As long as it compiles and doesn't crash, it's valid\n",
    "                                    if error is None or \"timeout\" not in error.lower():\n",
    "                                        pair_id = f\"{problem_id}_nonclone_{nonclone_type}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "                                        record = {\n",
    "                                            'id': pair_id,\n",
    "                                            'code_1': seed_code,\n",
    "                                            'code_2': generated_code,\n",
    "                                            'label': \"non-clone\",\n",
    "                                            'clone_type': f\"nonclone_{nonclone_type}\",\n",
    "                                            'language': 'Java',\n",
    "                                            'problem_id': problem_id,\n",
    "                                            'generator': get_model_for_nonclone_type(nonclone_type),\n",
    "                                            'timestamp': time.time()\n",
    "                                        }\n",
    "\n",
    "                                        dataset_writer.write(record)\n",
    "                                        nonclone_counters[nonclone_type] += 1\n",
    "                                        nonclones_generated_this_problem += 1\n",
    "                                        pbar.update(1)\n",
    "                                    else:\n",
    "                                        stats['failed'] += 1\n",
    "                                else:\n",
    "                                    stats['failed'] += 1\n",
    "                            except Exception:\n",
    "                                stats['failed'] += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        # print(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\") # debug\n",
    "                        # log(f\"[{problem_id}] {nonclone_type} non-clone error: {repr(e)}\", Fore.RED)\n",
    "\n",
    "                # Progress update every 50 problems\n",
    "                if current_problem_idx % 50 == 0:\n",
    "                    print(f\"\\n{Fore.CYAN}Progress Update - Problem {current_problem_idx}/{len(problems_to_process)} (Cycle {problems_processed + 1}):\")\n",
    "                    for nt, count in nonclone_counters.items():\n",
    "                        status = \"\" if count >= target_per_type else f\"{count}/{target_per_type}\"\n",
    "                        print(f\"  {nt} non-clones: {status}\")\n",
    "                    print()\n",
    "\n",
    "            except Exception as e:\n",
    "                stats['failed'] += 1\n",
    "                # log(f\"[{problem_id}] Unexpected error: {e}\", Fore.RED)\n",
    "                continue\n",
    "\n",
    "    # Close writer\n",
    "    dataset_writer.close()\n",
    "\n",
    "    return nonclone_counters, stats\n",
    "\n",
    "print(f\"{Fore.GREEN} Non-clone generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665e296954acb4",
   "metadata": {},
   "source": [
    "## 8. Generate Hard Non-Clones\n",
    "Use the more capable `deepseek-coder:6.7b` model to generate hard non-clones with different problem domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b637454e7024693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 6: Generate Hard Non-Clones using deepseek-coder:6.7b\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 6: Generating Hard Non-Clones\")\n",
    "print(f\"{Fore.CYAN}Model: {HARD_MODEL}\")\n",
    "print(f\"{Fore.CYAN}Output: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "hard_nonclone_counters, hard_nonclone_stats = generate_nonclones_for_types(\n",
    "    nonclone_types=['hard'],\n",
    "    output_path=HARD_NONCLONES_OUTPUT_PATH,\n",
    "    target_per_type=TARGET_NONCLONES_HARD\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN} HARD NON-CLONES GENERATION COMPLETE!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Non-Clone Counts:\")\n",
    "total_hard_nonclones = 0\n",
    "for nonclone_type, count in hard_nonclone_counters.items():\n",
    "    status = \" COMPLETE\" if count >= TARGET_NONCLONES_HARD else \" INCOMPLETE\"\n",
    "    print(f\"  {nonclone_type}: {count}/{TARGET_NONCLONES_HARD} {status}\")\n",
    "    total_hard_nonclones += count\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}Total hard non-clones: {total_hard_nonclones}\")\n",
    "print(f\"Time taken: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Dataset saved to: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "print(f\"\\n{Fore.YELLOW}Statistics:\")\n",
    "print(f\"  No seed found: {hard_nonclone_stats['no_seed']}\")\n",
    "print(f\"  Seed validation failed: {hard_nonclone_stats['seed_failed']}\")\n",
    "print(f\"  Generation/validation failed: {hard_nonclone_stats['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92410adeaf51218",
   "metadata": {},
   "source": [
    "## 9. Create Complete Dataset\n",
    "Combine all clones and non-clones into a single comprehensive dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67808d3fbc71e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d1fd9ba85de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 7: Create Complete Dataset (Clones + Non-Clones)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{Fore.CYAN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}STEP 7: Creating Complete Dataset\")\n",
    "print(f\"{Fore.CYAN}{'='*60}\\n\")\n",
    "\n",
    "# Read all datasets\n",
    "clone_records = []\n",
    "easy_nonclone_records = []\n",
    "hard_nonclone_records = []\n",
    "\n",
    "if COMBINED_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(COMBINED_OUTPUT_PATH) as reader:\n",
    "        clone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(clone_records)} clone records from {COMBINED_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW} Clone dataset file not found: {COMBINED_OUTPUT_PATH}\")\n",
    "\n",
    "if EASY_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(EASY_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        easy_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(easy_nonclone_records)} easy non-clone records from {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW} Easy non-clones file not found: {EASY_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "if HARD_NONCLONES_OUTPUT_PATH.exists():\n",
    "    with jsonlines.open(HARD_NONCLONES_OUTPUT_PATH) as reader:\n",
    "        hard_nonclone_records = list(reader)\n",
    "    print(f\"{Fore.GREEN} Loaded {len(hard_nonclone_records)} hard non-clone records from {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW} Hard non-clones file not found: {HARD_NONCLONES_OUTPUT_PATH}\")\n",
    "\n",
    "# Combine all records\n",
    "all_complete_records = clone_records + easy_nonclone_records + hard_nonclone_records\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Total records to write: {len(all_complete_records)}\")\n",
    "print(f\"  Clones: {len(clone_records)}\")\n",
    "print(f\"  Easy Non-clones: {len(easy_nonclone_records)}\")\n",
    "print(f\"  Hard Non-clones: {len(hard_nonclone_records)}\")\n",
    "\n",
    "# Write complete dataset\n",
    "with jsonlines.open(FINAL_DATASET_PATH, mode='w') as writer:\n",
    "    for record in all_complete_records:\n",
    "        writer.write(record)\n",
    "\n",
    "print(f\"{Fore.GREEN} Complete dataset written to: {FINAL_DATASET_PATH}\")\n",
    "\n",
    "# Count by type and label\n",
    "label_counts = {}\n",
    "type_counts = {}\n",
    "for record in all_complete_records:\n",
    "    label = record.get('label', 'unknown')\n",
    "    clone_type = record.get('clone_type', 'unknown')\n",
    "\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    type_counts[clone_type] = type_counts.get(clone_type, 0) + 1\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Label:\")\n",
    "for label in ['clone', 'non-clone']:\n",
    "    count = label_counts.get(label, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.CYAN}Distribution by Type:\")\n",
    "for type_name in ['type1', 'type2', 'type3', 'type4', 'nonclone_easy', 'nonclone_hard']:\n",
    "    count = type_counts.get(type_name, 0)\n",
    "    percentage = (count / len(all_complete_records) * 100) if all_complete_records else 0\n",
    "    print(f\"  {type_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.GREEN} COMPLETE DATASET CREATION FINISHED!\")\n",
    "print(f\"{Fore.GREEN}{'='*60}\")\n",
    "print(f\"{Fore.CYAN}Final Dataset: {FINAL_DATASET_PATH}\")\n",
    "print(f\"{Fore.CYAN}Total Records: {len(all_complete_records)}\")\n",
    "print(f\"{Fore.CYAN}File Size: {FINAL_DATASET_PATH.stat().st_size / (1024*1024):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
