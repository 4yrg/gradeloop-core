{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tier 3: Semantic Detection Evaluation\n",
                "\n",
                "Evaluates CodeBERT embeddings for Type-4 (Semantic) detection.\n",
                "**Note**: This may be slow on CPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading microsoft/codebert-base on CPU (no GPU detected)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-01-02 12:29:01.404997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                        "  if not hasattr(np, \"object\"):\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "Could not find RobertaModel neither in <module 'transformers.models.roberta' from '/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/roberta/__init__.py'> nor in <module 'transformers' from '/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/__init__.py'>!",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:741\u001b[39m, in \u001b[36mgetattribute_from_module\u001b[39m\u001b[34m(module, attr)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformers_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:745\u001b[39m, in \u001b[36mgetattribute_from_module\u001b[39m\u001b[34m(module, attr)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m!\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mValueError\u001b[39m: Could not find RobertaModel in <module 'transformers' from '/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/__init__.py'>!",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mREDIS_URL\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mredis://localhost:6379/0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Reload modules to pick up changes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embedding_model\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tier3_semantic\n\u001b[32m     13\u001b[39m importlib.reload(embedding_model)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/apps/cipas/app/models/embedding_model.py:37\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m embedding.cpu().numpy()[\u001b[32m0\u001b[39m].tolist()\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Singleton instance\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m embedder = \u001b[43mCodeEmbedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/apps/cipas/app/models/embedding_model.py:19\u001b[39m, in \u001b[36mCodeEmbedder.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on CPU (no GPU detected)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:601\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class.from_pretrained(\n\u001b[32m    598\u001b[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001b[32m    599\u001b[39m     )\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping:\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m     model_class = \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:394\u001b[39m, in \u001b[36m_get_model_class\u001b[39m\u001b[34m(config, model_mapping)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     supported_models = \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    396\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:807\u001b[39m, in \u001b[36m_LazyAutoMapping.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_mapping:\n\u001b[32m    806\u001b[39m     model_name = \u001b[38;5;28mself\u001b[39m._model_mapping[model_type]\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[32m    810\u001b[39m model_types = [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_mapping.items() \u001b[38;5;28;01mif\u001b[39;00m v == key.\u001b[34m__name__\u001b[39m]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:821\u001b[39m, in \u001b[36m_LazyAutoMapping._load_attr_from_module\u001b[39m\u001b[34m(self, model_type, attr)\u001b[39m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m    820\u001b[39m     \u001b[38;5;28mself\u001b[39m._modules[module_name] = importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransformers.models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:743\u001b[39m, in \u001b[36mgetattribute_from_module\u001b[39m\u001b[34m(module, attr)\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(transformers_module, attr)\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m neither in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m nor in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m!\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mValueError\u001b[39m: Could not find RobertaModel neither in <module 'transformers.models.roberta' from '/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/models/roberta/__init__.py'> nor in <module 'transformers' from '/home/iamdasun/Projects/SLIIT/4YRG/gradeloop-core/.venv/lib/python3.12/site-packages/transformers/__init__.py'>!"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "import numpy as np\n",
                "import json\n",
                "import importlib\n",
                "\n",
                "sys.path.append(os.path.abspath(\"..\"))\n",
                "os.environ[\"REDIS_URL\"] = \"redis://localhost:6379/0\"\n",
                "\n",
                "# Reload modules to pick up changes\n",
                "from app.models import embedding_model\n",
                "from app.pipeline import tier3_semantic\n",
                "importlib.reload(embedding_model)\n",
                "importlib.reload(tier3_semantic)\n",
                "from app.models.embedding_model import embedder\n",
                "from app.pipeline.tier3_semantic import tier3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Embedding Generation\n",
                "Generate and inspect embeddings for sample code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Embedding Size: 768\n"
                    ]
                }
            ],
            "source": [
                "# Factorial Recursive\n",
                "code_A = \"\"\"\n",
                "public int factorial(int n) {\n",
                "    if (n <= 1) return 1;\n",
                "    return n * factorial(n - 1);\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "# Factorial Iterative (Type-4 Clone of A)\n",
                "code_B = \"\"\"\n",
                "public int factorial(int n) {\n",
                "    int res = 1;\n",
                "    for (int i = 2; i <= n; i++)\n",
                "        res *= i;\n",
                "    return res;\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "# Completely unrelated\n",
                "code_C = \"\"\"\n",
                "public void printHello() {\n",
                "    System.out.println(\"Hello World\");\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "emb_A = embedder.generate_embedding(code_A)\n",
                "emb_B = embedder.generate_embedding(code_B)\n",
                "emb_C = embedder.generate_embedding(code_C)\n",
                "\n",
                "print(f\"Embedding Size: {len(emb_A)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Cosine Similarity Analysis\n",
                "Compare the embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Similarity (Recursive vs Iterative): 0.9966\n",
                        "Similarity (Factorial vs Hello): 0.9820\n",
                        "WARNING: Model may need fine-tuning.\n"
                    ]
                }
            ],
            "source": [
                "def cosine(v1, v2):\n",
                "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
                "\n",
                "sim_AB = cosine(emb_A, emb_B)\n",
                "sim_AC = cosine(emb_A, emb_C)\n",
                "\n",
                "print(f\"Similarity (Recursive vs Iterative): {sim_AB:.4f}\")\n",
                "print(f\"Similarity (Factorial vs Hello): {sim_AC:.4f}\")\n",
                "\n",
                "# Check if clear separation exists\n",
                "if sim_AB > sim_AC + 0.1:\n",
                "    print(\"SUCCESS: Semantic model distinguishes functionality.\")\n",
                "else:\n",
                "    print(\"WARNING: Model may need fine-tuning.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Tier 3 Retrieval"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[{'submission_id': 'sub_B', 'similarity': 0.6983037763136996, 'tier': 3, 'semantic_similarity': 0.9966075526273991}]\n"
                    ]
                }
            ],
            "source": [
                "candidates = [{\"submission_id\": \"sub_B\", \"similarity\": 0.4, \"tier\": 2}] # Low synth sim\n",
                "\n",
                "import redis\n",
                "r = redis.Redis.from_url(\"redis://localhost:6379/0\")\n",
                "r.set(\"emb:sub_B\", json.dumps(emb_B))\n",
                "\n",
                "results = await tier3.search(\"sub_A\", code_A, candidates)\n",
                "print(results)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
