{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45ed789-53e9-4e00-a15d-85243810f607",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation for Code Clone Detection\n",
    "\n",
    "This notebook covers the machine learning aspects of the code clone detection pipeline, including training an encoder model, building a FAISS index for efficient retrieval, and evaluating the system's performance. It builds upon the data prepared in `data_preparation_and_exploration.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768f5c3-8820-4e4f-b12e-131c34a8731b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "This cell sets up the Python environment by adding the project root to `sys.path` and importing necessary modules. This ensures that all custom modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9042b5a-e755-4d7a-85d0-7a083321d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = Path('../../..').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import modules from the code_clone_detection package\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import train_encoder\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import build_faiss_index\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.services import inference_service\n",
    "from apps.model_orchestrator.app.models.cipas.code_clone_detection.scripts import eval_metrics\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")\n",
    "\n",
    "# Ensure artifacts directory exists\n",
    "artifacts_dir = Path(train_encoder.ARTIFACTS_DIR)\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2e58a-36b1-4c40-9e8c-52d3a339f4d7",
   "metadata": {},
   "source": [
    "## 2. Train Encoder Model\n",
    "\n",
    "This step fine-tunes a HuggingFace encoder model (e.g., CodeT5+) using contrastive learning. The `train_encoder.py` script uses PyTorch Lightning and is configured to use positive pairs (T4 validated clones) and negative examples (generated hard negatives or random samples).\n",
    "\n",
    "For demonstration purposes, we will run training for a single epoch with a very small batch size. In a real scenario, this would involve more epochs, larger datasets, and potentially GPU acceleration.\n",
    "\n",
    "**Expected Runtime:** Even for one epoch on a tiny dataset, this can take a few minutes as it involves model loading and tensor operations. Using a GPU will significantly speed this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049618f-a9b1-4f12-9854-8e622345e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting encoder training...\")\n",
    "\n",
    "# Ensure you have run data_ingest, generate_syntactic_clones, and execute_validation\n",
    "# to create t4_validated_pairs.csv and generated_negatives_p00001.json\n",
    "# Mock dummy negative JSON if it doesn't exist for a quick test run\n",
    "dummy_negatives_path = artifacts_dir / \"generated_negatives_p00001.json\"\n",
    "if not dummy_negatives_path.exists():\n",
    "    print(f\"Creating dummy {dummy_negatives_path} for training...\")\n",
    "    with open(dummy_negatives_path, \"w\") as f:\n",
    "        json.dump([\"public class DummyNeg { /* code */ }\"], f)\n",
    "\n",
    "# The training script expects `t4_validated_pairs.csv` to exist\n",
    "# You should have created this in the data_preparation_and_exploration.ipynb notebook.\n",
    "dummy_t4_path = artifacts_dir / \"t4_validated_pairs.csv\"\n",
    "if not dummy_t4_path.exists():\n",
    "    print(f\"Creating dummy {dummy_t4_path} for training...\")\n",
    "    # Needs to match format: submission_id_1,submission_id_2,problem_id,language,clone_type\n",
    "    dummy_data = [\n",
    "        [\"sid1\", \"sid2\", \"p00001\", \"Java\", \"T4\"],\n",
    "        [\"sid3\", \"sid4\", \"p00001\", \"Java\", \"T4\"]\n",
    "    ]\n",
    "    with open(dummy_t4_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"submission_id_1\", \"submission_id_2\", \"problem_id\", \"language\", \"clone_type\"])\n",
    "        writer.writerows(dummy_data)\n",
    "\n",
    "\n",
    "# Call the training script via CLI. Adjust arguments as needed.\n",
    "command = [\n",
    "    \"python\", \n",
    "    str(project_root / \"apps\" / \"model_orchestrator\" / \"app\" / \"models\" / \"cipas\" / \"code_clone_detection\" / \"scripts\" / \"train_encoder.py\"),\n",
    "    \"train\",\n",
    "    \"--epochs\", \"1\",\n",
    "    \"--batch-size\", \"2\",\n",
    "    \"--lr\", \"2e-5\",\n",
    "    \"--t4-pairs-csv\", str(dummy_t4_path),\n",
    "    \"--negatives-json\", str(dummy_negatives_path),\n",
    "    \"--model-name\", \"Salesforce/codet5p-220m-bimodal\", # Smaller model for quicker test\n",
    "]
    "\n",
    "# Execute the command\n",
    "print(f\"Executing: {\' '.join(command)}\")\n",
    "# !{' '.join(command)}\n",
    "\n",
    "print(\"Training process initiated. Check console for detailed logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221b2d0-1c00-4787-8e65-989635b7e9ef",
   "metadata": {},
   "source": [
    "## 3. Build FAISS Index and Perform Retrieval\n",
    "\n",
    "After training, the encoder model can generate embeddings for code snippets. This section builds a FAISS index from these embeddings for efficient similarity search. We'll then use the `inference_service` to retrieve similar codes for a sample query.\n",
    "\n",
    "**Expected Runtime:** Index building can take seconds to minutes depending on the number of embeddings. Retrieval is very fast (milliseconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b21c4-0b61-4202-b25c-89a19c6f2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the embeddings directory exists and contains embeddings (created by train_encoder.py)\n",
    "embeddings_dir = Path(train_encoder.EMBEDDINGS_DIR)\n",
    "embeddings_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Assume `train_encoder.py` saves model and tokenizer to embeddings_dir / \"final_model\"\n",
    "# and generates some dummy embeddings for evaluation.\n",
    "# For this notebook, we'll create dummy embedding files if not present\n",
    "if not (embeddings_dir / \"final_model\").exists():\n",
    "    print(\"Creating dummy model directory for FAISS index build...\")\n",
    "    (embeddings_dir / \"final_model\").mkdir(exist_ok=True)\n",
    "    # Dummy tokenizer files required by AutoTokenizer\n",
    "    with open(embeddings_dir / \"final_model\" / \"tokenizer.json\", \"w\") as f: json.dump({}, f)\n",
    "    with open(embeddings_dir / \"final_model\" / \"config.json\", \"w\") as f: json.dump({}, f)\n",
    "    # Dummy embeddings and sids for build_faiss_index\n",
    "    dummy_embeddings = np.random.rand(10, 768).astype(np.float32)\n",
    "    np.save(embeddings_dir / \"part_0.npy\", dummy_embeddings)\n",
    "    dummy_sids = [f\"dummy_sid_{i}\" for i in range(10)]\n",
    "    with open(embeddings_dir / \"part_0.json\", \"w\") as f: json.dump(dummy_sids, f)\n",
    "\n",
    "\n",
    "print(\"Building FAISS index...\")\n",
    "command = [\n",
    "    \"python\",\n",
    "    str(project_root / \"apps\" / \"model_orchestrator\" / \"app\" / \"models\" / \"cipas\" / \"code_clone_detection\" / \"scripts\" / \"build_faiss_index.py\"),\n",
    "    \"build\",\n",
    "    \"--index-path\", str(inference_service.FAISS_INDEX_PATH),\n",
    "    \"--sid-map-path\", str(inference_service.SID_MAP_PATH),\n",
    "    \"--index-type\", \"flat\",\n",
    "    \"--metric\", \"ip\",\n",
    "    \"--overwrite\",\n",
    "]
    "\n",
    "print(f\"Executing: {\' '.join(command)}\")\n",
    "# !{' '.join(command)}\n",
    "\n",
    "print(\"\\n--- Sample Retrieval ---\")\n",
    "async def run_sample_retrieval():\n",
    "    # Reload the service to ensure it picks up the new index\n",
    "    svc = inference_service.InferenceService(\n",
    "        checkpoint_path=embeddings_dir / \"final_model\",\n",
    "        faiss_index_path=inference_service.FAISS_INDEX_PATH,\n",
    "        sid_map_path=inference_service.SID_MAP_PATH,\n",
    "    )\n",
    "    \n",
    "    if not svc.model or not svc.faiss_index:\n",
    "        print(\"Inference service not fully initialized after index build. Skipping retrieval.\")\n",
    "        return\n",
    "\n",
    "    sample_query_code = \"public class HelloWorld { public static void main(String[] args) { System.out.println(\\\"Hello, World!\\\"); } }\"\n",
    "    print(\"Querying for:\")\n",
    "    print(sample_query_code)\n",
    "    results = await svc.retrieve(sample_query_code, k=3)\n",
    "    print(\"\\nTop 3 retrieved clones:\")\n",
    "    for sid, score in results:\n",
    "        print(f\" - SID: {sid}, Score: {score:.4f}\")\n",
    "\n",
    "await run_sample_retrieval()\n",
    "\n",
    "print(\"\\nNote: The retrieval results will be random if dummy embeddings were used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221b2d0-1c00-4787-8e65-989635b7e9ef",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance\n",
    "\n",
    "This section evaluates the performance of the trained encoder and the FAISS index using metrics like Mean Average Precision (MAP) and Recall@k. We'll use a small subset of CodeNet (defined by T4 pairs) as the test set.\n",
    "\n",
    "**Expected Runtime:** This can take a few seconds to minutes depending on the number of queries and retrieval complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b21c4-0b61-4202-b25c-89a19c6f2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reports_dir = Path(eval_metrics.EVAL_REPORTS_DIR)\n",
    "eval_reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "command = [\n",
    "    \"python\",\n",
    "    str(project_root / \"apps\" / \"model_orchestrator\" / \"app\" / \"models\" / \"cipas\" / \"code_clone_detection\" / \"scripts\" / \"eval_metrics.py\"),\n",
    "    \"evaluate\",\n",
    "    \"codenet\",\n",
    "    \"--model-checkpoint\", str(embeddings_dir / \"final_model\"),\n",
    "    \"--faiss-index\", str(inference_service.FAISS_INDEX_PATH),\n",
    "    \"--sid-map\", str(inference_service.SID_MAP_PATH),\n",
    "    \"--k\", \"5\",\n",
    "    \"--limit-queries\", \"10\", # Limit for quick demo\n",
    "    \"--output-dir\", str(eval_reports_dir),\n",
    "]
    "\n",
    "print(f\"Executing: {\' '.join(command)}\")\n",
    "# !{' '.join(command)}\n",
    "\n",
    "print(\"\\nLoading latest evaluation report:\")\n",
    "try:\n",
    "    # Find the latest report in the output_dir\n",
    "    latest_report = sorted(eval_reports_dir.glob(\"eval_report_codenet_*.json\"), reverse=True)[0]\n",
    "    with open(latest_report, \"r\") as f:\n",
    "        report_data = json.load(f)\n",
    "    \n",
    "    print(\"Evaluation Report:\")\n",
    "    display(report_data)\n",
    "\n",
    "    # Plotting example\n",
    "    metrics_to_plot = [\"mean_average_precision\", \"recall@5\", \"recall@10\"]\n",
    "    scores = [report_data.get(metric, 0.0) for metric in metrics_to_plot]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    bars = ax.bar(metrics_to_plot, scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Code Clone Detection Evaluation Metrics\")\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.01, round(yval, 3), ha='center', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "except (FileNotFoundError, IndexError):\n",
    "    print(\"No evaluation report found. Ensure the evaluation script ran correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f32c3-9d11-4712-ae87-0b1ac8684d0b",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "This concludes the end-to-end demonstration of the code clone detection pipeline. Here's a checklist of potential next steps:\n",
    "\n",
    "- [ ] **Integrate with FastAPI**: Start the FastAPI application (`model-orchestrator`) and test the `/ciploc/encode` and `/ciploc/retrieve` endpoints.\n",
    "- [ ] **Full Data Ingestion**: Ingest the entire CodeNet dataset (or a larger subset).\n",
    "- [ ] **Hyperparameter Tuning**: Experiment with different training parameters (learning rate, epochs, batch size, model architecture).\n",
    "- [ ] **Model Evaluation**: Conduct more thorough evaluations on diverse datasets like BigCloneBench or CodeXGLUE.\n",
    "- [ ] **Deployment**: Explore deploying the FastAPI service with a robust inference setup (e.g., using a GPU, optimizing model serving).\n",
    "- [ ] **Hard Negative Mining**: Use `scripts/hard_negative_mining.py` to generate offline hard negatives and incorporate them into further training iterations.\n",
    "- [ ] **Refine Normalization**: Improve the `ast_rename_identifiers` for better Type-2 clone detection.\n",
    "- [ ] **Production Sandbox**: Replace the basic sandbox with a containerized solution for secure code execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
